{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fundemental modules\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pprint\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from ddqn import DDQNAgent # type: ignore\n",
    "from utils import load_config\n",
    "from obs import observation_shape\n",
    "\n",
    "aggregate_stats_every=100\n",
    "best_score = -1000.0\n",
    "score_history = []\n",
    "episode_lens = []\n",
    "avg_history = []\n",
    "std_history = []\n",
    "avg_history_100 = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/o/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.configure to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.configure` for environment variables or `env.get_wrapper_attr('configure')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "data = load_config()\n",
    "env = gym.make('racetrack-v0', render_mode = 'rgb_array')\n",
    "env.configure(data) # type: ignore\n",
    "# pprint.pprint(env.config) # type: ignore\n",
    "(obs, info), done = env.reset(), False\n",
    "\n",
    "#observation config\n",
    "proc = observation_shape(obs,info,2)\n",
    "proc.reset()\n",
    "input = proc.get_input()\n",
    "print(input.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 128)               3456      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 11)                1419      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21387 (83.54 KB)\n",
      "Trainable params: 21387 (83.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "summary\n",
      "Agent is initialized.\n"
     ]
    }
   ],
   "source": [
    "agent = DDQNAgent(alpha=0.001, gamma=0.9, epsilon=1.0, obs_shape=input.shape,\n",
    "                  batch_size=64, epsilon_dec=0.9995, epsilon_end=0.05, mem_size=100000,\n",
    "                  min_mem_size=100, replace_target=1000, learning_rate=0.0003)\n",
    "print(\"Agent is initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0ba980fa1d43e6a44d21865c0f0ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test episodes:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----saving models------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 21:50:13.966874: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  0 score 0.6 ep len 7 avg score 0.6 avg_score_100 0.6 std score 0.0\n",
      "episode  1 score -0.5 ep len 16 avg score 0.1 avg_score_100 0.1 std score 0.5\n",
      "episode  2 score -0.6 ep len 12 avg score -0.2 avg_score_100 -0.2 std score 0.5\n",
      "episode  3 score -0.2 ep len 8 avg score -0.2 avg_score_100 -0.2 std score 0.5\n",
      "episode  4 score 0.4 ep len 18 avg score -0.1 avg_score_100 -0.1 std score 0.5\n",
      "episode  5 score -0.2 ep len 4 avg score -0.1 avg_score_100 -0.1 std score 0.4\n",
      "episode  6 score 1.1 ep len 6 avg score 0.1 avg_score_100 0.1 std score 0.6\n",
      "episode  7 score 0.1 ep len 14 avg score 0.1 avg_score_100 0.1 std score 0.5\n",
      "episode  8 score -0.5 ep len 3 avg score 0.0 avg_score_100 0.0 std score 0.5\n",
      "episode  9 score 0.3 ep len 10 avg score 0.0 avg_score_100 0.0 std score 0.5\n",
      "episode  10 score 1.1 ep len 5 avg score 0.1 avg_score_100 0.1 std score 0.6\n",
      "episode  11 score -0.3 ep len 2 avg score 0.1 avg_score_100 0.1 std score 0.6\n",
      "episode  12 score 0.1 ep len 12 avg score 0.1 avg_score_100 0.1 std score 0.6\n",
      "episode  13 score -0.8 ep len 13 avg score 0.0 avg_score_100 0.0 std score 0.6\n",
      "episode  14 score -0.2 ep len 3 avg score 0.0 avg_score_100 0.0 std score 0.6\n",
      "episode  15 score 1.9 ep len 16 avg score 0.2 avg_score_100 0.2 std score 0.7\n",
      "episode  16 score 1.9 ep len 21 avg score 0.3 avg_score_100 0.3 std score 0.8\n",
      "episode  17 score -0.7 ep len 6 avg score 0.2 avg_score_100 0.2 std score 0.8\n",
      "episode  18 score 0.6 ep len 8 avg score 0.2 avg_score_100 0.2 std score 0.8\n",
      "episode  19 score 0.3 ep len 7 avg score 0.2 avg_score_100 0.2 std score 0.8\n",
      "episode  20 score 2.9 ep len 7 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  21 score -0.4 ep len 3 avg score 0.3 avg_score_100 0.3 std score 0.9\n",
      "episode  22 score 2.5 ep len 13 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  23 score -0.3 ep len 3 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  24 score 0.3 ep len 11 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  25 score -0.5 ep len 3 avg score 0.3 avg_score_100 0.3 std score 1.0\n",
      "episode  26 score -1.1 ep len 8 avg score 0.3 avg_score_100 0.3 std score 1.0\n",
      "episode  27 score 0.8 ep len 5 avg score 0.3 avg_score_100 0.3 std score 1.0\n",
      "episode  28 score -0.6 ep len 8 avg score 0.3 avg_score_100 0.3 std score 1.0\n",
      "episode  29 score -1.2 ep len 12 avg score 0.2 avg_score_100 0.2 std score 1.0\n",
      "episode  30 score -0.2 ep len 4 avg score 0.2 avg_score_100 0.2 std score 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 21:50:17.330816: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4a5c02c650 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-02 21:50:17.330829: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-12-02 21:50:17.335994: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-02 21:50:18.574831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2023-12-02 21:50:18.632092: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  31 score 0.5 ep len 39 avg score 0.2 avg_score_100 0.2 std score 1.0\n",
      "episode  32 score 0.8 ep len 21 avg score 0.2 avg_score_100 0.2 std score 1.0\n",
      "episode  33 score -0.5 ep len 9 avg score 0.2 avg_score_100 0.2 std score 1.0\n",
      "episode  34 score 3.0 ep len 12 avg score 0.3 avg_score_100 0.3 std score 1.1\n",
      "episode  35 score -1.6 ep len 18 avg score 0.3 avg_score_100 0.3 std score 1.1\n",
      "episode  36 score 1.7 ep len 13 avg score 0.3 avg_score_100 0.3 std score 1.1\n",
      "episode  37 score 0.1 ep len 17 avg score 0.3 avg_score_100 0.3 std score 1.1\n",
      "episode  38 score 1.7 ep len 17 avg score 0.3 avg_score_100 0.3 std score 1.1\n",
      "episode  39 score -1.2 ep len 11 avg score 0.3 avg_score_100 0.3 std score 1.1\n",
      "episode  40 score -0.3 ep len 3 avg score 0.3 avg_score_100 0.3 std score 1.1\n",
      "episode  41 score -0.3 ep len 2 avg score 0.3 avg_score_100 0.3 std score 1.1\n",
      "episode  42 score -0.3 ep len 3 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  43 score -2.0 ep len 17 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  44 score 3.2 ep len 19 avg score 0.3 avg_score_100 0.3 std score 1.2\n",
      "episode  45 score -0.3 ep len 3 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  46 score -1.8 ep len 12 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  47 score 1.7 ep len 8 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  48 score -0.8 ep len 5 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  49 score -0.0 ep len 7 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  50 score -0.2 ep len 29 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  51 score 1.3 ep len 19 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  52 score 0.4 ep len 3 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  53 score -1.1 ep len 11 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  54 score -0.3 ep len 13 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  55 score 0.6 ep len 21 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  56 score 0.9 ep len 8 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  57 score 0.4 ep len 7 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  58 score -0.5 ep len 7 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  59 score 0.1 ep len 11 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  60 score -0.4 ep len 6 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  61 score -0.3 ep len 3 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  62 score -0.7 ep len 4 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  63 score 0.9 ep len 13 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  64 score 0.2 ep len 8 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  65 score -0.6 ep len 7 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  66 score 1.3 ep len 14 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  67 score -0.5 ep len 18 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  68 score -0.3 ep len 2 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  69 score -1.2 ep len 18 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  70 score -0.5 ep len 4 avg score 0.1 avg_score_100 0.1 std score 1.1\n",
      "episode  71 score 1.1 ep len 11 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  72 score 1.0 ep len 11 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  73 score 0.5 ep len 9 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  74 score 2.4 ep len 18 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  75 score -0.4 ep len 3 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  76 score 0.5 ep len 18 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  77 score -1.0 ep len 7 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  78 score 0.7 ep len 7 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  79 score -0.3 ep len 3 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  80 score -0.9 ep len 20 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  81 score -1.7 ep len 15 avg score 0.1 avg_score_100 0.1 std score 1.1\n",
      "episode  82 score 2.1 ep len 12 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  83 score 0.1 ep len 10 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  84 score -0.1 ep len 6 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  85 score -0.2 ep len 7 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  86 score 1.0 ep len 18 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  87 score -0.5 ep len 12 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  88 score -0.5 ep len 7 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  89 score -0.2 ep len 4 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  90 score 2.0 ep len 15 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  91 score -2.0 ep len 23 avg score 0.1 avg_score_100 0.1 std score 1.1\n",
      "episode  92 score -1.8 ep len 17 avg score 0.1 avg_score_100 0.1 std score 1.1\n",
      "episode  93 score 3.3 ep len 22 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  94 score 1.8 ep len 16 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "Target Updated\n",
      "episode  95 score -0.2 ep len 3 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "episode  96 score -0.4 ep len 4 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "episode  97 score -0.2 ep len 12 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "episode  98 score 1.0 ep len 14 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  99 score -0.3 ep len 3 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  100 score -0.3 ep len 4 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  101 score 1.3 ep len 5 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  102 score 0.4 ep len 17 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  103 score -0.3 ep len 7 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  104 score 1.8 ep len 16 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  105 score -0.6 ep len 5 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  106 score -0.4 ep len 5 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  107 score 1.8 ep len 10 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  108 score 4.0 ep len 15 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  109 score -1.3 ep len 22 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  110 score -0.9 ep len 6 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  111 score -0.8 ep len 6 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  112 score -0.1 ep len 4 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  113 score 0.3 ep len 6 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  114 score -1.1 ep len 9 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  115 score 3.2 ep len 26 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  116 score -0.3 ep len 4 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  117 score 0.6 ep len 22 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  118 score 0.7 ep len 14 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  119 score 1.7 ep len 14 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  120 score 1.4 ep len 12 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  121 score 4.6 ep len 52 avg score 0.3 avg_score_100 0.3 std score 1.2\n",
      "episode  122 score 1.6 ep len 10 avg score 0.3 avg_score_100 0.2 std score 1.2\n",
      "episode  123 score 2.9 ep len 28 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  124 score 5.1 ep len 19 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  125 score 3.5 ep len 14 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  126 score 0.1 ep len 3 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  127 score 1.1 ep len 12 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  128 score 0.9 ep len 16 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  129 score 0.8 ep len 15 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  130 score 0.8 ep len 6 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  131 score 0.7 ep len 27 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  132 score 1.6 ep len 10 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  133 score 6.2 ep len 13 avg score 0.4 avg_score_100 0.5 std score 1.4\n",
      "episode  134 score 1.1 ep len 17 avg score 0.4 avg_score_100 0.5 std score 1.4\n",
      "episode  135 score 3.0 ep len 16 avg score 0.5 avg_score_100 0.5 std score 1.4\n",
      "episode  136 score 1.4 ep len 10 avg score 0.5 avg_score_100 0.5 std score 1.4\n",
      "episode  137 score 0.7 ep len 16 avg score 0.5 avg_score_100 0.5 std score 1.4\n",
      "episode  138 score 4.0 ep len 20 avg score 0.5 avg_score_100 0.6 std score 1.4\n",
      "-----saving models------\n",
      "episode  139 score 4.2 ep len 13 avg score 0.5 avg_score_100 0.6 std score 1.5\n",
      "-----saving models------\n",
      "episode  140 score 0.8 ep len 11 avg score 0.5 avg_score_100 0.6 std score 1.5\n",
      "-----saving models------\n",
      "episode  141 score 2.5 ep len 31 avg score 0.5 avg_score_100 0.6 std score 1.5\n",
      "-----saving models------\n",
      "episode  142 score 0.5 ep len 12 avg score 0.5 avg_score_100 0.7 std score 1.5\n",
      "-----saving models------\n",
      "episode  143 score -1.1 ep len 27 avg score 0.5 avg_score_100 0.7 std score 1.5\n",
      "-----saving models------\n",
      "episode  144 score 2.7 ep len 30 avg score 0.5 avg_score_100 0.7 std score 1.5\n",
      "-----saving models------\n",
      "episode  145 score -1.2 ep len 9 avg score 0.5 avg_score_100 0.6 std score 1.5\n",
      "-----saving models------\n",
      "episode  146 score 2.3 ep len 14 avg score 0.5 avg_score_100 0.7 std score 1.5\n",
      "-----saving models------\n",
      "episode  147 score 0.3 ep len 15 avg score 0.5 avg_score_100 0.7 std score 1.5\n",
      "-----saving models------\n",
      "episode  148 score -0.6 ep len 12 avg score 0.5 avg_score_100 0.7 std score 1.5\n",
      "-----saving models------\n",
      "episode  149 score -1.3 ep len 11 avg score 0.5 avg_score_100 0.7 std score 1.5\n",
      "-----saving models------\n",
      "episode  150 score 0.3 ep len 12 avg score 0.5 avg_score_100 0.7 std score 1.5\n",
      "-----saving models------\n",
      "episode  151 score 3.2 ep len 19 avg score 0.5 avg_score_100 0.7 std score 1.5\n",
      "-----saving models------\n",
      "episode  152 score 1.3 ep len 5 avg score 0.5 avg_score_100 0.7 std score 1.5\n",
      "-----saving models------\n",
      "episode  153 score 3.5 ep len 16 avg score 0.6 avg_score_100 0.7 std score 1.5\n",
      "-----saving models------\n",
      "episode  154 score 0.2 ep len 13 avg score 0.5 avg_score_100 0.7 std score 1.5\n",
      "-----saving models------\n",
      "episode  155 score 1.7 ep len 14 avg score 0.6 avg_score_100 0.8 std score 1.5\n",
      "-----saving models------\n",
      "episode  156 score 3.4 ep len 33 avg score 0.6 avg_score_100 0.8 std score 1.5\n",
      "-----saving models------\n",
      "episode  157 score 0.0 ep len 14 avg score 0.6 avg_score_100 0.8 std score 1.5\n",
      "-----saving models------\n",
      "episode  158 score 7.5 ep len 22 avg score 0.6 avg_score_100 0.9 std score 1.6\n",
      "-----saving models------\n",
      "episode  159 score 1.7 ep len 8 avg score 0.6 avg_score_100 0.9 std score 1.6\n",
      "-----saving models------\n",
      "episode  160 score 4.0 ep len 18 avg score 0.6 avg_score_100 0.9 std score 1.6\n",
      "-----saving models------\n",
      "episode  161 score 4.9 ep len 36 avg score 0.7 avg_score_100 1.0 std score 1.6\n",
      "-----saving models------\n",
      "episode  162 score -0.2 ep len 4 avg score 0.7 avg_score_100 1.0 std score 1.6\n",
      "-----saving models------\n",
      "episode  163 score 4.2 ep len 14 avg score 0.7 avg_score_100 1.0 std score 1.6\n",
      "-----saving models------\n",
      "episode  164 score 4.6 ep len 17 avg score 0.7 avg_score_100 1.1 std score 1.7\n",
      "-----saving models------\n",
      "episode  165 score 2.8 ep len 13 avg score 0.7 avg_score_100 1.1 std score 1.7\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  166 score 2.2 ep len 15 avg score 0.7 avg_score_100 1.1 std score 1.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  167 score 3.4 ep len 48 avg score 0.7 avg_score_100 1.1 std score 1.7\n",
      "-----saving models------\n",
      "episode  168 score 1.0 ep len 6 avg score 0.7 avg_score_100 1.1 std score 1.7\n",
      "-----saving models------\n",
      "episode  169 score 4.9 ep len 15 avg score 0.8 avg_score_100 1.2 std score 1.7\n",
      "-----saving models------\n",
      "episode  170 score 5.8 ep len 20 avg score 0.8 avg_score_100 1.3 std score 1.7\n",
      "-----saving models------\n",
      "episode  171 score 5.4 ep len 28 avg score 0.8 avg_score_100 1.3 std score 1.8\n",
      "-----saving models------\n",
      "episode  172 score 3.5 ep len 21 avg score 0.8 avg_score_100 1.3 std score 1.8\n",
      "-----saving models------\n",
      "episode  173 score 2.7 ep len 18 avg score 0.9 avg_score_100 1.4 std score 1.8\n",
      "-----saving models------\n",
      "episode  174 score 2.2 ep len 44 avg score 0.9 avg_score_100 1.4 std score 1.8\n",
      "-----saving models------\n",
      "episode  175 score 0.7 ep len 12 avg score 0.9 avg_score_100 1.4 std score 1.8\n",
      "-----saving models------\n",
      "episode  176 score 3.1 ep len 13 avg score 0.9 avg_score_100 1.4 std score 1.8\n",
      "-----saving models------\n",
      "episode  177 score 10.3 ep len 33 avg score 0.9 avg_score_100 1.5 std score 1.9\n",
      "-----saving models------\n",
      "episode  178 score 9.6 ep len 30 avg score 1.0 avg_score_100 1.6 std score 2.0\n",
      "-----saving models------\n",
      "episode  179 score -0.3 ep len 2 avg score 1.0 avg_score_100 1.6 std score 2.0\n",
      "-----saving models------\n",
      "episode  180 score 6.1 ep len 33 avg score 1.0 avg_score_100 1.7 std score 2.0\n",
      "-----saving models------\n",
      "episode  181 score 6.3 ep len 31 avg score 1.0 avg_score_100 1.7 std score 2.1\n",
      "-----saving models------\n",
      "episode  182 score 1.3 ep len 10 avg score 1.0 avg_score_100 1.7 std score 2.1\n",
      "-----saving models------\n",
      "episode  183 score 14.7 ep len 28 avg score 1.1 avg_score_100 1.9 std score 2.3\n",
      "-----saving models------\n",
      "episode  184 score 5.7 ep len 27 avg score 1.1 avg_score_100 1.9 std score 2.3\n",
      "-----saving models------\n",
      "episode  185 score 3.5 ep len 27 avg score 1.1 avg_score_100 2.0 std score 2.3\n",
      "-----saving models------\n",
      "episode  186 score 1.0 ep len 22 avg score 1.1 avg_score_100 2.0 std score 2.3\n",
      "-----saving models------\n",
      "episode  187 score 6.8 ep len 21 avg score 1.2 avg_score_100 2.1 std score 2.3\n",
      "-----saving models------\n",
      "episode  188 score 6.9 ep len 27 avg score 1.2 avg_score_100 2.1 std score 2.4\n",
      "-----saving models------\n",
      "episode  189 score 9.2 ep len 44 avg score 1.2 avg_score_100 2.2 std score 2.4\n",
      "-----saving models------\n",
      "episode  190 score 9.5 ep len 46 avg score 1.3 avg_score_100 2.3 std score 2.5\n",
      "-----saving models------\n",
      "episode  191 score 6.3 ep len 19 avg score 1.3 avg_score_100 2.4 std score 2.5\n",
      "-----saving models------\n",
      "episode  192 score 15.0 ep len 45 avg score 1.4 avg_score_100 2.5 std score 2.7\n",
      "-----saving models------\n",
      "episode  193 score 12.4 ep len 30 avg score 1.4 avg_score_100 2.6 std score 2.8\n",
      "-----saving models------\n",
      "episode  194 score 2.1 ep len 14 avg score 1.4 avg_score_100 2.6 std score 2.8\n",
      "-----saving models------\n",
      "episode  195 score 7.2 ep len 21 avg score 1.5 avg_score_100 2.7 std score 2.8\n",
      "-----saving models------\n",
      "episode  196 score 3.8 ep len 17 avg score 1.5 avg_score_100 2.8 std score 2.8\n",
      "-----saving models------\n",
      "episode  197 score 7.1 ep len 23 avg score 1.5 avg_score_100 2.8 std score 2.8\n",
      "-----saving models------\n",
      "episode  198 score 5.5 ep len 32 avg score 1.5 avg_score_100 2.9 std score 2.8\n",
      "-----saving models------\n",
      "episode  199 score 3.0 ep len 15 avg score 1.5 avg_score_100 2.9 std score 2.8\n",
      "-----saving models------\n",
      "episode  200 score 8.8 ep len 27 avg score 1.6 avg_score_100 3.0 std score 2.9\n",
      "-----saving models------\n",
      "episode  201 score 11.8 ep len 24 avg score 1.6 avg_score_100 3.1 std score 2.9\n",
      "-----saving models------\n",
      "episode  202 score 3.8 ep len 31 avg score 1.6 avg_score_100 3.1 std score 2.9\n",
      "-----saving models------\n",
      "episode  203 score 6.8 ep len 25 avg score 1.7 avg_score_100 3.2 std score 3.0\n",
      "-----saving models------\n",
      "episode  204 score 12.4 ep len 31 avg score 1.7 avg_score_100 3.3 std score 3.0\n",
      "-----saving models------\n",
      "episode  205 score 2.1 ep len 6 avg score 1.7 avg_score_100 3.3 std score 3.0\n",
      "-----saving models------\n",
      "episode  206 score 6.3 ep len 14 avg score 1.7 avg_score_100 3.4 std score 3.0\n",
      "-----saving models------\n",
      "episode  207 score 8.1 ep len 31 avg score 1.8 avg_score_100 3.5 std score 3.1\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  208 score 7.3 ep len 18 avg score 1.8 avg_score_100 3.5 std score 3.1\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  209 score 12.3 ep len 45 avg score 1.8 avg_score_100 3.6 std score 3.2\n",
      "-----saving models------\n",
      "episode  210 score 1.9 ep len 10 avg score 1.8 avg_score_100 3.7 std score 3.2\n",
      "-----saving models------\n",
      "episode  211 score 17.2 ep len 43 avg score 1.9 avg_score_100 3.9 std score 3.3\n",
      "-----saving models------\n",
      "episode  212 score 11.8 ep len 30 avg score 2.0 avg_score_100 4.0 std score 3.4\n",
      "-----saving models------\n",
      "episode  213 score 15.2 ep len 34 avg score 2.0 avg_score_100 4.1 std score 3.5\n",
      "-----saving models------\n",
      "episode  214 score 11.1 ep len 47 avg score 2.1 avg_score_100 4.2 std score 3.5\n",
      "-----saving models------\n",
      "episode  215 score 10.0 ep len 26 avg score 2.1 avg_score_100 4.3 std score 3.6\n",
      "-----saving models------\n",
      "episode  216 score 8.0 ep len 14 avg score 2.1 avg_score_100 4.4 std score 3.6\n",
      "-----saving models------\n",
      "episode  217 score 18.3 ep len 42 avg score 2.2 avg_score_100 4.6 std score 3.7\n",
      "-----saving models------\n",
      "episode  218 score 22.9 ep len 46 avg score 2.3 avg_score_100 4.8 std score 4.0\n",
      "-----saving models------\n",
      "episode  219 score 20.8 ep len 56 avg score 2.4 avg_score_100 5.0 std score 4.2\n",
      "-----saving models------\n",
      "episode  220 score 6.3 ep len 15 avg score 2.4 avg_score_100 5.0 std score 4.2\n",
      "-----saving models------\n",
      "episode  221 score 8.5 ep len 18 avg score 2.4 avg_score_100 5.1 std score 4.2\n",
      "-----saving models------\n",
      "episode  222 score 17.9 ep len 42 avg score 2.5 avg_score_100 5.2 std score 4.3\n",
      "-----saving models------\n",
      "episode  223 score 15.0 ep len 31 avg score 2.6 avg_score_100 5.4 std score 4.4\n",
      "-----saving models------\n",
      "episode  224 score 15.6 ep len 39 avg score 2.6 avg_score_100 5.5 std score 4.4\n",
      "-----saving models------\n",
      "episode  225 score 21.2 ep len 66 avg score 2.7 avg_score_100 5.6 std score 4.6\n",
      "-----saving models------\n",
      "episode  226 score 38.9 ep len 74 avg score 2.9 avg_score_100 6.0 std score 5.2\n",
      "-----saving models------\n",
      "episode  227 score 25.0 ep len 60 avg score 3.0 avg_score_100 6.3 std score 5.4\n",
      "-----saving models------\n",
      "episode  228 score 9.6 ep len 41 avg score 3.0 avg_score_100 6.4 std score 5.4\n",
      "-----saving models------\n",
      "episode  229 score 17.6 ep len 45 avg score 3.0 avg_score_100 6.5 std score 5.4\n",
      "-----saving models------\n",
      "episode  230 score 19.9 ep len 45 avg score 3.1 avg_score_100 6.7 std score 5.5\n",
      "-----saving models------\n",
      "episode  231 score 23.3 ep len 50 avg score 3.2 avg_score_100 6.9 std score 5.7\n",
      "-----saving models------\n",
      "episode  232 score 15.7 ep len 25 avg score 3.3 avg_score_100 7.1 std score 5.7\n",
      "-----saving models------\n",
      "episode  233 score 28.1 ep len 74 avg score 3.4 avg_score_100 7.3 std score 5.9\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  234 score 30.8 ep len 80 avg score 3.5 avg_score_100 7.6 std score 6.2\n",
      "-----saving models------\n",
      "episode  235 score 22.6 ep len 70 avg score 3.6 avg_score_100 7.8 std score 6.3\n",
      "-----saving models------\n",
      "episode  236 score 9.7 ep len 28 avg score 3.6 avg_score_100 7.9 std score 6.3\n",
      "-----saving models------\n",
      "episode  237 score 29.8 ep len 86 avg score 3.7 avg_score_100 8.2 std score 6.5\n",
      "-----saving models------\n",
      "episode  238 score 31.0 ep len 61 avg score 3.8 avg_score_100 8.4 std score 6.7\n",
      "-----saving models------\n",
      "episode  239 score 36.9 ep len 76 avg score 4.0 avg_score_100 8.8 std score 7.1\n",
      "-----saving models------\n",
      "episode  240 score 26.9 ep len 84 avg score 4.0 avg_score_100 9.0 std score 7.2\n",
      "-----saving models------\n",
      "episode  241 score 26.3 ep len 74 avg score 4.1 avg_score_100 9.3 std score 7.3\n",
      "-----saving models------\n",
      "episode  242 score 36.7 ep len 81 avg score 4.3 avg_score_100 9.6 std score 7.6\n",
      "-----saving models------\n",
      "episode  243 score 35.6 ep len 80 avg score 4.4 avg_score_100 10.0 std score 7.8\n",
      "-----saving models------\n",
      "episode  244 score 40.5 ep len 71 avg score 4.5 avg_score_100 10.4 std score 8.2\n",
      "-----saving models------\n",
      "episode  245 score 32.0 ep len 73 avg score 4.7 avg_score_100 10.7 std score 8.3\n",
      "-----saving models------\n",
      "episode  246 score 39.9 ep len 79 avg score 4.8 avg_score_100 11.1 std score 8.6\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  247 score 50.1 ep len 91 avg score 5.0 avg_score_100 11.6 std score 9.1\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  248 score 39.0 ep len 75 avg score 5.1 avg_score_100 12.0 std score 9.3\n",
      "-----saving models------\n",
      "episode  249 score 36.4 ep len 80 avg score 5.2 avg_score_100 12.3 std score 9.5\n",
      "-----saving models------\n",
      "episode  250 score 38.4 ep len 83 avg score 5.4 avg_score_100 12.7 std score 9.7\n",
      "-----saving models------\n",
      "episode  251 score 24.2 ep len 38 avg score 5.5 avg_score_100 12.9 std score 9.7\n",
      "-----saving models------\n",
      "episode  252 score 49.9 ep len 90 avg score 5.6 avg_score_100 13.4 std score 10.1\n",
      "-----saving models------\n",
      "episode  253 score 62.1 ep len 158 avg score 5.9 avg_score_100 14.0 std score 10.7\n",
      "-----saving models------\n",
      "episode  254 score 62.5 ep len 147 avg score 6.1 avg_score_100 14.6 std score 11.2\n",
      "-----saving models------\n",
      "episode  255 score 82.3 ep len 150 avg score 6.4 avg_score_100 15.4 std score 12.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  256 score 82.2 ep len 200 avg score 6.7 avg_score_100 16.2 std score 13.0\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  257 score 104.0 ep len 185 avg score 7.0 avg_score_100 17.3 std score 14.4\n",
      "-----saving models------\n",
      "episode  258 score 115.1 ep len 181 avg score 7.5 avg_score_100 18.3 std score 15.8\n",
      "-----saving models------\n",
      "episode  259 score 111.9 ep len 200 avg score 7.9 avg_score_100 19.4 std score 17.1\n",
      "-----saving models------\n",
      "episode  260 score 75.4 ep len 173 avg score 8.1 avg_score_100 20.2 std score 17.5\n",
      "-----saving models------\n",
      "episode  261 score 102.3 ep len 168 avg score 8.5 avg_score_100 21.1 std score 18.4\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  262 score 100.7 ep len 189 avg score 8.8 avg_score_100 22.1 std score 19.3\n",
      "-----saving models------\n",
      "episode  263 score 121.8 ep len 200 avg score 9.3 avg_score_100 23.3 std score 20.4\n",
      "-----saving models------\n",
      "episode  264 score 133.5 ep len 200 avg score 9.7 avg_score_100 24.6 std score 21.8\n",
      "-----saving models------\n",
      "episode  265 score 123.9 ep len 200 avg score 10.2 avg_score_100 25.8 std score 22.8\n",
      "-----saving models------\n",
      "episode  266 score 140.6 ep len 200 avg score 10.6 avg_score_100 27.2 std score 24.1\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  267 score 136.3 ep len 200 avg score 11.1 avg_score_100 28.5 std score 25.3\n",
      "-----saving models------\n",
      "episode  268 score 132.6 ep len 200 avg score 11.6 avg_score_100 29.8 std score 26.3\n",
      "-----saving models------\n",
      "episode  269 score 78.0 ep len 108 avg score 11.8 avg_score_100 30.6 std score 26.6\n",
      "-----saving models------\n",
      "episode  270 score 139.6 ep len 200 avg score 12.3 avg_score_100 31.9 std score 27.6\n",
      "-----saving models------\n",
      "episode  271 score 143.9 ep len 200 avg score 12.8 avg_score_100 33.3 std score 28.7\n",
      "-----saving models------\n",
      "episode  272 score 133.1 ep len 200 avg score 13.2 avg_score_100 34.6 std score 29.5\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  273 score 140.3 ep len 200 avg score 13.7 avg_score_100 36.0 std score 30.5\n",
      "-----saving models------\n",
      "episode  274 score 55.4 ep len 75 avg score 13.8 avg_score_100 36.5 std score 30.5\n",
      "-----saving models------\n",
      "episode  275 score 143.0 ep len 200 avg score 14.3 avg_score_100 37.9 std score 31.4\n",
      "-----saving models------\n",
      "episode  276 score 116.1 ep len 166 avg score 14.7 avg_score_100 39.1 std score 32.0\n",
      "-----saving models------\n",
      "episode  277 score 4.1 ep len 11 avg score 14.6 avg_score_100 39.0 std score 31.9\n",
      "-----saving models------\n",
      "episode  278 score 149.5 ep len 200 avg score 15.1 avg_score_100 40.4 std score 32.9\n",
      "-----saving models------\n",
      "episode  279 score 131.8 ep len 200 avg score 15.5 avg_score_100 41.7 std score 33.5\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  280 score 125.1 ep len 200 avg score 15.9 avg_score_100 42.9 std score 34.1\n",
      "-----saving models------\n",
      "episode  281 score 147.4 ep len 200 avg score 16.4 avg_score_100 44.3 std score 34.9\n",
      "-----saving models------\n",
      "episode  282 score 141.2 ep len 200 avg score 16.8 avg_score_100 45.7 std score 35.6\n",
      "-----saving models------\n",
      "episode  283 score 13.6 ep len 18 avg score 16.8 avg_score_100 45.7 std score 35.6\n",
      "-----saving models------\n",
      "episode  284 score 48.9 ep len 62 avg score 16.9 avg_score_100 46.1 std score 35.6\n",
      "-----saving models------\n",
      "episode  285 score 146.9 ep len 200 avg score 17.4 avg_score_100 47.6 std score 36.3\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  286 score 137.5 ep len 200 avg score 17.8 avg_score_100 48.9 std score 37.0\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  287 score 134.4 ep len 200 avg score 18.2 avg_score_100 50.2 std score 37.5\n",
      "-----saving models------\n",
      "episode  288 score 140.0 ep len 200 avg score 18.6 avg_score_100 51.5 std score 38.1\n",
      "-----saving models------\n",
      "episode  289 score 145.3 ep len 200 avg score 19.1 avg_score_100 52.9 std score 38.8\n",
      "-----saving models------\n",
      "episode  290 score 139.7 ep len 200 avg score 19.5 avg_score_100 54.2 std score 39.4\n",
      "-----saving models------\n",
      "episode  291 score 68.4 ep len 130 avg score 19.6 avg_score_100 54.8 std score 39.4\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  292 score 143.7 ep len 200 avg score 20.1 avg_score_100 56.1 std score 40.0\n",
      "-----saving models------\n",
      "episode  293 score 147.5 ep len 200 avg score 20.5 avg_score_100 57.5 std score 40.6\n",
      "-----saving models------\n",
      "episode  294 score 59.2 ep len 90 avg score 20.6 avg_score_100 58.0 std score 40.6\n",
      "-----saving models------\n",
      "episode  295 score 148.1 ep len 200 avg score 21.1 avg_score_100 59.4 std score 41.2\n",
      "-----saving models------\n",
      "episode  296 score 140.2 ep len 200 avg score 21.5 avg_score_100 60.8 std score 41.7\n",
      "-----saving models------\n",
      "episode  297 score 145.8 ep len 200 avg score 21.9 avg_score_100 62.2 std score 42.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  298 score 154.6 ep len 200 avg score 22.3 avg_score_100 63.7 std score 42.9\n",
      "-----saving models------\n",
      "episode  299 score 135.2 ep len 200 avg score 22.7 avg_score_100 65.0 std score 43.3\n",
      "-----saving models------\n",
      "episode  300 score 144.0 ep len 200 avg score 23.1 avg_score_100 66.4 std score 43.8\n",
      "-----saving models------\n",
      "episode  301 score 141.5 ep len 200 avg score 23.5 avg_score_100 67.7 std score 44.2\n",
      "-----saving models------\n",
      "episode  302 score 143.4 ep len 200 avg score 23.9 avg_score_100 69.1 std score 44.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  303 score 150.7 ep len 200 avg score 24.3 avg_score_100 70.5 std score 45.2\n",
      "-----saving models------\n",
      "episode  304 score 148.8 ep len 200 avg score 24.7 avg_score_100 71.9 std score 45.7\n",
      "-----saving models------\n",
      "episode  305 score 97.0 ep len 135 avg score 24.9 avg_score_100 72.8 std score 45.8\n",
      "-----saving models------\n",
      "episode  306 score 150.6 ep len 200 avg score 25.4 avg_score_100 74.2 std score 46.3\n",
      "-----saving models------\n",
      "episode  307 score 8.9 ep len 13 avg score 25.3 avg_score_100 74.3 std score 46.2\n",
      "-----saving models------\n",
      "episode  308 score 24.8 ep len 43 avg score 25.3 avg_score_100 74.4 std score 46.1\n",
      "-----saving models------\n",
      "episode  309 score 139.2 ep len 200 avg score 25.7 avg_score_100 75.7 std score 46.5\n",
      "-----saving models------\n",
      "episode  310 score 7.6 ep len 15 avg score 25.6 avg_score_100 75.8 std score 46.5\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  311 score 131.1 ep len 200 avg score 25.9 avg_score_100 76.9 std score 46.8\n",
      "-----saving models------\n",
      "episode  312 score 154.5 ep len 200 avg score 26.4 avg_score_100 78.3 std score 47.2\n",
      "-----saving models------\n",
      "episode  313 score 160.9 ep len 200 avg score 26.8 avg_score_100 79.8 std score 47.8\n",
      "-----saving models------\n",
      "episode  314 score 148.6 ep len 200 avg score 27.2 avg_score_100 81.2 std score 48.2\n",
      "-----saving models------\n",
      "episode  315 score 156.3 ep len 200 avg score 27.6 avg_score_100 82.6 std score 48.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  316 score 139.1 ep len 200 avg score 27.9 avg_score_100 83.9 std score 49.0\n",
      "-----saving models------\n",
      "episode  317 score 144.8 ep len 200 avg score 28.3 avg_score_100 85.2 std score 49.3\n",
      "-----saving models------\n",
      "episode  318 score 33.0 ep len 40 avg score 28.3 avg_score_100 85.3 std score 49.3\n",
      "-----saving models------\n",
      "episode  319 score 9.0 ep len 24 avg score 28.3 avg_score_100 85.2 std score 49.2\n",
      "-----saving models------\n",
      "episode  320 score 13.5 ep len 20 avg score 28.2 avg_score_100 85.2 std score 49.1\n",
      "-----saving models------\n",
      "episode  321 score 110.9 ep len 141 avg score 28.5 avg_score_100 86.3 std score 49.3\n",
      "-----saving models------\n",
      "episode  322 score 14.1 ep len 19 avg score 28.4 avg_score_100 86.2 std score 49.2\n",
      "-----saving models------\n",
      "episode  323 score 140.5 ep len 200 avg score 28.8 avg_score_100 87.5 std score 49.5\n",
      "-----saving models------\n",
      "episode  324 score 51.6 ep len 83 avg score 28.8 avg_score_100 87.8 std score 49.5\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  325 score 143.5 ep len 200 avg score 29.2 avg_score_100 89.1 std score 49.8\n",
      "-----saving models------\n",
      "episode  326 score 121.1 ep len 200 avg score 29.5 avg_score_100 89.9 std score 50.0\n",
      "-----saving models------\n",
      "episode  327 score 151.8 ep len 200 avg score 29.8 avg_score_100 91.2 std score 50.3\n",
      "-----saving models------\n",
      "episode  328 score 143.0 ep len 200 avg score 30.2 avg_score_100 92.5 std score 50.6\n",
      "-----saving models------\n",
      "episode  329 score 152.1 ep len 200 avg score 30.6 avg_score_100 93.8 std score 51.0\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  330 score 144.5 ep len 200 avg score 30.9 avg_score_100 95.1 std score 51.3\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  331 score 82.1 ep len 114 avg score 31.1 avg_score_100 95.7 std score 51.3\n",
      "-----saving models------\n",
      "episode  332 score 158.0 ep len 200 avg score 31.4 avg_score_100 97.1 std score 51.7\n",
      "-----saving models------\n",
      "episode  333 score 149.3 ep len 200 avg score 31.8 avg_score_100 98.3 std score 52.0\n",
      "-----saving models------\n",
      "episode  334 score 154.0 ep len 200 avg score 32.2 avg_score_100 99.5 std score 52.4\n",
      "-----saving models------\n",
      "episode  335 score 158.1 ep len 200 avg score 32.5 avg_score_100 100.9 std score 52.8\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  336 score 151.4 ep len 200 avg score 32.9 avg_score_100 102.3 std score 53.1\n",
      "-----saving models------\n",
      "episode  337 score 151.9 ep len 200 avg score 33.2 avg_score_100 103.5 std score 53.4\n",
      "-----saving models------\n",
      "episode  338 score 74.3 ep len 104 avg score 33.4 avg_score_100 104.0 std score 53.4\n",
      "-----saving models------\n",
      "episode  339 score 159.4 ep len 200 avg score 33.7 avg_score_100 105.2 std score 53.7\n",
      "-----saving models------\n",
      "episode  340 score 148.0 ep len 200 avg score 34.1 avg_score_100 106.4 std score 54.0\n",
      "-----saving models------\n",
      "episode  341 score 107.3 ep len 200 avg score 34.3 avg_score_100 107.2 std score 54.0\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  342 score 162.2 ep len 200 avg score 34.6 avg_score_100 108.5 std score 54.4\n",
      "-----saving models------\n",
      "episode  343 score 155.7 ep len 200 avg score 35.0 avg_score_100 109.7 std score 54.7\n",
      "-----saving models------\n",
      "episode  344 score 34.5 ep len 43 avg score 35.0 avg_score_100 109.6 std score 54.6\n",
      "-----saving models------\n",
      "episode  345 score 146.8 ep len 200 avg score 35.3 avg_score_100 110.8 std score 54.9\n",
      "-----saving models------\n",
      "episode  346 score 146.2 ep len 200 avg score 35.6 avg_score_100 111.8 std score 55.1\n",
      "-----saving models------\n",
      "episode  347 score -1.3 ep len 18 avg score 35.5 avg_score_100 111.3 std score 55.1\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  348 score 160.0 ep len 200 avg score 35.9 avg_score_100 112.5 std score 55.4\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  349 score 3.8 ep len 7 avg score 35.8 avg_score_100 112.2 std score 55.4\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  350 score 153.0 ep len 200 avg score 36.1 avg_score_100 113.3 std score 55.6\n",
      "-----saving models------\n",
      "episode  351 score 134.7 ep len 200 avg score 36.4 avg_score_100 114.4 std score 55.8\n",
      "-----saving models------\n",
      "episode  352 score 92.8 ep len 126 avg score 36.6 avg_score_100 114.9 std score 55.8\n",
      "-----saving models------\n",
      "episode  353 score 130.4 ep len 185 avg score 36.8 avg_score_100 115.6 std score 55.9\n",
      "-----saving models------\n",
      "episode  354 score 128.1 ep len 200 avg score 37.1 avg_score_100 116.2 std score 56.1\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  355 score 137.3 ep len 200 avg score 37.4 avg_score_100 116.8 std score 56.2\n",
      "-----saving models------\n",
      "episode  356 score 152.1 ep len 200 avg score 37.7 avg_score_100 117.5 std score 56.5\n",
      "-----saving models------\n",
      "episode  357 score -0.3 ep len 14 avg score 37.6 avg_score_100 116.4 std score 56.5\n",
      "-----saving models------\n",
      "episode  358 score 154.0 ep len 200 avg score 37.9 avg_score_100 116.8 std score 56.7\n",
      "-----saving models------\n",
      "episode  359 score 130.1 ep len 200 avg score 38.2 avg_score_100 117.0 std score 56.8\n",
      "-----saving models------\n",
      "episode  360 score 16.6 ep len 20 avg score 38.1 avg_score_100 116.4 std score 56.8\n",
      "-----saving models------\n",
      "episode  361 score 12.2 ep len 17 avg score 38.0 avg_score_100 115.5 std score 56.7\n",
      "-----saving models------\n",
      "episode  362 score 4.4 ep len 16 avg score 38.0 avg_score_100 114.5 std score 56.7\n",
      "-----saving models------\n",
      "episode  363 score 144.3 ep len 200 avg score 38.2 avg_score_100 114.8 std score 56.8\n",
      "-----saving models------\n",
      "episode  364 score 1.8 ep len 12 avg score 38.1 avg_score_100 113.4 std score 56.8\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  365 score 136.2 ep len 200 avg score 38.4 avg_score_100 113.6 std score 57.0\n",
      "-----saving models------\n",
      "episode  366 score 148.0 ep len 200 avg score 38.7 avg_score_100 113.6 std score 57.2\n",
      "-----saving models------\n",
      "episode  367 score 139.6 ep len 200 avg score 39.0 avg_score_100 113.7 std score 57.3\n",
      "-----saving models------\n",
      "episode  368 score 143.7 ep len 200 avg score 39.3 avg_score_100 113.8 std score 57.5\n",
      "-----saving models------\n",
      "episode  369 score 153.4 ep len 200 avg score 39.6 avg_score_100 114.5 std score 57.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  370 score 97.1 ep len 148 avg score 39.7 avg_score_100 114.1 std score 57.7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/o/Documents/thesis/ddqn/main.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         done \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     agent\u001b[39m.\u001b[39mremember(state\u001b[39m=\u001b[39mobservation, action\u001b[39m=\u001b[39maction_index, done\u001b[39m=\u001b[39mdone,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                     reward\u001b[39m=\u001b[39mreward, new_state\u001b[39m=\u001b[39mnew_observation)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     agent\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     observation \u001b[39m=\u001b[39m new_observation\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m episode_lens\u001b[39m.\u001b[39mappend(episode_len)\n",
      "File \u001b[0;32m~/Documents/thesis/ddqn/ddqn.py:141\u001b[0m, in \u001b[0;36mDDQNAgent.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mset_priorities(sample_indices, error)\n\u001b[1;32m    140\u001b[0m \u001b[39m#* now we fit the main model (q_eval)\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_eval\u001b[39m.\u001b[39;49mfit(state, q_target, verbose \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m) \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m#* If counter reaches set value, update target network with weights of main network\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m#* it will update it at the very beginning also\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mmem_cntr \u001b[39m&\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplace_target \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/engine/training.py:1721\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cluster_coordinator \u001b[39m=\u001b[39m (\n\u001b[1;32m   1712\u001b[0m         tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mcoordinator\u001b[39m.\u001b[39mClusterCoordinator(\n\u001b[1;32m   1713\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\n\u001b[1;32m   1714\u001b[0m         )\n\u001b[1;32m   1715\u001b[0m     )\n\u001b[1;32m   1717\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mscope(), training_utils\u001b[39m.\u001b[39mRespectCompiledTrainableState(  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[1;32m   1718\u001b[0m     \u001b[39mself\u001b[39m\n\u001b[1;32m   1719\u001b[0m ):\n\u001b[1;32m   1720\u001b[0m     \u001b[39m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m-> 1721\u001b[0m     data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[1;32m   1722\u001b[0m         x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   1723\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   1724\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1725\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1726\u001b[0m         steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1727\u001b[0m         initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m   1728\u001b[0m         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   1729\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1730\u001b[0m         class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   1731\u001b[0m         max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1732\u001b[0m         workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1733\u001b[0m         use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1734\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1735\u001b[0m         steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[1;32m   1736\u001b[0m     )\n\u001b[1;32m   1738\u001b[0m     \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1687\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1688\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[1;32m   1291\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1292\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   1293\u001b[0m     x,\n\u001b[1;32m   1294\u001b[0m     y,\n\u001b[1;32m   1295\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1296\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1297\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[1;32m   1298\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1299\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1300\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1301\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1302\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1303\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[1;32m   1304\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1305\u001b[0m     pss_evaluation_shards\u001b[39m=\u001b[39;49mpss_evaluation_shards,\n\u001b[1;32m   1306\u001b[0m )\n\u001b[1;32m   1308\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   1310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:355\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[39mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m    353\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39mflat_map(slice_batch_indices)\n\u001b[0;32m--> 355\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mslice_inputs(indices_dataset, inputs)\n\u001b[1;32m    357\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    359\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mshuffle_batch\u001b[39m(\u001b[39m*\u001b[39mbatch):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:396\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.slice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgrab_batch\u001b[39m(i, data):\n\u001b[1;32m    392\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m    393\u001b[0m         \u001b[39mlambda\u001b[39;00m d: tf\u001b[39m.\u001b[39mgather(d, i, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), data\n\u001b[1;32m    394\u001b[0m     )\n\u001b[0;32m--> 396\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(grab_batch, num_parallel_calls\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mAUTOTUNE)\n\u001b[1;32m    398\u001b[0m \u001b[39m# Default optimizations are disabled to avoid the overhead of\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39m# (unnecessary) input pipeline graph serialization and deserialization\u001b[39;00m\n\u001b[1;32m    400\u001b[0m options \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mOptions()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2268\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2264\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2266\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2267\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2268\u001b[0m \u001b[39mreturn\u001b[39;00m map_op\u001b[39m.\u001b[39;49m_map_v2(\n\u001b[1;32m   2269\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2270\u001b[0m     map_func,\n\u001b[1;32m   2271\u001b[0m     num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls,\n\u001b[1;32m   2272\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m   2273\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:40\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[39mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m   \u001b[39mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[1;32m     43\u001b[0m       num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls,\n\u001b[1;32m     44\u001b[0m       deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:148\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[1;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m--> 148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[1;32m    149\u001b[0m     map_func,\n\u001b[1;32m    150\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[1;32m    151\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[1;32m    152\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deterministic \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[1;32m    266\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1222\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1221\u001b[0m   \u001b[39m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1222\u001b[0m   concrete \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1223\u001b[0m   concrete\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1192\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1191\u001b[0m     initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m-> 1192\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwargs, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m   1193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1195\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m   1196\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m   \u001b[39m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:694\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    690\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    691\u001b[0m     tracing_compilation\u001b[39m.\u001b[39mScopeType\u001b[39m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    692\u001b[0m )\n\u001b[1;32m    693\u001b[0m \u001b[39m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mtrace_function(\n\u001b[1;32m    695\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[1;32m    696\u001b[0m )\n\u001b[1;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    699\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[39m=\u001b[39m tracing_options\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[39m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    181\u001b[0m   _set_arg_keywords(concrete_function)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tracing_options\u001b[39m.\u001b[39mbind_graph_to_function:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:251\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    247\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete_function\n\u001b[1;32m    249\u001b[0m \u001b[39m# Use a timer for graph building only if not already inside a function. This\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# avoids double counting graph building time for nested functions.\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[39mwith\u001b[39;00m monitoring\u001b[39m.\u001b[39mMonitoredTimer(\n\u001b[1;32m    252\u001b[0m     _graph_building_time_counter\u001b[39m.\u001b[39mget_cell()\n\u001b[1;32m    253\u001b[0m ) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ops\u001b[39m.\u001b[39minside_function() \u001b[39melse\u001b[39;00m contextlib\u001b[39m.\u001b[39mnullcontext():\n\u001b[1;32m    254\u001b[0m   \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.function-graph_building\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    255\u001b[0m     logging\u001b[39m.\u001b[39mvlog(\n\u001b[1;32m    256\u001b[0m         \u001b[39m1\u001b[39m,\n\u001b[1;32m    257\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCreating new FuncGraph for Python function \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m (key: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m         lookup_func_type,\n\u001b[1;32m    261\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# main loop\n",
    "for episode in trange(500, desc='Test episodes'):\n",
    "\n",
    "        proc.reset()\n",
    "        (observation, info), done = env.reset(), False\n",
    "        truncated = False\n",
    "        proc.update_input(observation, info)\n",
    "        observation = proc.get_input()\n",
    "\n",
    "        episode_reward = 0\n",
    "        episode_len = 0\n",
    "\n",
    "        while (not done) and (not truncated):\n",
    "            \n",
    "            action, action_index = agent.get_action(observation, deterministic=False)\n",
    "            new_observation, reward, done, truncated, new_info = env.step(action=[action])\n",
    "            \n",
    "            proc.update_input(new_observation, info)\n",
    "            new_observation = proc.get_input()\n",
    "\n",
    "            episode_reward += reward # type: ignore\n",
    "            episode_len +=1\n",
    "\n",
    "            if new_info[\"rewards\"][\"on_road_reward\"] == False or episode_len >= 200:\n",
    "                done = True\n",
    "            \n",
    "            agent.remember(state=observation, action=action_index, done=done,\n",
    "                            reward=reward, new_state=new_observation)\n",
    "            agent.train()\n",
    "\n",
    "            observation = new_observation\n",
    "\n",
    "        episode_lens.append(episode_len)\n",
    "\n",
    "        score_history.append(episode_reward)\n",
    "        avg_score = np.mean(score_history)\n",
    "        avg_history.append(avg_score)\n",
    "        std_score = np.std(score_history)\n",
    "        std_history.append(std_score)\n",
    "\n",
    "        avg_score_100 = np.mean(score_history[-100:])\n",
    "        avg_history_100.append(avg_score_100)\n",
    "\n",
    "        if avg_score_100 > best_score:\n",
    "            best_score = avg_score\n",
    "            agent.save_model(episode)\n",
    "\n",
    "        agent.tensorboard.update_stats(episode_rew = episode_reward,\n",
    "                                       average_rew =avg_score,\n",
    "                                       average_100_reward = avg_score_100,\n",
    "                                       std_rew=std_score,\n",
    "                                       epsilon=agent.epsilon,\n",
    "                                       episode_len = episode_len)\n",
    "        \n",
    "        # #* save things in checkpoints\n",
    "        # if not episode % aggregate_stats_every or episode == 1:\n",
    "        #     average_reward = sum(score_history[-aggregate_stats_every:])/len(score_history[-aggregate_stats_every:])\n",
    "        #     min_reward = min(score_history[-aggregate_stats_every:])\n",
    "        #     max_reward = max(score_history[-aggregate_stats_every:])\n",
    "\n",
    "        #     agent.tensorboard_steps.update_stats(reward_avg_steps=average_reward, reward_min_steps=min_reward, reward_max_steps=max_reward, epsilon_steps=agent.epsilon)\n",
    "\n",
    "        print('episode ', episode, 'score %.1f' % episode_reward, 'ep len', episode_len,\n",
    "              'avg score %.1f' % avg_score, 'avg_score_100 %.1f' %avg_score_100,'std score %.1f' % std_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24663\n"
     ]
    }
   ],
   "source": [
    "n_steps = sum(episode_lens)\n",
    "print(n_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/o/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.configure to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.configure` for environment variables or `env.get_wrapper_attr('configure')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/o/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/o/Documents/thesis/ddqn/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2856703cccae44899001099d25b36a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test episodes:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  0 score 128.1 ep len 150\n",
      "episode  1 score 123.4 ep len 146\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/o/Documents/thesis/ddqn/main.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mwhile\u001b[39;00m (\u001b[39mnot\u001b[39;00m done) \u001b[39mor\u001b[39;00m truncated:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     action, action_index \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mget_action(observation, deterministic\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     new_observation, reward, done, truncated, new_info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action\u001b[39m=\u001b[39;49m[action])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     proc\u001b[39m.\u001b[39mupdate_input(new_observation, info)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     new_observation \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_input()\n",
      "File \u001b[0;32m~/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/wrappers/record_video.py:183\u001b[0m, in \u001b[0;36mRecordVideo.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecording:\n\u001b[1;32m    182\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvideo_recorder \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvideo_recorder\u001b[39m.\u001b[39;49mcapture_frame()\n\u001b[1;32m    184\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecorded_frames \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    185\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvideo_length \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/wrappers/monitoring/video_recorder.py:113\u001b[0m, in \u001b[0;36mVideoRecorder.capture_frame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcapture_frame\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    112\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Render the given `env` and add the resulting frame to the video.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     frame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender()\n\u001b[1;32m    114\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(frame, List):\n\u001b[1;32m    115\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_history \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m frame\n",
      "File \u001b[0;32m~/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py:70\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_disable_render_order_enforcing \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[1;32m     66\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\n\u001b[1;32m     67\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot call `env.render()` before calling `env.reset()`, if this is a intended action, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m     )\n\u001b[0;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py:67\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m env_render_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/thesis/.venv/lib/python3.10/site-packages/highway_env/envs/common/abstract.py:287\u001b[0m, in \u001b[0;36mAbstractEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mviewer \u001b[39m=\u001b[39m EnvViewer(\u001b[39mself\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menable_auto_render \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mviewer\u001b[39m.\u001b[39;49mdisplay()\n\u001b[1;32m    289\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mviewer\u001b[39m.\u001b[39moffscreen:\n\u001b[1;32m    290\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mviewer\u001b[39m.\u001b[39mhandle_events()\n",
      "File \u001b[0;32m~/Documents/thesis/.venv/lib/python3.10/site-packages/highway_env/envs/common/graphics.py:136\u001b[0m, in \u001b[0;36mEnvViewer.display\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscreen\u001b[39m.\u001b[39mblit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msim_surface, (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m))\n\u001b[1;32m    135\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mreal_time_rendering\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 136\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclock\u001b[39m.\u001b[39;49mtick(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39msimulation_frequency\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    137\u001b[0m     pygame\u001b[39m.\u001b[39mdisplay\u001b[39m.\u001b[39mflip()\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSAVE_IMAGES \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdirectory:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# env = record_videos(env)\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "data = load_config()\n",
    "env = gym.make('racetrack-v0', render_mode = 'rgb_array')\n",
    "env.configure(data) # type: ignore\n",
    "\n",
    "env = RecordVideo(env, video_folder=\"videos\", episode_trigger=lambda e: True)\n",
    "env.unwrapped.set_record_video_wrapper(env)\n",
    "\n",
    "# main loop\n",
    "for episode in trange(3, desc='Test episodes'):\n",
    "\n",
    "        proc.reset()\n",
    "        (observation, info), done = env.reset(), False\n",
    "        truncated = False\n",
    "        proc.update_input(observation, info)\n",
    "        observation = proc.get_input()\n",
    "\n",
    "        episode_reward = 0\n",
    "        episode_len = 0\n",
    "\n",
    "        while (not done) or truncated:\n",
    "            \n",
    "            action, action_index = agent.get_action(observation, deterministic=True)\n",
    "            new_observation, reward, done, truncated, new_info = env.step(action=[action])\n",
    "            \n",
    "            proc.update_input(new_observation, info)\n",
    "            new_observation = proc.get_input()\n",
    "\n",
    "            episode_reward += reward # type: ignore\n",
    "            episode_len +=1\n",
    "\n",
    "            if new_info[\"rewards\"][\"on_road_reward\"] == False or episode_len >=150:\n",
    "               done = True\n",
    "            \n",
    "            observation = new_observation\n",
    "\n",
    "        print('episode ', episode, 'score %.1f' % episode_reward, 'ep len', episode_len)   \n",
    "\n",
    "env.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
