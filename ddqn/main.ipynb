{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 14:42:30.920424: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-29 14:42:31.157877: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-29 14:42:31.157936: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-29 14:42:31.159164: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-29 14:42:31.266223: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# fundemental modules\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pprint\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from ddqn import DDQNAgent # type: ignore\n",
    "from utils import load_config\n",
    "from obs import observation_shape\n",
    "\n",
    "aggregate_stats_every=100\n",
    "best_score = -1000.0\n",
    "score_history = []\n",
    "episode_lens = []\n",
    "avg_history = []\n",
    "std_history = []\n",
    "avg_history_100 = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/o/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.configure to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.configure` for environment variables or `env.get_wrapper_attr('configure')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "data = load_config()\n",
    "env = gym.make('racetrack-v0', render_mode = 'rgb_array')\n",
    "env.configure(data) # type: ignore\n",
    "# pprint.pprint(env.config) # type: ignore\n",
    "(obs, info), done = env.reset(), False\n",
    "\n",
    "#observation config\n",
    "proc = observation_shape(obs,info,2)\n",
    "proc.reset()\n",
    "input = proc.get_input()\n",
    "print(input.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               6912      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 11)                2827      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 75531 (295.04 KB)\n",
      "Trainable params: 75531 (295.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "summary\n",
      "Agent is initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 14:42:52.078612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-29 14:42:52.199610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-29 14:42:52.200084: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-29 14:42:52.202174: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-29 14:42:52.202424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-29 14:42:52.202576: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-29 14:42:52.789649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-29 14:42:52.789742: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-29 14:42:52.789799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-29 14:42:52.789843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9748 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "agent = DDQNAgent(alpha=0.001, gamma=0.9, epsilon=1.0, obs_shape=input.shape,\n",
    "                  batch_size=512, epsilon_dec=0.9994, epsilon_end=0.05, mem_size=100000,\n",
    "                  min_mem_size=600, replace_target=1000, learning_rate=0.0003)\n",
    "print(\"Agent is initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9ab5d28a0a48d283727b09383a2076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test episodes:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----saving models------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 22:10:53.856275: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  0 score -1.3 ep len 16 avg score -1.3 avg_score_100 -1.3 std score 0.0\n",
      "-----saving models------\n",
      "episode  1 score -0.3 ep len 14 avg score -0.8 avg_score_100 -0.8 std score 0.5\n",
      "-----saving models------\n",
      "episode  2 score -0.3 ep len 3 avg score -0.6 avg_score_100 -0.6 std score 0.5\n",
      "episode  3 score -1.1 ep len 15 avg score -0.7 avg_score_100 -0.7 std score 0.5\n",
      "-----saving models------\n",
      "episode  4 score 1.7 ep len 31 avg score -0.2 avg_score_100 -0.2 std score 1.1\n",
      "episode  5 score -0.7 ep len 6 avg score -0.3 avg_score_100 -0.3 std score 1.0\n",
      "-----saving models------\n",
      "episode  6 score 0.7 ep len 8 avg score -0.2 avg_score_100 -0.2 std score 1.0\n",
      "-----saving models------\n",
      "episode  7 score 2.8 ep len 24 avg score 0.2 avg_score_100 0.2 std score 1.3\n",
      "-----saving models------\n",
      "episode  8 score 1.5 ep len 21 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "-----saving models------\n",
      "episode  9 score 0.9 ep len 9 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "-----saving models------\n",
      "episode  10 score 1.2 ep len 19 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "-----saving models------\n",
      "episode  11 score 0.9 ep len 8 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  12 score -0.7 ep len 12 avg score 0.4 avg_score_100 0.4 std score 1.2\n",
      "episode  13 score 1.3 ep len 8 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  14 score -0.4 ep len 8 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  15 score 0.3 ep len 10 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  16 score 0.2 ep len 6 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  17 score -0.6 ep len 6 avg score 0.3 avg_score_100 0.3 std score 1.1\n",
      "episode  18 score 0.9 ep len 12 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  19 score 1.1 ep len 12 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  20 score -0.3 ep len 2 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  21 score 0.4 ep len 4 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  22 score 1.9 ep len 23 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  23 score -0.0 ep len 17 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  24 score 0.0 ep len 9 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  25 score 2.0 ep len 19 avg score 0.5 avg_score_100 0.5 std score 1.0\n",
      "episode  26 score -1.2 ep len 7 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  27 score 0.6 ep len 5 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  28 score -1.0 ep len 11 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  29 score 0.5 ep len 9 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  30 score -0.2 ep len 3 avg score 0.3 avg_score_100 0.3 std score 1.0\n",
      "episode  31 score -0.2 ep len 10 avg score 0.3 avg_score_100 0.3 std score 1.0\n",
      "episode  32 score 1.3 ep len 24 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  33 score 2.4 ep len 14 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  34 score -0.5 ep len 3 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  35 score -0.7 ep len 8 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  36 score -1.0 ep len 35 avg score 0.3 avg_score_100 0.3 std score 1.0\n",
      "episode  37 score -0.6 ep len 8 avg score 0.3 avg_score_100 0.3 std score 1.0\n",
      "episode  38 score 1.3 ep len 4 avg score 0.3 avg_score_100 0.3 std score 1.0\n",
      "episode  39 score 1.1 ep len 6 avg score 0.3 avg_score_100 0.3 std score 1.0\n",
      "episode  40 score 0.5 ep len 8 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  41 score -0.4 ep len 11 avg score 0.3 avg_score_100 0.3 std score 1.0\n",
      "episode  42 score -1.6 ep len 18 avg score 0.3 avg_score_100 0.3 std score 1.0\n",
      "episode  43 score -2.0 ep len 25 avg score 0.2 avg_score_100 0.2 std score 1.1\n",
      "episode  44 score 1.1 ep len 8 avg score 0.3 avg_score_100 0.3 std score 1.1\n",
      "episode  45 score 1.4 ep len 25 avg score 0.3 avg_score_100 0.3 std score 1.1\n",
      "episode  46 score -3.8 ep len 30 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  47 score 0.5 ep len 5 avg score 0.2 avg_score_100 0.2 std score 1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 22:10:58.162330: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0ff82e4ea0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-28 22:10:58.162344: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-11-28 22:10:58.165284: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-28 22:10:59.081812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2023-11-28 22:10:59.135781: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  48 score -0.8 ep len 15 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  49 score -1.0 ep len 6 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  50 score 0.6 ep len 11 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  51 score -0.2 ep len 5 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  52 score -0.2 ep len 6 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  53 score -1.7 ep len 24 avg score 0.1 avg_score_100 0.1 std score 1.2\n",
      "episode  54 score 1.4 ep len 9 avg score 0.1 avg_score_100 0.1 std score 1.2\n",
      "episode  55 score 1.6 ep len 9 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  56 score 0.1 ep len 5 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  57 score 3.6 ep len 18 avg score 0.2 avg_score_100 0.2 std score 1.3\n",
      "episode  58 score 0.5 ep len 3 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  59 score 1.3 ep len 5 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  60 score -0.6 ep len 9 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  61 score -0.1 ep len 5 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  62 score 0.6 ep len 10 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  63 score 0.2 ep len 4 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  64 score -0.3 ep len 4 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  65 score -2.4 ep len 18 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  66 score 5.0 ep len 26 avg score 0.3 avg_score_100 0.3 std score 1.4\n",
      "episode  67 score 0.5 ep len 5 avg score 0.3 avg_score_100 0.3 std score 1.4\n",
      "episode  68 score -0.4 ep len 8 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  69 score 1.7 ep len 9 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  70 score 1.2 ep len 4 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  71 score -0.0 ep len 12 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  72 score 1.0 ep len 14 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  73 score -0.4 ep len 7 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  74 score 2.8 ep len 11 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  75 score 0.9 ep len 6 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  76 score 1.2 ep len 12 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  77 score 0.2 ep len 6 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  78 score 2.7 ep len 7 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  79 score -1.1 ep len 20 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  80 score -0.5 ep len 8 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  81 score 0.0 ep len 4 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  82 score 1.0 ep len 13 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  83 score -0.0 ep len 15 avg score 0.3 avg_score_100 0.3 std score 1.3\n",
      "episode  84 score 2.0 ep len 26 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  85 score 1.2 ep len 28 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "episode  86 score 3.0 ep len 30 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "episode  87 score -0.5 ep len 6 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "episode  88 score 1.0 ep len 5 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  89 score 0.1 ep len 10 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  90 score 0.6 ep len 11 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  91 score -0.2 ep len 6 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  92 score -0.6 ep len 6 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  93 score 2.5 ep len 22 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  94 score -1.0 ep len 11 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  95 score 0.3 ep len 4 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  96 score 1.9 ep len 16 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  97 score 1.3 ep len 6 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  98 score -0.1 ep len 17 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  99 score -0.8 ep len 15 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  100 score 4.3 ep len 11 avg score 0.4 avg_score_100 0.4 std score 1.3\n",
      "episode  101 score 2.6 ep len 12 avg score 0.5 avg_score_100 0.5 std score 1.4\n",
      "episode  102 score -0.3 ep len 5 avg score 0.4 avg_score_100 0.5 std score 1.4\n",
      "episode  103 score -1.8 ep len 24 avg score 0.4 avg_score_100 0.5 std score 1.4\n",
      "episode  104 score 1.6 ep len 20 avg score 0.4 avg_score_100 0.5 std score 1.4\n",
      "episode  105 score -0.4 ep len 3 avg score 0.4 avg_score_100 0.5 std score 1.4\n",
      "episode  106 score 1.3 ep len 8 avg score 0.4 avg_score_100 0.5 std score 1.4\n",
      "episode  107 score 2.5 ep len 8 avg score 0.5 avg_score_100 0.5 std score 1.4\n",
      "episode  108 score 2.1 ep len 29 avg score 0.5 avg_score_100 0.5 std score 1.4\n",
      "episode  109 score 1.5 ep len 11 avg score 0.5 avg_score_100 0.5 std score 1.4\n",
      "episode  110 score 1.6 ep len 24 avg score 0.5 avg_score_100 0.5 std score 1.4\n",
      "episode  111 score 0.2 ep len 9 avg score 0.5 avg_score_100 0.5 std score 1.4\n",
      "-----saving models------\n",
      "episode  112 score 5.8 ep len 21 avg score 0.5 avg_score_100 0.5 std score 1.4\n",
      "episode  113 score -0.4 ep len 4 avg score 0.5 avg_score_100 0.5 std score 1.4\n",
      "-----saving models------\n",
      "episode  114 score 1.6 ep len 15 avg score 0.5 avg_score_100 0.5 std score 1.4\n",
      "-----saving models------\n",
      "episode  115 score 0.4 ep len 19 avg score 0.5 avg_score_100 0.5 std score 1.4\n",
      "-----saving models------\n",
      "episode  116 score 2.4 ep len 18 avg score 0.5 avg_score_100 0.6 std score 1.4\n",
      "-----saving models------\n",
      "episode  117 score 2.3 ep len 6 avg score 0.6 avg_score_100 0.6 std score 1.4\n",
      "-----saving models------\n",
      "episode  118 score 7.5 ep len 60 avg score 0.6 avg_score_100 0.7 std score 1.6\n",
      "-----saving models------\n",
      "episode  119 score 0.8 ep len 7 avg score 0.6 avg_score_100 0.7 std score 1.6\n",
      "-----saving models------\n",
      "episode  120 score 1.8 ep len 23 avg score 0.6 avg_score_100 0.7 std score 1.6\n",
      "-----saving models------\n",
      "episode  121 score 3.0 ep len 16 avg score 0.6 avg_score_100 0.7 std score 1.6\n",
      "-----saving models------\n",
      "episode  122 score 2.3 ep len 10 avg score 0.7 avg_score_100 0.7 std score 1.6\n",
      "-----saving models------\n",
      "episode  123 score 2.8 ep len 15 avg score 0.7 avg_score_100 0.7 std score 1.6\n",
      "-----saving models------\n",
      "episode  124 score -0.2 ep len 5 avg score 0.7 avg_score_100 0.7 std score 1.6\n",
      "-----saving models------\n",
      "episode  125 score 2.2 ep len 20 avg score 0.7 avg_score_100 0.7 std score 1.6\n",
      "-----saving models------\n",
      "episode  126 score 4.7 ep len 21 avg score 0.7 avg_score_100 0.8 std score 1.6\n",
      "-----saving models------\n",
      "episode  127 score 4.1 ep len 12 avg score 0.7 avg_score_100 0.8 std score 1.6\n",
      "-----saving models------\n",
      "episode  128 score 2.6 ep len 38 avg score 0.8 avg_score_100 0.9 std score 1.6\n",
      "-----saving models------\n",
      "episode  129 score 0.7 ep len 6 avg score 0.8 avg_score_100 0.9 std score 1.6\n",
      "-----saving models------\n",
      "episode  130 score 8.1 ep len 25 avg score 0.8 avg_score_100 1.0 std score 1.7\n",
      "-----saving models------\n",
      "episode  131 score 1.6 ep len 25 avg score 0.8 avg_score_100 1.0 std score 1.7\n",
      "-----saving models------\n",
      "episode  132 score -0.4 ep len 8 avg score 0.8 avg_score_100 1.0 std score 1.7\n",
      "-----saving models------\n",
      "episode  133 score 0.1 ep len 9 avg score 0.8 avg_score_100 0.9 std score 1.7\n",
      "-----saving models------\n",
      "episode  134 score 0.7 ep len 8 avg score 0.8 avg_score_100 0.9 std score 1.7\n",
      "-----saving models------\n",
      "episode  135 score 1.5 ep len 8 avg score 0.8 avg_score_100 1.0 std score 1.7\n",
      "-----saving models------\n",
      "episode  136 score 2.3 ep len 20 avg score 0.8 avg_score_100 1.0 std score 1.7\n",
      "-----saving models------\n",
      "episode  137 score 0.4 ep len 8 avg score 0.8 avg_score_100 1.0 std score 1.7\n",
      "-----saving models------\n",
      "episode  138 score 5.2 ep len 13 avg score 0.8 avg_score_100 1.1 std score 1.7\n",
      "-----saving models------\n",
      "episode  139 score 6.0 ep len 15 avg score 0.9 avg_score_100 1.1 std score 1.8\n",
      "-----saving models------\n",
      "episode  140 score 5.5 ep len 25 avg score 0.9 avg_score_100 1.2 std score 1.8\n",
      "-----saving models------\n",
      "episode  141 score 1.1 ep len 6 avg score 0.9 avg_score_100 1.2 std score 1.8\n",
      "-----saving models------\n",
      "episode  142 score 3.4 ep len 16 avg score 0.9 avg_score_100 1.2 std score 1.8\n",
      "-----saving models------\n",
      "episode  143 score 0.4 ep len 8 avg score 0.9 avg_score_100 1.2 std score 1.8\n",
      "-----saving models------\n",
      "episode  144 score 1.1 ep len 9 avg score 0.9 avg_score_100 1.2 std score 1.8\n",
      "-----saving models------\n",
      "episode  145 score 13.0 ep len 33 avg score 1.0 avg_score_100 1.4 std score 2.1\n",
      "-----saving models------\n",
      "episode  146 score 3.5 ep len 18 avg score 1.0 avg_score_100 1.4 std score 2.1\n",
      "-----saving models------\n",
      "episode  147 score 5.0 ep len 8 avg score 1.1 avg_score_100 1.5 std score 2.1\n",
      "-----saving models------\n",
      "episode  148 score 3.2 ep len 16 avg score 1.1 avg_score_100 1.5 std score 2.1\n",
      "-----saving models------\n",
      "episode  149 score 1.9 ep len 34 avg score 1.1 avg_score_100 1.5 std score 2.1\n",
      "-----saving models------\n",
      "episode  150 score 9.2 ep len 24 avg score 1.1 avg_score_100 1.6 std score 2.2\n",
      "-----saving models------\n",
      "episode  151 score 0.9 ep len 11 avg score 1.1 avg_score_100 1.6 std score 2.2\n",
      "-----saving models------\n",
      "episode  152 score 6.8 ep len 11 avg score 1.2 avg_score_100 1.7 std score 2.2\n",
      "-----saving models------\n",
      "episode  153 score 4.4 ep len 8 avg score 1.2 avg_score_100 1.8 std score 2.2\n",
      "-----saving models------\n",
      "episode  154 score 6.1 ep len 15 avg score 1.2 avg_score_100 1.8 std score 2.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  155 score 6.6 ep len 21 avg score 1.3 avg_score_100 1.9 std score 2.3\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  156 score 5.2 ep len 24 avg score 1.3 avg_score_100 1.9 std score 2.3\n",
      "-----saving models------\n",
      "episode  157 score 10.6 ep len 38 avg score 1.3 avg_score_100 2.0 std score 2.4\n",
      "-----saving models------\n",
      "episode  158 score 3.7 ep len 15 avg score 1.4 avg_score_100 2.0 std score 2.4\n",
      "-----saving models------\n",
      "episode  159 score 6.3 ep len 20 avg score 1.4 avg_score_100 2.1 std score 2.4\n",
      "-----saving models------\n",
      "episode  160 score 12.9 ep len 18 avg score 1.5 avg_score_100 2.2 std score 2.6\n",
      "-----saving models------\n",
      "episode  161 score 15.9 ep len 34 avg score 1.5 avg_score_100 2.4 std score 2.8\n",
      "-----saving models------\n",
      "episode  162 score 14.1 ep len 29 avg score 1.6 avg_score_100 2.5 std score 3.0\n",
      "-----saving models------\n",
      "episode  163 score 8.7 ep len 20 avg score 1.7 avg_score_100 2.6 std score 3.0\n",
      "-----saving models------\n",
      "episode  164 score 13.1 ep len 41 avg score 1.7 avg_score_100 2.7 std score 3.1\n",
      "-----saving models------\n",
      "episode  165 score 12.6 ep len 28 avg score 1.8 avg_score_100 2.9 std score 3.2\n",
      "-----saving models------\n",
      "episode  166 score 12.5 ep len 28 avg score 1.9 avg_score_100 2.9 std score 3.3\n",
      "-----saving models------\n",
      "episode  167 score 11.7 ep len 53 avg score 1.9 avg_score_100 3.1 std score 3.4\n",
      "-----saving models------\n",
      "episode  168 score 14.0 ep len 34 avg score 2.0 avg_score_100 3.2 std score 3.5\n",
      "-----saving models------\n",
      "episode  169 score 11.7 ep len 21 avg score 2.1 avg_score_100 3.3 std score 3.6\n",
      "-----saving models------\n",
      "episode  170 score 5.9 ep len 23 avg score 2.1 avg_score_100 3.3 std score 3.6\n",
      "-----saving models------\n",
      "episode  171 score 19.0 ep len 37 avg score 2.2 avg_score_100 3.5 std score 3.8\n",
      "-----saving models------\n",
      "episode  172 score 9.8 ep len 18 avg score 2.2 avg_score_100 3.6 std score 3.8\n",
      "-----saving models------\n",
      "episode  173 score 10.8 ep len 24 avg score 2.3 avg_score_100 3.7 std score 3.9\n",
      "-----saving models------\n",
      "episode  174 score 13.7 ep len 38 avg score 2.3 avg_score_100 3.8 std score 4.0\n",
      "-----saving models------\n",
      "episode  175 score 7.2 ep len 13 avg score 2.4 avg_score_100 3.9 std score 4.0\n",
      "-----saving models------\n",
      "episode  176 score 6.8 ep len 19 avg score 2.4 avg_score_100 4.0 std score 4.0\n",
      "-----saving models------\n",
      "episode  177 score 10.9 ep len 16 avg score 2.4 avg_score_100 4.1 std score 4.0\n",
      "-----saving models------\n",
      "episode  178 score 13.4 ep len 48 avg score 2.5 avg_score_100 4.2 std score 4.1\n",
      "-----saving models------\n",
      "episode  179 score -0.3 ep len 3 avg score 2.5 avg_score_100 4.2 std score 4.1\n",
      "-----saving models------\n",
      "episode  180 score 23.3 ep len 58 avg score 2.6 avg_score_100 4.4 std score 4.3\n",
      "-----saving models------\n",
      "episode  181 score 18.2 ep len 27 avg score 2.7 avg_score_100 4.6 std score 4.5\n",
      "-----saving models------\n",
      "episode  182 score 24.2 ep len 54 avg score 2.8 avg_score_100 4.8 std score 4.7\n",
      "-----saving models------\n",
      "episode  183 score 25.3 ep len 50 avg score 2.9 avg_score_100 5.1 std score 5.0\n",
      "-----saving models------\n",
      "episode  184 score 13.2 ep len 28 avg score 3.0 avg_score_100 5.2 std score 5.1\n",
      "-----saving models------\n",
      "episode  185 score 33.2 ep len 83 avg score 3.1 avg_score_100 5.5 std score 5.5\n",
      "-----saving models------\n",
      "episode  186 score 23.8 ep len 52 avg score 3.3 avg_score_100 5.7 std score 5.7\n",
      "-----saving models------\n",
      "episode  187 score 6.6 ep len 12 avg score 3.3 avg_score_100 5.8 std score 5.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  188 score 32.2 ep len 64 avg score 3.4 avg_score_100 6.1 std score 6.0\n",
      "-----saving models------\n",
      "episode  189 score 19.8 ep len 35 avg score 3.5 avg_score_100 6.3 std score 6.1\n",
      "-----saving models------\n",
      "episode  190 score 35.4 ep len 75 avg score 3.7 avg_score_100 6.7 std score 6.5\n",
      "-----saving models------\n",
      "episode  191 score 25.3 ep len 43 avg score 3.8 avg_score_100 6.9 std score 6.7\n",
      "-----saving models------\n",
      "episode  192 score 29.3 ep len 59 avg score 3.9 avg_score_100 7.2 std score 6.9\n",
      "-----saving models------\n",
      "episode  193 score 24.3 ep len 54 avg score 4.0 avg_score_100 7.4 std score 7.1\n",
      "-----saving models------\n",
      "episode  194 score 31.4 ep len 67 avg score 4.2 avg_score_100 7.8 std score 7.3\n",
      "-----saving models------\n",
      "episode  195 score 46.7 ep len 95 avg score 4.4 avg_score_100 8.2 std score 7.9\n",
      "-----saving models------\n",
      "episode  196 score 47.2 ep len 118 avg score 4.6 avg_score_100 8.7 std score 8.5\n",
      "-----saving models------\n",
      "episode  197 score 38.7 ep len 78 avg score 4.8 avg_score_100 9.0 std score 8.8\n",
      "-----saving models------\n",
      "episode  198 score 41.0 ep len 57 avg score 5.0 avg_score_100 9.5 std score 9.1\n",
      "-----saving models------\n",
      "episode  199 score 28.8 ep len 42 avg score 5.1 avg_score_100 9.8 std score 9.2\n",
      "-----saving models------\n",
      "episode  200 score 28.2 ep len 51 avg score 5.2 avg_score_100 10.0 std score 9.4\n",
      "-----saving models------\n",
      "episode  201 score 12.7 ep len 19 avg score 5.2 avg_score_100 10.1 std score 9.4\n",
      "-----saving models------\n",
      "episode  202 score 67.3 ep len 104 avg score 5.5 avg_score_100 10.8 std score 10.3\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  203 score 75.2 ep len 232 avg score 5.9 avg_score_100 11.5 std score 11.4\n",
      "-----saving models------\n",
      "episode  204 score 45.6 ep len 86 avg score 6.1 avg_score_100 12.0 std score 11.7\n",
      "-----saving models------\n",
      "episode  205 score 96.4 ep len 156 avg score 6.5 avg_score_100 13.0 std score 13.2\n",
      "-----saving models------\n",
      "episode  206 score 91.9 ep len 210 avg score 6.9 avg_score_100 13.9 std score 14.5\n",
      "-----saving models------\n",
      "episode  207 score 101.1 ep len 216 avg score 7.4 avg_score_100 14.8 std score 15.8\n",
      "-----saving models------\n",
      "episode  208 score 58.6 ep len 90 avg score 7.6 avg_score_100 15.4 std score 16.2\n",
      "-----saving models------\n",
      "episode  209 score 53.6 ep len 84 avg score 7.8 avg_score_100 15.9 std score 16.5\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  210 score 28.2 ep len 37 avg score 7.9 avg_score_100 16.2 std score 16.5\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  211 score 92.9 ep len 175 avg score 8.3 avg_score_100 17.1 std score 17.4\n",
      "-----saving models------\n",
      "episode  212 score 123.3 ep len 278 avg score 8.9 avg_score_100 18.3 std score 19.1\n",
      "-----saving models------\n",
      "episode  213 score 91.8 ep len 170 avg score 9.3 avg_score_100 19.2 std score 19.9\n",
      "-----saving models------\n",
      "episode  214 score 104.6 ep len 165 avg score 9.7 avg_score_100 20.2 std score 20.9\n",
      "-----saving models------\n",
      "episode  215 score 49.1 ep len 73 avg score 9.9 avg_score_100 20.7 std score 21.0\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  216 score 150.2 ep len 290 avg score 10.5 avg_score_100 22.2 std score 23.0\n",
      "-----saving models------\n",
      "episode  217 score 135.3 ep len 269 avg score 11.1 avg_score_100 23.5 std score 24.4\n",
      "-----saving models------\n",
      "episode  218 score 113.3 ep len 176 avg score 11.6 avg_score_100 24.6 std score 25.3\n",
      "-----saving models------\n",
      "episode  219 score 131.7 ep len 225 avg score 12.1 avg_score_100 25.9 std score 26.5\n",
      "-----saving models------\n",
      "episode  220 score 83.8 ep len 174 avg score 12.4 avg_score_100 26.7 std score 26.9\n",
      "-----saving models------\n",
      "episode  221 score 23.7 ep len 29 avg score 12.5 avg_score_100 26.9 std score 26.9\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  222 score 131.0 ep len 246 avg score 13.0 avg_score_100 28.2 std score 27.9\n",
      "-----saving models------\n",
      "episode  223 score 168.6 ep len 253 avg score 13.7 avg_score_100 29.9 std score 29.7\n",
      "-----saving models------\n",
      "episode  224 score 142.2 ep len 281 avg score 14.3 avg_score_100 31.3 std score 30.9\n",
      "-----saving models------\n",
      "episode  225 score 35.5 ep len 57 avg score 14.4 avg_score_100 31.6 std score 30.8\n",
      "-----saving models------\n",
      "episode  226 score 106.5 ep len 145 avg score 14.8 avg_score_100 32.7 std score 31.4\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  227 score 200.3 ep len 462 avg score 15.6 avg_score_100 34.6 std score 33.6\n",
      "-----saving models------\n",
      "episode  228 score 222.5 ep len 442 avg score 16.5 avg_score_100 36.8 std score 36.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  229 score 282.3 ep len 463 avg score 17.7 avg_score_100 39.6 std score 40.1\n",
      "-----saving models------\n",
      "episode  230 score 107.5 ep len 163 avg score 18.0 avg_score_100 40.6 std score 40.5\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  231 score 421.5 ep len 805 avg score 19.8 avg_score_100 44.8 std score 48.3\n",
      "-----saving models------\n",
      "episode  232 score 130.3 ep len 241 avg score 20.3 avg_score_100 46.1 std score 48.7\n",
      "-----saving models------\n",
      "episode  233 score 29.4 ep len 37 avg score 20.3 avg_score_100 46.4 std score 48.6\n",
      "-----saving models------\n",
      "episode  234 score 101.4 ep len 145 avg score 20.6 avg_score_100 47.4 std score 48.8\n",
      "-----saving models------\n",
      "episode  235 score 18.3 ep len 25 avg score 20.6 avg_score_100 47.6 std score 48.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  236 score 336.3 ep len 518 avg score 22.0 avg_score_100 50.9 std score 52.7\n",
      "-----saving models------\n",
      "episode  237 score 8.6 ep len 17 avg score 21.9 avg_score_100 51.0 std score 52.6\n",
      "-----saving models------\n",
      "episode  238 score 110.2 ep len 153 avg score 22.3 avg_score_100 52.1 std score 52.8\n",
      "-----saving models------\n",
      "episode  239 score 58.1 ep len 87 avg score 22.4 avg_score_100 52.6 std score 52.8\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  240 score 439.3 ep len 633 avg score 24.2 avg_score_100 56.9 std score 59.1\n",
      "-----saving models------\n",
      "episode  241 score 305.3 ep len 428 avg score 25.3 avg_score_100 60.0 std score 61.7\n",
      "-----saving models------\n",
      "episode  242 score 41.7 ep len 55 avg score 25.4 avg_score_100 60.4 std score 61.5\n",
      "-----saving models------\n",
      "episode  243 score 149.4 ep len 234 avg score 25.9 avg_score_100 61.8 std score 61.9\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  244 score 743.9 ep len 1142 avg score 28.8 avg_score_100 69.3 std score 76.9\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  245 score 930.5 ep len 1361 avg score 32.5 avg_score_100 78.4 std score 95.8\n",
      "-----saving models------\n",
      "episode  246 score 18.3 ep len 36 avg score 32.4 avg_score_100 78.6 std score 95.6\n",
      "-----saving models------\n",
      "episode  247 score 31.2 ep len 40 avg score 32.4 avg_score_100 78.9 std score 95.4\n",
      "-----saving models------\n",
      "episode  248 score 7.3 ep len 31 avg score 32.3 avg_score_100 78.9 std score 95.3\n",
      "-----saving models------\n",
      "episode  249 score 23.2 ep len 48 avg score 32.3 avg_score_100 79.1 std score 95.1\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  250 score 681.8 ep len 921 avg score 34.9 avg_score_100 85.8 std score 103.3\n",
      "-----saving models------\n",
      "episode  251 score 100.7 ep len 137 avg score 35.1 avg_score_100 86.8 std score 103.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  252 score 968.9 ep len 1326 avg score 38.8 avg_score_100 96.5 std score 118.5\n",
      "-----saving models------\n",
      "episode  253 score 25.3 ep len 44 avg score 38.8 avg_score_100 96.7 std score 118.3\n",
      "-----saving models------\n",
      "episode  254 score 24.1 ep len 39 avg score 38.7 avg_score_100 96.8 std score 118.0\n",
      "-----saving models------\n",
      "episode  255 score 116.8 ep len 160 avg score 39.0 avg_score_100 97.9 std score 117.9\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  256 score 730.5 ep len 961 avg score 41.7 avg_score_100 105.2 std score 125.3\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/o/Documents/thesis/ddqn/main.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         done \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     agent\u001b[39m.\u001b[39mremember(state\u001b[39m=\u001b[39mobservation, action\u001b[39m=\u001b[39maction_index, done\u001b[39m=\u001b[39mdone,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                     reward\u001b[39m=\u001b[39mreward, new_state\u001b[39m=\u001b[39mnew_observation)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     agent\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     observation \u001b[39m=\u001b[39m new_observation\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m episode_lens\u001b[39m.\u001b[39mappend(episode_len)\n",
      "File \u001b[0;32m~/Documents/thesis/ddqn/ddqn.py:141\u001b[0m, in \u001b[0;36mDDQNAgent.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mset_priorities(sample_indices, error)\n\u001b[1;32m    140\u001b[0m \u001b[39m#* now we fit the main model (q_eval)\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_eval\u001b[39m.\u001b[39;49mfit(state, q_target, verbose \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m) \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m#* If counter reaches set value, update target network with weights of main network\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m#* it will update it at the very beginning also\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mmem_cntr \u001b[39m&\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplace_target \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/engine/training.py:1721\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cluster_coordinator \u001b[39m=\u001b[39m (\n\u001b[1;32m   1712\u001b[0m         tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mcoordinator\u001b[39m.\u001b[39mClusterCoordinator(\n\u001b[1;32m   1713\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\n\u001b[1;32m   1714\u001b[0m         )\n\u001b[1;32m   1715\u001b[0m     )\n\u001b[1;32m   1717\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mscope(), training_utils\u001b[39m.\u001b[39mRespectCompiledTrainableState(  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[1;32m   1718\u001b[0m     \u001b[39mself\u001b[39m\n\u001b[1;32m   1719\u001b[0m ):\n\u001b[1;32m   1720\u001b[0m     \u001b[39m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m-> 1721\u001b[0m     data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[1;32m   1722\u001b[0m         x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   1723\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   1724\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1725\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1726\u001b[0m         steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1727\u001b[0m         initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m   1728\u001b[0m         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   1729\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1730\u001b[0m         class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   1731\u001b[0m         max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1732\u001b[0m         workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1733\u001b[0m         use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1734\u001b[0m         model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1735\u001b[0m         steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[1;32m   1736\u001b[0m     )\n\u001b[1;32m   1738\u001b[0m     \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1687\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1688\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[1;32m   1291\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1292\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   1293\u001b[0m     x,\n\u001b[1;32m   1294\u001b[0m     y,\n\u001b[1;32m   1295\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1296\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1297\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[1;32m   1298\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1299\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1300\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1301\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1302\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1303\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[1;32m   1304\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1305\u001b[0m     pss_evaluation_shards\u001b[39m=\u001b[39;49mpss_evaluation_shards,\n\u001b[1;32m   1306\u001b[0m )\n\u001b[1;32m   1308\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   1310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:355\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[39mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m    353\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39mflat_map(slice_batch_indices)\n\u001b[0;32m--> 355\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mslice_inputs(indices_dataset, inputs)\n\u001b[1;32m    357\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    359\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mshuffle_batch\u001b[39m(\u001b[39m*\u001b[39mbatch):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:396\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.slice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgrab_batch\u001b[39m(i, data):\n\u001b[1;32m    392\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m    393\u001b[0m         \u001b[39mlambda\u001b[39;00m d: tf\u001b[39m.\u001b[39mgather(d, i, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), data\n\u001b[1;32m    394\u001b[0m     )\n\u001b[0;32m--> 396\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(grab_batch, num_parallel_calls\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mAUTOTUNE)\n\u001b[1;32m    398\u001b[0m \u001b[39m# Default optimizations are disabled to avoid the overhead of\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39m# (unnecessary) input pipeline graph serialization and deserialization\u001b[39;00m\n\u001b[1;32m    400\u001b[0m options \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mOptions()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2268\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2264\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2266\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2267\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2268\u001b[0m \u001b[39mreturn\u001b[39;00m map_op\u001b[39m.\u001b[39;49m_map_v2(\n\u001b[1;32m   2269\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2270\u001b[0m     map_func,\n\u001b[1;32m   2271\u001b[0m     num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls,\n\u001b[1;32m   2272\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m   2273\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:40\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[39mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m   \u001b[39mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[1;32m     43\u001b[0m       num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls,\n\u001b[1;32m     44\u001b[0m       deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:148\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[1;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m--> 148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[1;32m    149\u001b[0m     map_func,\n\u001b[1;32m    150\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[1;32m    151\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[1;32m    152\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_deterministic \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[1;32m    266\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1222\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1221\u001b[0m   \u001b[39m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1222\u001b[0m   concrete \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1223\u001b[0m   concrete\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1192\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1191\u001b[0m     initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m-> 1192\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwargs, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[1;32m   1193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1195\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m   1196\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m   \u001b[39m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:694\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    690\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    691\u001b[0m     tracing_compilation\u001b[39m.\u001b[39mScopeType\u001b[39m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    692\u001b[0m )\n\u001b[1;32m    693\u001b[0m \u001b[39m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mtrace_function(\n\u001b[1;32m    695\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[1;32m    696\u001b[0m )\n\u001b[1;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    699\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[39m=\u001b[39m tracing_options\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[39m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    181\u001b[0m   _set_arg_keywords(concrete_function)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tracing_options\u001b[39m.\u001b[39mbind_graph_to_function:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:284\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m   target_func_type \u001b[39m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 284\u001b[0m concrete_function \u001b[39m=\u001b[39m _create_concrete_function(\n\u001b[1;32m    285\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[1;32m    286\u001b[0m )\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m tracing_options\u001b[39m.\u001b[39mfunction_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    289\u001b[0m   tracing_options\u001b[39m.\u001b[39mfunction_cache\u001b[39m.\u001b[39madd(\n\u001b[1;32m    290\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    291\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:308\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mwith\u001b[39;00m func_graph\u001b[39m.\u001b[39mas_default():\n\u001b[1;32m    304\u001b[0m   placeholder_bound_args \u001b[39m=\u001b[39m function_type\u001b[39m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    305\u001b[0m       placeholder_context\n\u001b[1;32m    306\u001b[0m   )\n\u001b[0;32m--> 308\u001b[0m traced_func_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    309\u001b[0m     tracing_options\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    310\u001b[0m     tracing_options\u001b[39m.\u001b[39;49mpython_function,\n\u001b[1;32m    311\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39;49margs,\n\u001b[1;32m    312\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39;49mkwargs,\n\u001b[1;32m    313\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    314\u001b[0m     func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[1;32m    315\u001b[0m     arg_names\u001b[39m=\u001b[39;49mfunction_type_utils\u001b[39m.\u001b[39;49mto_arg_names(function_type),\n\u001b[1;32m    316\u001b[0m     create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    317\u001b[0m )\n\u001b[1;32m    319\u001b[0m transform\u001b[39m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    321\u001b[0m graph_capture_container \u001b[39m=\u001b[39m traced_func_graph\u001b[39m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[1;32m   1061\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:597\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    594\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 597\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    598\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    232\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39mnested_args)\n\u001b[1;32m    162\u001b[0m ret \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:583\u001b[0m, in \u001b[0;36mtf_convert\u001b[0;34m(f, ctx, convert_by_default, user_requested)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mThis switch contains all possible cases!\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 583\u001b[0m wrapper \u001b[39m=\u001b[39m wrapper_factory(f)\n\u001b[1;32m    585\u001b[0m \u001b[39mif\u001b[39;00m decorators:\n\u001b[1;32m    586\u001b[0m   wrapper \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39mrewrap(f_wrapper, f, wrapper)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:700\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misfunction(f) \u001b[39mor\u001b[39;00m inspect\u001b[39m.\u001b[39mismethod(f):\n\u001b[1;32m    698\u001b[0m   wrapper \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mupdate_wrapper(wrapper, f)\n\u001b[0;32m--> 700\u001b[0m decorated_wrapper \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39;49mmake_decorator(f, wrapper)\n\u001b[1;32m    701\u001b[0m \u001b[39mreturn\u001b[39;00m autograph_artifact(decorated_wrapper)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/util/tf_decorator.py:136\u001b[0m, in \u001b[0;36mmake_decorator\u001b[0;34m(target, decorator_func, decorator_name, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m decorator_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m   decorator_name \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mcurrentframe()\u001b[39m.\u001b[39mf_back\u001b[39m.\u001b[39mf_code\u001b[39m.\u001b[39mco_name\n\u001b[0;32m--> 136\u001b[0m decorator \u001b[39m=\u001b[39m TFDecorator(decorator_name, target, decorator_doc,\n\u001b[1;32m    137\u001b[0m                         decorator_argspec)\n\u001b[1;32m    138\u001b[0m \u001b[39msetattr\u001b[39m(decorator_func, \u001b[39m'\u001b[39m\u001b[39m_tf_decorator\u001b[39m\u001b[39m'\u001b[39m, decorator)\n\u001b[1;32m    139\u001b[0m \u001b[39m# Objects that are callables (e.g., a functools.partial object) may not have\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[39m# the following attributes.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/util/tf_decorator.py:332\u001b[0m, in \u001b[0;36mTFDecorator.__init__\u001b[0;34m(self, decorator_name, target, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mcallable\u001b[39m(target):\n\u001b[1;32m    331\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__signature__ \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39;49msignature(target)\n\u001b[1;32m    333\u001b[0m   \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m    334\u001b[0m     \u001b[39m# Certain callables such as builtins can not be inspected for signature.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/inspect.py:3254\u001b[0m, in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msignature\u001b[39m(obj, \u001b[39m*\u001b[39m, follow_wrapped\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39mglobals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39mlocals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, eval_str\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   3253\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3254\u001b[0m     \u001b[39mreturn\u001b[39;00m Signature\u001b[39m.\u001b[39;49mfrom_callable(obj, follow_wrapped\u001b[39m=\u001b[39;49mfollow_wrapped,\n\u001b[1;32m   3255\u001b[0m                                    \u001b[39mglobals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mglobals\u001b[39;49m, \u001b[39mlocals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m, eval_str\u001b[39m=\u001b[39;49meval_str)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/inspect.py:3002\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[0;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   2999\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_callable\u001b[39m(\u001b[39mcls\u001b[39m, obj, \u001b[39m*\u001b[39m,\n\u001b[1;32m   3000\u001b[0m                   follow_wrapped\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39mglobals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39mlocals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, eval_str\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   3001\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3002\u001b[0m     \u001b[39mreturn\u001b[39;00m _signature_from_callable(obj, sigcls\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m,\n\u001b[1;32m   3003\u001b[0m                                     follow_wrapper_chains\u001b[39m=\u001b[39;49mfollow_wrapped,\n\u001b[1;32m   3004\u001b[0m                                     \u001b[39mglobals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mglobals\u001b[39;49m, \u001b[39mlocals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m, eval_str\u001b[39m=\u001b[39;49meval_str)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/inspect.py:2463\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2458\u001b[0m             \u001b[39mreturn\u001b[39;00m sig\u001b[39m.\u001b[39mreplace(parameters\u001b[39m=\u001b[39mnew_params)\n\u001b[1;32m   2460\u001b[0m \u001b[39mif\u001b[39;00m isfunction(obj) \u001b[39mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[1;32m   2461\u001b[0m     \u001b[39m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[1;32m   2462\u001b[0m     \u001b[39m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[0;32m-> 2463\u001b[0m     \u001b[39mreturn\u001b[39;00m _signature_from_function(sigcls, obj,\n\u001b[1;32m   2464\u001b[0m                                     skip_bound_arg\u001b[39m=\u001b[39;49mskip_bound_arg,\n\u001b[1;32m   2465\u001b[0m                                     \u001b[39mglobals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mglobals\u001b[39;49m, \u001b[39mlocals\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m, eval_str\u001b[39m=\u001b[39;49meval_str)\n\u001b[1;32m   2467\u001b[0m \u001b[39mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[1;32m   2468\u001b[0m     \u001b[39mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[1;32m   2469\u001b[0m                                    skip_bound_arg\u001b[39m=\u001b[39mskip_bound_arg)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/inspect.py:2324\u001b[0m, in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m positional[:non_default_count]:\n\u001b[1;32m   2323\u001b[0m     kind \u001b[39m=\u001b[39m _POSITIONAL_ONLY \u001b[39mif\u001b[39;00m posonly_left \u001b[39melse\u001b[39;00m _POSITIONAL_OR_KEYWORD\n\u001b[0;32m-> 2324\u001b[0m     annotation \u001b[39m=\u001b[39m annotations\u001b[39m.\u001b[39;49mget(name, _empty)\n\u001b[1;32m   2325\u001b[0m     parameters\u001b[39m.\u001b[39mappend(Parameter(name, annotation\u001b[39m=\u001b[39mannotation,\n\u001b[1;32m   2326\u001b[0m                                 kind\u001b[39m=\u001b[39mkind))\n\u001b[1;32m   2327\u001b[0m     \u001b[39mif\u001b[39;00m posonly_left:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# main loop\n",
    "for episode in trange(500, desc='Test episodes'):\n",
    "\n",
    "        proc.reset()\n",
    "        (observation, info), done = env.reset(), False\n",
    "        truncated = False\n",
    "        proc.update_input(observation, info)\n",
    "        observation = proc.get_input()\n",
    "\n",
    "        episode_reward = 0\n",
    "        episode_len = 0\n",
    "\n",
    "        while (not done) or truncated:\n",
    "            \n",
    "            action, action_index = agent.get_action(observation, deterministic=False)\n",
    "            new_observation, reward, done, truncated, new_info = env.step(action=[action])\n",
    "            \n",
    "            proc.update_input(new_observation, info)\n",
    "            new_observation = proc.get_input()\n",
    "\n",
    "            episode_reward += reward # type: ignore\n",
    "            episode_len +=1\n",
    "\n",
    "            if new_info[\"rewards\"][\"on_road_reward\"] == False:\n",
    "                done = True\n",
    "            \n",
    "            agent.remember(state=observation, action=action_index, done=done,\n",
    "                            reward=reward, new_state=new_observation)\n",
    "            agent.train()\n",
    "\n",
    "            observation = new_observation\n",
    "\n",
    "        episode_lens.append(episode_len)\n",
    "\n",
    "        score_history.append(episode_reward)\n",
    "        avg_score = np.mean(score_history)\n",
    "        avg_history.append(avg_score)\n",
    "        std_score = np.std(score_history)\n",
    "        std_history.append(std_score)\n",
    "\n",
    "        avg_score_100 = np.mean(score_history[-100:])\n",
    "        avg_history_100.append(avg_score_100)\n",
    "\n",
    "        if avg_score_100 > best_score:\n",
    "            best_score = avg_score\n",
    "            agent.save_model(episode)\n",
    "\n",
    "        agent.tensorboard.update_stats(episode_rew = episode_reward,\n",
    "                                       average_rew =avg_score,\n",
    "                                       average_100_reward = avg_score_100,\n",
    "                                       std_rew=std_score,\n",
    "                                       epsilon=agent.epsilon,\n",
    "                                       episode_len = episode_len)\n",
    "        \n",
    "        #* save things in checkpoints\n",
    "        if not episode % aggregate_stats_every or episode == 1:\n",
    "            average_reward = sum(score_history[-aggregate_stats_every:])/len(score_history[-aggregate_stats_every:])\n",
    "            min_reward = min(score_history[-aggregate_stats_every:])\n",
    "            max_reward = max(score_history[-aggregate_stats_every:])\n",
    "\n",
    "            agent.tensorboard_steps.update_stats(reward_avg_steps=average_reward, reward_min_steps=min_reward, reward_max_steps=max_reward, epsilon_steps=agent.epsilon)\n",
    "\n",
    "        print('episode ', episode, 'score %.1f' % episode_reward, 'ep len', episode_len,\n",
    "              'avg score %.1f' % avg_score, 'avg_score_100 %.1f' %avg_score_100,'std score %.1f' % std_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19291\n",
      "-----saving models------\n"
     ]
    }
   ],
   "source": [
    "n_steps = sum(episode_lens)\n",
    "print(n_steps)\n",
    "agent.save_model(100000000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----loading models------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/o/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.configure to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.configure` for environment variables or `env.get_wrapper_attr('configure')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/o/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/o/Documents/thesis/ddqn/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b70cf7458c74adcb9861bc9fce4fb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test episodes:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  0 score 236.8 ep len 300\n",
      "episode  1 score 244.9 ep len 300\n",
      "episode  2 score 242.0 ep len 300\n",
      "Moviepy - Building video /home/o/Documents/thesis/ddqn/videos/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/o/Documents/thesis/ddqn/videos/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/o/Documents/thesis/ddqn/videos/rl-video-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# env = record_videos(env)\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "data = load_config()\n",
    "env = gym.make('racetrack-v0', render_mode = 'rgb_array')\n",
    "env.configure(data) # type: ignore\n",
    "\n",
    "env = RecordVideo(env, video_folder=\"videos\", episode_trigger=lambda e: True)\n",
    "env.unwrapped.set_record_video_wrapper(env)\n",
    "\n",
    "agent.load_model()\n",
    "# main loop\n",
    "for episode in trange(3, desc='Test episodes'):\n",
    "\n",
    "        proc.reset()\n",
    "        (observation, info), done = env.reset(), False\n",
    "        truncated = False\n",
    "        proc.update_input(observation, info)\n",
    "        observation = proc.get_input()\n",
    "\n",
    "        episode_reward = 0\n",
    "        episode_len = 0\n",
    "\n",
    "        while (not done) or truncated:\n",
    "            \n",
    "            action, action_index = agent.get_action(observation, deterministic=True)\n",
    "            new_observation, reward, done, truncated, new_info = env.step(action=[action])\n",
    "            \n",
    "            proc.update_input(new_observation, info)\n",
    "            new_observation = proc.get_input()\n",
    "\n",
    "            episode_reward += reward # type: ignore\n",
    "            episode_len +=1\n",
    "\n",
    "            if new_info[\"rewards\"][\"on_road_reward\"] == False or episode_len >=300:\n",
    "               done = True\n",
    "            \n",
    "            observation = new_observation\n",
    "\n",
    "        print('episode ', episode, 'score %.1f' % episode_reward, 'ep len', episode_len)   \n",
    "\n",
    "env.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
