{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 16:48:07.730389: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-03 16:48:07.991926: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-03 16:48:07.991998: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-03 16:48:07.993295: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-03 16:48:08.106118: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# fundemental modules\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pprint\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from ddqn import DDQNAgent # type: ignore\n",
    "from utils import load_config\n",
    "from obs import observation_shape\n",
    "\n",
    "aggregate_stats_every=100\n",
    "best_score = -1000.0\n",
    "score_history = []\n",
    "episode_lens = []\n",
    "avg_history = []\n",
    "std_history = []\n",
    "avg_history_100 = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/o/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.configure to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.configure` for environment variables or `env.get_wrapper_attr('configure')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "data = load_config()\n",
    "env = gym.make('racetrack-v0', render_mode = 'rgb_array')\n",
    "env.configure(data) # type: ignore\n",
    "# pprint.pprint(env.config) # type: ignore\n",
    "(obs, info), done = env.reset(), False\n",
    "\n",
    "#observation config\n",
    "proc = observation_shape(obs,info,2)\n",
    "proc.reset()\n",
    "input = proc.get_input()\n",
    "print(input.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 16:48:20.209681: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 16:48:20.323305: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 16:48:20.323580: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 16:48:20.327361: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysf"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               3456      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 11)                1419      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21387 (83.54 KB)\n",
      "Trainable params: 21387 (83.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "summary\n",
      "Agent is initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s-bus-pci#L344-L355\n",
      "2023-12-03 16:48:20.327610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 16:48:20.327765: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 16:48:20.911282: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 16:48:20.911370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 16:48:20.911428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 16:48:20.911474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9960 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "agent = DDQNAgent(alpha=0.001, gamma=0.9, epsilon=1.0, obs_shape=input.shape,\n",
    "                  batch_size=64, epsilon_dec=0.9995, epsilon_end=0.05, mem_size=100000,\n",
    "                  min_mem_size=100, replace_target=1000, learning_rate=0.0003)\n",
    "print(\"Agent is initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138b66571e314a78b25aa9081b106944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test episodes:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----saving models------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 16:48:42.194242: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  0 score 0.6 ep len 9 avg score 0.6 avg_score_100 0.6 std score 0.0\n",
      "-----saving models------\n",
      "episode  1 score 0.9 ep len 10 avg score 0.8 avg_score_100 0.8 std score 0.2\n",
      "episode  2 score 0.7 ep len 14 avg score 0.7 avg_score_100 0.7 std score 0.2\n",
      "-----saving models------\n",
      "episode  3 score 2.5 ep len 11 avg score 1.2 avg_score_100 1.2 std score 0.8\n",
      "episode  4 score -0.2 ep len 10 avg score 0.9 avg_score_100 0.9 std score 0.9\n",
      "episode  5 score -0.3 ep len 3 avg score 0.7 avg_score_100 0.7 std score 1.0\n",
      "episode  6 score 0.0 ep len 9 avg score 0.6 avg_score_100 0.6 std score 0.9\n",
      "episode  7 score -0.7 ep len 5 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  8 score 0.3 ep len 5 avg score 0.4 avg_score_100 0.4 std score 0.9\n",
      "episode  9 score -0.1 ep len 5 avg score 0.4 avg_score_100 0.4 std score 0.9\n",
      "episode  10 score -1.1 ep len 11 avg score 0.2 avg_score_100 0.2 std score 0.9\n",
      "episode  11 score 1.2 ep len 7 avg score 0.3 avg_score_100 0.3 std score 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 16:48:44.493984: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f50381eca00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-03 16:48:44.493995: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-12-03 16:48:44.499350: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-03 16:48:45.778564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2023-12-03 16:48:45.836504: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  12 score 0.7 ep len 5 avg score 0.3 avg_score_100 0.3 std score 0.9\n",
      "episode  13 score -0.6 ep len 7 avg score 0.3 avg_score_100 0.3 std score 0.9\n",
      "episode  14 score 0.1 ep len 16 avg score 0.3 avg_score_100 0.3 std score 0.9\n",
      "episode  15 score -0.0 ep len 4 avg score 0.3 avg_score_100 0.3 std score 0.8\n",
      "episode  16 score -1.0 ep len 8 avg score 0.2 avg_score_100 0.2 std score 0.9\n",
      "episode  17 score 0.4 ep len 10 avg score 0.2 avg_score_100 0.2 std score 0.8\n",
      "episode  18 score 1.8 ep len 17 avg score 0.3 avg_score_100 0.3 std score 0.9\n",
      "episode  19 score -0.3 ep len 13 avg score 0.2 avg_score_100 0.2 std score 0.9\n",
      "episode  20 score 1.2 ep len 5 avg score 0.3 avg_score_100 0.3 std score 0.9\n",
      "episode  21 score -0.1 ep len 4 avg score 0.3 avg_score_100 0.3 std score 0.9\n",
      "episode  22 score 0.8 ep len 11 avg score 0.3 avg_score_100 0.3 std score 0.9\n",
      "episode  23 score 1.5 ep len 23 avg score 0.3 avg_score_100 0.3 std score 0.9\n",
      "episode  24 score 0.4 ep len 8 avg score 0.3 avg_score_100 0.3 std score 0.9\n",
      "episode  25 score -0.7 ep len 6 avg score 0.3 avg_score_100 0.3 std score 0.9\n",
      "episode  26 score 2.6 ep len 20 avg score 0.4 avg_score_100 0.4 std score 0.9\n",
      "episode  27 score -0.1 ep len 8 avg score 0.4 avg_score_100 0.4 std score 0.9\n",
      "episode  28 score 3.3 ep len 15 avg score 0.5 avg_score_100 0.5 std score 1.1\n",
      "episode  29 score 0.9 ep len 14 avg score 0.5 avg_score_100 0.5 std score 1.0\n",
      "episode  30 score 0.5 ep len 14 avg score 0.5 avg_score_100 0.5 std score 1.0\n",
      "episode  31 score -0.3 ep len 4 avg score 0.5 avg_score_100 0.5 std score 1.0\n",
      "episode  32 score 1.8 ep len 9 avg score 0.5 avg_score_100 0.5 std score 1.0\n",
      "episode  33 score 0.7 ep len 7 avg score 0.5 avg_score_100 0.5 std score 1.0\n",
      "episode  34 score -0.4 ep len 7 avg score 0.5 avg_score_100 0.5 std score 1.0\n",
      "episode  35 score -0.3 ep len 3 avg score 0.5 avg_score_100 0.5 std score 1.0\n",
      "episode  36 score -0.6 ep len 6 avg score 0.4 avg_score_100 0.4 std score 1.0\n",
      "episode  37 score 1.9 ep len 13 avg score 0.5 avg_score_100 0.5 std score 1.0\n",
      "episode  38 score -2.6 ep len 23 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  39 score 2.5 ep len 11 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  40 score -0.5 ep len 4 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  41 score 0.2 ep len 10 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  42 score 0.4 ep len 6 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  43 score -0.8 ep len 5 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  44 score 0.3 ep len 22 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  45 score 1.1 ep len 7 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  46 score -0.1 ep len 6 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  47 score 0.0 ep len 6 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  48 score -0.1 ep len 6 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  49 score -0.1 ep len 12 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  50 score -1.1 ep len 17 avg score 0.3 avg_score_100 0.3 std score 1.1\n",
      "episode  51 score 0.5 ep len 7 avg score 0.3 avg_score_100 0.3 std score 1.1\n",
      "episode  52 score 1.0 ep len 6 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  53 score 1.1 ep len 6 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  54 score 2.7 ep len 13 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  55 score 1.0 ep len 10 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  56 score 3.4 ep len 27 avg score 0.5 avg_score_100 0.5 std score 1.1\n",
      "episode  57 score 2.8 ep len 15 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  58 score -0.2 ep len 4 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  59 score -0.6 ep len 5 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  60 score -0.3 ep len 7 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  61 score 0.0 ep len 3 avg score 0.5 avg_score_100 0.5 std score 1.1\n",
      "episode  62 score 0.8 ep len 14 avg score 0.5 avg_score_100 0.5 std score 1.1\n",
      "episode  63 score -0.8 ep len 6 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  64 score -0.4 ep len 3 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  65 score -0.9 ep len 12 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  66 score 2.1 ep len 10 avg score 0.4 avg_score_100 0.4 std score 1.2\n",
      "episode  67 score 0.3 ep len 10 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  68 score 0.1 ep len 5 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  69 score 0.2 ep len 9 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  70 score 0.1 ep len 14 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  71 score -0.9 ep len 7 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  72 score 0.5 ep len 5 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  73 score -0.0 ep len 14 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  74 score -1.2 ep len 15 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  75 score -1.4 ep len 13 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  76 score 0.4 ep len 8 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  77 score -0.1 ep len 5 avg score 0.3 avg_score_100 0.3 std score 1.1\n",
      "episode  78 score 2.0 ep len 9 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  79 score -0.3 ep len 7 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  80 score 3.1 ep len 21 avg score 0.4 avg_score_100 0.4 std score 1.2\n",
      "episode  81 score -0.4 ep len 3 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  82 score 1.6 ep len 26 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  83 score 1.4 ep len 17 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  84 score 1.6 ep len 11 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  85 score 1.1 ep len 10 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  86 score 1.8 ep len 7 avg score 0.5 avg_score_100 0.5 std score 1.1\n",
      "episode  87 score -0.8 ep len 15 avg score 0.4 avg_score_100 0.4 std score 1.1\n",
      "episode  88 score 4.9 ep len 13 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  89 score 0.9 ep len 7 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  90 score 1.0 ep len 6 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  91 score 0.1 ep len 7 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  92 score -0.3 ep len 11 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  93 score 3.6 ep len 30 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  94 score 1.1 ep len 7 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  95 score 0.7 ep len 9 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  96 score 0.8 ep len 9 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  97 score 1.0 ep len 9 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  98 score 0.5 ep len 4 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  99 score 0.1 ep len 9 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  100 score -0.3 ep len 3 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  101 score 3.1 ep len 20 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  102 score -0.7 ep len 6 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "episode  103 score 0.5 ep len 7 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "episode  104 score -0.3 ep len 18 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "episode  105 score -0.1 ep len 6 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  106 score -1.5 ep len 20 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  107 score 0.4 ep len 14 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  108 score 1.6 ep len 14 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  109 score -1.1 ep len 8 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  110 score -0.9 ep len 9 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  111 score 2.5 ep len 15 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  112 score 0.4 ep len 10 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  113 score -1.6 ep len 10 avg score 0.5 avg_score_100 0.5 std score 1.2\n",
      "episode  114 score 3.6 ep len 9 avg score 0.5 avg_score_100 0.5 std score 1.3\n",
      "episode  115 score 1.4 ep len 15 avg score 0.5 avg_score_100 0.6 std score 1.3\n",
      "episode  116 score 3.3 ep len 50 avg score 0.5 avg_score_100 0.6 std score 1.3\n",
      "episode  117 score 2.1 ep len 14 avg score 0.6 avg_score_100 0.6 std score 1.3\n",
      "episode  118 score 0.7 ep len 24 avg score 0.6 avg_score_100 0.6 std score 1.3\n",
      "episode  119 score 6.9 ep len 19 avg score 0.6 avg_score_100 0.7 std score 1.4\n",
      "episode  120 score -0.3 ep len 2 avg score 0.6 avg_score_100 0.7 std score 1.4\n",
      "episode  121 score -1.3 ep len 19 avg score 0.6 avg_score_100 0.7 std score 1.4\n",
      "episode  122 score -0.0 ep len 3 avg score 0.6 avg_score_100 0.6 std score 1.4\n",
      "episode  123 score 1.9 ep len 18 avg score 0.6 avg_score_100 0.6 std score 1.4\n",
      "episode  124 score 0.9 ep len 11 avg score 0.6 avg_score_100 0.7 std score 1.4\n",
      "episode  125 score 5.3 ep len 27 avg score 0.6 avg_score_100 0.7 std score 1.4\n",
      "episode  126 score -0.4 ep len 9 avg score 0.6 avg_score_100 0.7 std score 1.4\n",
      "episode  127 score -0.5 ep len 14 avg score 0.6 avg_score_100 0.7 std score 1.4\n",
      "episode  128 score 3.5 ep len 22 avg score 0.6 avg_score_100 0.7 std score 1.5\n",
      "episode  129 score -1.8 ep len 31 avg score 0.6 avg_score_100 0.7 std score 1.5\n",
      "episode  130 score -0.5 ep len 12 avg score 0.6 avg_score_100 0.6 std score 1.5\n",
      "episode  131 score 0.0 ep len 14 avg score 0.6 avg_score_100 0.6 std score 1.5\n",
      "episode  132 score 3.3 ep len 18 avg score 0.6 avg_score_100 0.7 std score 1.5\n",
      "episode  133 score -0.3 ep len 8 avg score 0.6 avg_score_100 0.7 std score 1.5\n",
      "episode  134 score 2.4 ep len 17 avg score 0.6 avg_score_100 0.7 std score 1.5\n",
      "episode  135 score -0.3 ep len 3 avg score 0.6 avg_score_100 0.7 std score 1.5\n",
      "episode  136 score 6.0 ep len 45 avg score 0.7 avg_score_100 0.7 std score 1.5\n",
      "episode  137 score -0.3 ep len 2 avg score 0.7 avg_score_100 0.7 std score 1.5\n",
      "episode  138 score 0.5 ep len 11 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  139 score -0.0 ep len 28 avg score 0.6 avg_score_100 0.7 std score 1.5\n",
      "episode  140 score 2.1 ep len 45 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  141 score -1.1 ep len 36 avg score 0.6 avg_score_100 0.7 std score 1.5\n",
      "episode  142 score 1.9 ep len 12 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  143 score 2.7 ep len 21 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  144 score 1.9 ep len 14 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  145 score 0.4 ep len 24 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  146 score 1.4 ep len 20 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  147 score 0.5 ep len 7 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  148 score -1.2 ep len 22 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  149 score 0.3 ep len 12 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  150 score 2.1 ep len 18 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  151 score 0.4 ep len 10 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  152 score 0.6 ep len 10 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  153 score -1.0 ep len 24 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  154 score 0.7 ep len 15 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  155 score 3.8 ep len 38 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  156 score 0.7 ep len 8 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  157 score 1.4 ep len 10 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  158 score 1.2 ep len 22 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  159 score 3.2 ep len 13 avg score 0.7 avg_score_100 0.8 std score 1.5\n",
      "episode  160 score 1.3 ep len 36 avg score 0.7 avg_score_100 0.9 std score 1.5\n",
      "episode  161 score 0.9 ep len 11 avg score 0.7 avg_score_100 0.9 std score 1.5\n",
      "episode  162 score -0.4 ep len 3 avg score 0.7 avg_score_100 0.9 std score 1.5\n",
      "episode  163 score 1.4 ep len 12 avg score 0.7 avg_score_100 0.9 std score 1.5\n",
      "episode  164 score -0.5 ep len 4 avg score 0.7 avg_score_100 0.9 std score 1.5\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "episode  165 score 1.9 ep len 23 avg score 0.7 avg_score_100 0.9 std score 1.5\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "episode  166 score 1.0 ep len 17 avg score 0.7 avg_score_100 0.9 std score 1.5\n",
      "episode  167 score -0.0 ep len 10 avg score 0.7 avg_score_100 0.9 std score 1.5\n",
      "episode  168 score 4.1 ep len 64 avg score 0.7 avg_score_100 0.9 std score 1.5\n",
      "episode  169 score 4.1 ep len 10 avg score 0.7 avg_score_100 1.0 std score 1.5\n",
      "episode  170 score 0.3 ep len 24 avg score 0.7 avg_score_100 1.0 std score 1.5\n",
      "episode  171 score 0.1 ep len 18 avg score 0.7 avg_score_100 1.0 std score 1.5\n",
      "episode  172 score 7.7 ep len 57 avg score 0.8 avg_score_100 1.0 std score 1.6\n",
      "episode  173 score 3.0 ep len 28 avg score 0.8 avg_score_100 1.1 std score 1.6\n",
      "episode  174 score 1.0 ep len 73 avg score 0.8 avg_score_100 1.1 std score 1.6\n",
      "episode  175 score 4.4 ep len 19 avg score 0.8 avg_score_100 1.2 std score 1.6\n",
      "episode  176 score -0.6 ep len 8 avg score 0.8 avg_score_100 1.1 std score 1.6\n",
      "-----saving models------\n",
      "episode  177 score 5.8 ep len 41 avg score 0.8 avg_score_100 1.2 std score 1.7\n",
      "-----saving models------\n",
      "episode  178 score 0.1 ep len 36 avg score 0.8 avg_score_100 1.2 std score 1.6\n",
      "-----saving models------\n",
      "episode  179 score 2.3 ep len 13 avg score 0.8 avg_score_100 1.2 std score 1.6\n",
      "-----saving models------\n",
      "episode  180 score 6.2 ep len 36 avg score 0.9 avg_score_100 1.2 std score 1.7\n",
      "-----saving models------\n",
      "episode  181 score 8.0 ep len 59 avg score 0.9 avg_score_100 1.3 std score 1.8\n",
      "-----saving models------\n",
      "episode  182 score 6.6 ep len 82 avg score 0.9 avg_score_100 1.4 std score 1.8\n",
      "-----saving models------\n",
      "episode  183 score 2.3 ep len 14 avg score 0.9 avg_score_100 1.4 std score 1.8\n",
      "-----saving models------\n",
      "episode  184 score -0.3 ep len 37 avg score 0.9 avg_score_100 1.4 std score 1.8\n",
      "-----saving models------\n",
      "episode  185 score 2.3 ep len 12 avg score 0.9 avg_score_100 1.4 std score 1.8\n",
      "-----saving models------\n",
      "episode  186 score 3.7 ep len 45 avg score 1.0 avg_score_100 1.4 std score 1.8\n",
      "-----saving models------\n",
      "episode  187 score 1.8 ep len 16 avg score 1.0 avg_score_100 1.4 std score 1.8\n",
      "-----saving models------\n",
      "episode  188 score 3.0 ep len 34 avg score 1.0 avg_score_100 1.4 std score 1.8\n",
      "-----saving models------\n",
      "episode  189 score 4.6 ep len 71 avg score 1.0 avg_score_100 1.4 std score 1.8\n",
      "-----saving models------\n",
      "episode  190 score 2.6 ep len 34 avg score 1.0 avg_score_100 1.5 std score 1.8\n",
      "-----saving models------\n",
      "episode  191 score 2.8 ep len 31 avg score 1.0 avg_score_100 1.5 std score 1.8\n",
      "-----saving models------\n",
      "episode  192 score 4.5 ep len 49 avg score 1.0 avg_score_100 1.5 std score 1.8\n",
      "-----saving models------\n",
      "episode  193 score 4.1 ep len 14 avg score 1.0 avg_score_100 1.5 std score 1.8\n",
      "-----saving models------\n",
      "episode  194 score 3.9 ep len 10 avg score 1.1 avg_score_100 1.6 std score 1.8\n",
      "-----saving models------\n",
      "episode  195 score 8.0 ep len 34 avg score 1.1 avg_score_100 1.6 std score 1.9\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  196 score 3.8 ep len 49 avg score 1.1 avg_score_100 1.7 std score 1.9\n",
      "-----saving models------\n",
      "episode  197 score 7.2 ep len 46 avg score 1.1 avg_score_100 1.7 std score 2.0\n",
      "-----saving models------\n",
      "episode  198 score 4.3 ep len 77 avg score 1.2 avg_score_100 1.8 std score 2.0\n",
      "-----saving models------\n",
      "episode  199 score 8.1 ep len 65 avg score 1.2 avg_score_100 1.9 std score 2.0\n",
      "-----saving models------\n",
      "episode  200 score 15.5 ep len 42 avg score 1.3 avg_score_100 2.0 std score 2.3\n",
      "-----saving models------\n",
      "episode  201 score 4.2 ep len 55 avg score 1.3 avg_score_100 2.0 std score 2.3\n",
      "-----saving models------\n",
      "episode  202 score 8.2 ep len 34 avg score 1.3 avg_score_100 2.1 std score 2.3\n",
      "-----saving models------\n",
      "episode  203 score 5.4 ep len 18 avg score 1.3 avg_score_100 2.2 std score 2.3\n",
      "-----saving models------\n",
      "episode  204 score 6.6 ep len 33 avg score 1.4 avg_score_100 2.2 std score 2.3\n",
      "-----saving models------\n",
      "episode  205 score 2.9 ep len 35 avg score 1.4 avg_score_100 2.3 std score 2.3\n",
      "-----saving models------\n",
      "episode  206 score 8.6 ep len 24 avg score 1.4 avg_score_100 2.4 std score 2.4\n",
      "-----saving models------\n",
      "episode  207 score 13.1 ep len 38 avg score 1.5 avg_score_100 2.5 std score 2.5\n",
      "-----saving models------\n",
      "episode  208 score 16.7 ep len 32 avg score 1.5 avg_score_100 2.6 std score 2.7\n",
      "-----saving models------\n",
      "episode  209 score 16.5 ep len 110 avg score 1.6 avg_score_100 2.8 std score 2.9\n",
      "-----saving models------\n",
      "episode  210 score 5.4 ep len 13 avg score 1.6 avg_score_100 2.9 std score 2.9\n",
      "-----saving models------\n",
      "episode  211 score 2.9 ep len 20 avg score 1.6 avg_score_100 2.9 std score 2.9\n",
      "-----saving models------\n",
      "episode  212 score 27.1 ep len 78 avg score 1.7 avg_score_100 3.1 std score 3.4\n",
      "-----saving models------\n",
      "episode  213 score 12.2 ep len 64 avg score 1.8 avg_score_100 3.3 std score 3.4\n",
      "-----saving models------\n",
      "episode  214 score 22.1 ep len 62 avg score 1.9 avg_score_100 3.5 std score 3.7\n",
      "-----saving models------\n",
      "episode  215 score 32.0 ep len 108 avg score 2.0 avg_score_100 3.8 std score 4.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  216 score 16.0 ep len 64 avg score 2.1 avg_score_100 3.9 std score 4.3\n",
      "-----saving models------\n",
      "episode  217 score 19.2 ep len 75 avg score 2.2 avg_score_100 4.1 std score 4.5\n",
      "-----saving models------\n",
      "episode  218 score 19.7 ep len 49 avg score 2.2 avg_score_100 4.3 std score 4.6\n",
      "-----saving models------\n",
      "episode  219 score 14.9 ep len 34 avg score 2.3 avg_score_100 4.3 std score 4.7\n",
      "-----saving models------\n",
      "episode  220 score 17.2 ep len 69 avg score 2.4 avg_score_100 4.5 std score 4.8\n",
      "-----saving models------\n",
      "episode  221 score 19.9 ep len 81 avg score 2.5 avg_score_100 4.7 std score 4.9\n",
      "-----saving models------\n",
      "episode  222 score 2.7 ep len 15 avg score 2.5 avg_score_100 4.8 std score 4.9\n",
      "-----saving models------\n",
      "episode  223 score 7.8 ep len 46 avg score 2.5 avg_score_100 4.8 std score 4.9\n",
      "-----saving models------\n",
      "episode  224 score 11.7 ep len 44 avg score 2.5 avg_score_100 4.9 std score 4.9\n",
      "-----saving models------\n",
      "episode  225 score 22.7 ep len 84 avg score 2.6 avg_score_100 5.1 std score 5.1\n",
      "-----saving models------\n",
      "episode  226 score 33.0 ep len 86 avg score 2.7 avg_score_100 5.4 std score 5.5\n",
      "-----saving models------\n",
      "episode  227 score 14.8 ep len 45 avg score 2.8 avg_score_100 5.6 std score 5.5\n",
      "-----saving models------\n",
      "episode  228 score 31.8 ep len 84 avg score 2.9 avg_score_100 5.9 std score 5.8\n",
      "-----saving models------\n",
      "episode  229 score 43.0 ep len 152 avg score 3.1 avg_score_100 6.3 std score 6.4\n",
      "-----saving models------\n",
      "episode  230 score 39.6 ep len 81 avg score 3.3 avg_score_100 6.7 std score 6.8\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  231 score 35.0 ep len 72 avg score 3.4 avg_score_100 7.1 std score 7.1\n",
      "-----saving models------\n",
      "episode  232 score 40.1 ep len 75 avg score 3.5 avg_score_100 7.4 std score 7.5\n",
      "-----saving models------\n",
      "episode  233 score 69.1 ep len 167 avg score 3.8 avg_score_100 8.1 std score 8.6\n",
      "-----saving models------\n",
      "episode  234 score 65.9 ep len 200 avg score 4.1 avg_score_100 8.8 std score 9.5\n",
      "-----saving models------\n",
      "episode  235 score 73.8 ep len 200 avg score 4.4 avg_score_100 9.5 std score 10.5\n",
      "-----saving models------\n",
      "episode  236 score 56.5 ep len 200 avg score 4.6 avg_score_100 10.0 std score 11.0\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  237 score 92.2 ep len 200 avg score 5.0 avg_score_100 10.9 std score 12.4\n",
      "-----saving models------\n",
      "episode  238 score 92.7 ep len 200 avg score 5.3 avg_score_100 11.9 std score 13.6\n",
      "-----saving models------\n",
      "episode  239 score 101.5 ep len 200 avg score 5.7 avg_score_100 12.9 std score 14.9\n",
      "-----saving models------\n",
      "episode  240 score 47.5 ep len 75 avg score 5.9 avg_score_100 13.3 std score 15.1\n",
      "-----saving models------\n",
      "episode  241 score 94.3 ep len 200 avg score 6.3 avg_score_100 14.3 std score 16.1\n",
      "-----saving models------\n",
      "episode  242 score 103.4 ep len 200 avg score 6.7 avg_score_100 15.3 std score 17.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  243 score 91.1 ep len 166 avg score 7.0 avg_score_100 16.2 std score 18.0\n",
      "-----saving models------\n",
      "episode  244 score 120.9 ep len 200 avg score 7.5 avg_score_100 17.4 std score 19.4\n",
      "-----saving models------\n",
      "episode  245 score 111.7 ep len 200 avg score 7.9 avg_score_100 18.5 std score 20.5\n",
      "-----saving models------\n",
      "episode  246 score 110.2 ep len 200 avg score 8.3 avg_score_100 19.6 std score 21.4\n",
      "-----saving models------\n",
      "episode  247 score 119.2 ep len 200 avg score 8.8 avg_score_100 20.8 std score 22.5\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  248 score 114.7 ep len 200 avg score 9.2 avg_score_100 21.9 std score 23.4\n",
      "-----saving models------\n",
      "episode  249 score 123.1 ep len 200 avg score 9.7 avg_score_100 23.2 std score 24.5\n",
      "-----saving models------\n",
      "episode  250 score 123.4 ep len 200 avg score 10.1 avg_score_100 24.4 std score 25.5\n",
      "-----saving models------\n",
      "episode  251 score 114.8 ep len 200 avg score 10.5 avg_score_100 25.5 std score 26.2\n",
      "-----saving models------\n",
      "episode  252 score 107.3 ep len 200 avg score 10.9 avg_score_100 26.6 std score 26.9\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  253 score 130.4 ep len 200 avg score 11.4 avg_score_100 27.9 std score 27.9\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  254 score 113.8 ep len 200 avg score 11.8 avg_score_100 29.0 std score 28.5\n",
      "-----saving models------\n",
      "episode  255 score 121.6 ep len 200 avg score 12.2 avg_score_100 30.2 std score 29.3\n",
      "-----saving models------\n",
      "episode  256 score 122.1 ep len 200 avg score 12.6 avg_score_100 31.4 std score 30.0\n",
      "-----saving models------\n",
      "episode  257 score 54.2 ep len 98 avg score 12.8 avg_score_100 31.9 std score 30.1\n",
      "-----saving models------\n",
      "episode  258 score 109.7 ep len 200 avg score 13.2 avg_score_100 33.0 std score 30.6\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  259 score 127.8 ep len 200 avg score 13.6 avg_score_100 34.3 std score 31.4\n",
      "-----saving models------\n",
      "episode  260 score 114.8 ep len 200 avg score 14.0 avg_score_100 35.4 std score 31.9\n",
      "-----saving models------\n",
      "episode  261 score 116.5 ep len 200 avg score 14.4 avg_score_100 36.6 std score 32.5\n",
      "-----saving models------\n",
      "episode  262 score 123.0 ep len 200 avg score 14.8 avg_score_100 37.8 std score 33.1\n",
      "-----saving models------\n",
      "episode  263 score 108.0 ep len 200 avg score 15.2 avg_score_100 38.9 std score 33.5\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  264 score 122.1 ep len 200 avg score 15.6 avg_score_100 40.1 std score 34.1\n",
      "-----saving models------\n",
      "episode  265 score 122.1 ep len 200 avg score 16.0 avg_score_100 41.3 std score 34.7\n",
      "-----saving models------\n",
      "episode  266 score 130.4 ep len 200 avg score 16.4 avg_score_100 42.6 std score 35.3\n",
      "-----saving models------\n",
      "episode  267 score 132.1 ep len 200 avg score 16.8 avg_score_100 43.9 std score 35.9\n",
      "-----saving models------\n",
      "episode  268 score 134.6 ep len 200 avg score 17.3 avg_score_100 45.2 std score 36.6\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  269 score 142.6 ep len 200 avg score 17.7 avg_score_100 46.6 std score 37.3\n",
      "-----saving models------\n",
      "episode  270 score 125.8 ep len 200 avg score 18.1 avg_score_100 47.8 std score 37.8\n",
      "-----saving models------\n",
      "episode  271 score 125.4 ep len 200 avg score 18.5 avg_score_100 49.1 std score 38.3\n",
      "-----saving models------\n",
      "episode  272 score 127.1 ep len 200 avg score 18.9 avg_score_100 50.3 std score 38.8\n",
      "-----saving models------\n",
      "episode  273 score 128.1 ep len 200 avg score 19.3 avg_score_100 51.5 std score 39.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  274 score 140.1 ep len 200 avg score 19.8 avg_score_100 52.9 std score 39.8\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  275 score 136.1 ep len 200 avg score 20.2 avg_score_100 54.3 std score 40.4\n",
      "-----saving models------\n",
      "episode  276 score 122.3 ep len 200 avg score 20.5 avg_score_100 55.5 std score 40.8\n",
      "-----saving models------\n",
      "episode  277 score 132.7 ep len 200 avg score 20.9 avg_score_100 56.8 std score 41.2\n",
      "-----saving models------\n",
      "episode  278 score 9.2 ep len 20 avg score 20.9 avg_score_100 56.8 std score 41.2\n",
      "-----saving models------\n",
      "episode  279 score 131.2 ep len 200 avg score 21.3 avg_score_100 58.1 std score 41.6\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  280 score 128.6 ep len 200 avg score 21.7 avg_score_100 59.4 std score 42.0\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  281 score 140.9 ep len 200 avg score 22.1 avg_score_100 60.7 std score 42.6\n",
      "-----saving models------\n",
      "episode  282 score 127.3 ep len 200 avg score 22.5 avg_score_100 61.9 std score 42.9\n",
      "-----saving models------\n",
      "episode  283 score 130.9 ep len 200 avg score 22.9 avg_score_100 63.2 std score 43.3\n",
      "-----saving models------\n",
      "episode  284 score 138.0 ep len 200 avg score 23.3 avg_score_100 64.6 std score 43.8\n",
      "-----saving models------\n",
      "episode  285 score 134.5 ep len 200 avg score 23.7 avg_score_100 65.9 std score 44.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  286 score 129.0 ep len 200 avg score 24.0 avg_score_100 67.1 std score 44.6\n",
      "-----saving models------\n",
      "episode  287 score 131.5 ep len 200 avg score 24.4 avg_score_100 68.4 std score 44.9\n",
      "-----saving models------\n",
      "episode  288 score 143.9 ep len 200 avg score 24.8 avg_score_100 69.8 std score 45.4\n",
      "-----saving models------\n",
      "episode  289 score 144.2 ep len 200 avg score 25.2 avg_score_100 71.2 std score 45.9\n",
      "-----saving models------\n",
      "episode  290 score 129.7 ep len 200 avg score 25.6 avg_score_100 72.5 std score 46.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  291 score 133.7 ep len 200 avg score 25.9 avg_score_100 73.8 std score 46.6\n",
      "-----saving models------\n",
      "episode  292 score 136.6 ep len 200 avg score 26.3 avg_score_100 75.1 std score 46.9\n",
      "-----saving models------\n",
      "episode  293 score 128.1 ep len 200 avg score 26.7 avg_score_100 76.4 std score 47.2\n",
      "-----saving models------\n",
      "episode  294 score 145.7 ep len 200 avg score 27.1 avg_score_100 77.8 std score 47.6\n",
      "-----saving models------\n",
      "episode  295 score 133.3 ep len 200 avg score 27.4 avg_score_100 79.1 std score 48.0\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  296 score 136.6 ep len 200 avg score 27.8 avg_score_100 80.4 std score 48.3\n",
      "-----saving models------\n",
      "episode  297 score 107.9 ep len 157 avg score 28.1 avg_score_100 81.4 std score 48.4\n",
      "-----saving models------\n",
      "episode  298 score 133.8 ep len 200 avg score 28.4 avg_score_100 82.7 std score 48.7\n",
      "-----saving models------\n",
      "episode  299 score 119.2 ep len 200 avg score 28.7 avg_score_100 83.8 std score 48.9\n",
      "-----saving models------\n",
      "episode  300 score 146.3 ep len 200 avg score 29.1 avg_score_100 85.1 std score 49.3\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  301 score 137.5 ep len 200 avg score 29.5 avg_score_100 86.4 std score 49.6\n",
      "-----saving models------\n",
      "episode  302 score 142.8 ep len 200 avg score 29.8 avg_score_100 87.8 std score 50.0\n",
      "-----saving models------\n",
      "episode  303 score 126.6 ep len 200 avg score 30.2 avg_score_100 89.0 std score 50.2\n",
      "-----saving models------\n",
      "episode  304 score 144.2 ep len 200 avg score 30.5 avg_score_100 90.4 std score 50.5\n",
      "-----saving models------\n",
      "episode  305 score 147.6 ep len 200 avg score 30.9 avg_score_100 91.8 std score 50.9\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  306 score 142.6 ep len 200 avg score 31.3 avg_score_100 93.2 std score 51.2\n",
      "-----saving models------\n",
      "episode  307 score 126.3 ep len 200 avg score 31.6 avg_score_100 94.3 std score 51.4\n",
      "-----saving models------\n",
      "episode  308 score 149.7 ep len 200 avg score 32.0 avg_score_100 95.6 std score 51.8\n",
      "-----saving models------\n",
      "episode  309 score 140.3 ep len 200 avg score 32.3 avg_score_100 96.9 std score 52.0\n",
      "-----saving models------\n",
      "episode  310 score 136.5 ep len 200 avg score 32.7 avg_score_100 98.2 std score 52.3\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  311 score 138.9 ep len 200 avg score 33.0 avg_score_100 99.5 std score 52.6\n",
      "-----saving models------\n",
      "episode  312 score 141.9 ep len 200 avg score 33.4 avg_score_100 100.7 std score 52.8\n",
      "-----saving models------\n",
      "episode  313 score 142.9 ep len 200 avg score 33.7 avg_score_100 102.0 std score 53.1\n",
      "-----saving models------\n",
      "episode  314 score 145.0 ep len 200 avg score 34.1 avg_score_100 103.2 std score 53.4\n",
      "-----saving models------\n",
      "episode  315 score 40.5 ep len 61 avg score 34.1 avg_score_100 103.3 std score 53.3\n",
      "-----saving models------\n",
      "episode  316 score 138.6 ep len 200 avg score 34.4 avg_score_100 104.5 std score 53.5\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  317 score 134.1 ep len 200 avg score 34.7 avg_score_100 105.7 std score 53.7\n",
      "-----saving models------\n",
      "episode  318 score 20.8 ep len 33 avg score 34.7 avg_score_100 105.7 std score 53.7\n",
      "-----saving models------\n",
      "episode  319 score 141.9 ep len 200 avg score 35.0 avg_score_100 107.0 std score 53.9\n",
      "-----saving models------\n",
      "episode  320 score 144.7 ep len 200 avg score 35.3 avg_score_100 108.2 std score 54.2\n",
      "-----saving models------\n",
      "episode  321 score 130.6 ep len 200 avg score 35.6 avg_score_100 109.3 std score 54.4\n",
      "-----saving models------\n",
      "episode  322 score 147.7 ep len 200 avg score 36.0 avg_score_100 110.8 std score 54.6\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  323 score 151.7 ep len 200 avg score 36.3 avg_score_100 112.2 std score 54.9\n",
      "-----saving models------\n",
      "episode  324 score 134.0 ep len 200 avg score 36.6 avg_score_100 113.4 std score 55.1\n",
      "-----saving models------\n",
      "episode  325 score 133.6 ep len 200 avg score 36.9 avg_score_100 114.6 std score 55.3\n",
      "-----saving models------\n",
      "episode  326 score 125.7 ep len 200 avg score 37.2 avg_score_100 115.5 std score 55.4\n",
      "-----saving models------\n",
      "episode  327 score 148.1 ep len 200 avg score 37.6 avg_score_100 116.8 std score 55.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  328 score 144.1 ep len 200 avg score 37.9 avg_score_100 117.9 std score 55.9\n",
      "-----saving models------\n",
      "episode  329 score 148.2 ep len 200 avg score 38.2 avg_score_100 119.0 std score 56.1\n",
      "-----saving models------\n",
      "episode  330 score 143.2 ep len 200 avg score 38.5 avg_score_100 120.0 std score 56.3\n",
      "-----saving models------\n",
      "episode  331 score 143.4 ep len 200 avg score 38.8 avg_score_100 121.1 std score 56.5\n",
      "-----saving models------\n",
      "episode  332 score 151.7 ep len 200 avg score 39.2 avg_score_100 122.2 std score 56.8\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  333 score 149.6 ep len 200 avg score 39.5 avg_score_100 123.0 std score 57.0\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  334 score 138.0 ep len 200 avg score 39.8 avg_score_100 123.7 std score 57.2\n",
      "-----saving models------\n",
      "episode  335 score 136.6 ep len 200 avg score 40.1 avg_score_100 124.4 std score 57.4\n",
      "-----saving models------\n",
      "episode  336 score 145.4 ep len 200 avg score 40.4 avg_score_100 125.3 std score 57.6\n",
      "-----saving models------\n",
      "episode  337 score 144.1 ep len 200 avg score 40.7 avg_score_100 125.8 std score 57.7\n",
      "-----saving models------\n",
      "episode  338 score 152.9 ep len 200 avg score 41.0 avg_score_100 126.4 std score 58.0\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  339 score 144.7 ep len 200 avg score 41.4 avg_score_100 126.8 std score 58.2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/o/Documents/thesis/ddqn/main.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m episode_len \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mwhile\u001b[39;00m (\u001b[39mnot\u001b[39;00m done) \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m truncated):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     action, action_index \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mget_action(observation, deterministic\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     new_observation, reward, done, truncated, new_info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action\u001b[39m=\u001b[39m[action])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/ddqn/main.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     proc\u001b[39m.\u001b[39mupdate_input(new_observation, info)\n",
      "File \u001b[0;32m~/Documents/thesis/ddqn/ddqn.py:80\u001b[0m, in \u001b[0;36mDDQNAgent.get_action\u001b[0;34m(self, observation, deterministic)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandom() \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepsilon \u001b[39mor\u001b[39;00m deterministic: \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \n\u001b[1;32m     77\u001b[0m     \u001b[39m# observation = tf.convert_to_tensor(observation, dtype = tf.float16)\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     observation \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(observation, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 80\u001b[0m     qs_\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_eval\u001b[39m.\u001b[39;49mpredict(observation, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m) \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[39m#*----------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[39m#! Added for testing only\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[39m# print(\"Predicted Q values: \", qs_)\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[39m#*----------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     action_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(qs_)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/engine/training.py:2627\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2625\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution_tuner\u001b[39m.\u001b[39mstart()\n\u001b[1;32m   2626\u001b[0m batch_outputs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2627\u001b[0m \u001b[39mfor\u001b[39;00m _, iterator \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39menumerate_epochs():  \u001b[39m# Single epoch.\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m     \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m   2629\u001b[0m         \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1341\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[0;32m-> 1341\u001b[0m     data_iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset)\n\u001b[1;32m   1342\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_epoch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epochs):\n\u001b[1;32m   1343\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:496\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mor\u001b[39;00m ops\u001b[39m.\u001b[39minside_function():\n\u001b[1;32m    495\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 496\u001b[0m     \u001b[39mreturn\u001b[39;00m iterator_ops\u001b[39m.\u001b[39;49mOwnedIterator(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    497\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39miteration in eager mode or within tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:705\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    701\u001b[0m   \u001b[39mif\u001b[39;00m (components \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m element_spec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    702\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    703\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    704\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot be specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 705\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_iterator(dataset)\n\u001b[1;32m    707\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next_call_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:744\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    741\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(fulltype\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margs) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\n\u001b[1;32m    742\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_output_types)\n\u001b[1;32m    743\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_resource\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 744\u001b[0m gen_dataset_ops\u001b[39m.\u001b[39;49mmake_iterator(ds_variant, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3420\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3418\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   3419\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3420\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   3421\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMakeIterator\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, dataset, iterator)\n\u001b[1;32m   3422\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3423\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# main loop\n",
    "for episode in trange(500, desc='Test episodes'):\n",
    "\n",
    "        proc.reset()\n",
    "        (observation, info), done = env.reset(), False\n",
    "        truncated = False\n",
    "        proc.update_input(observation, info)\n",
    "        observation = proc.get_input()\n",
    "\n",
    "        episode_reward = 0\n",
    "        episode_len = 0\n",
    "\n",
    "        while (not done) and (not truncated):\n",
    "            \n",
    "            action, action_index = agent.get_action(observation, deterministic=False)\n",
    "            new_observation, reward, done, truncated, new_info = env.step(action=[action])\n",
    "            \n",
    "            proc.update_input(new_observation, info)\n",
    "            new_observation = proc.get_input()\n",
    "\n",
    "            episode_reward += reward # type: ignore\n",
    "            episode_len +=1\n",
    "\n",
    "            if new_info[\"rewards\"][\"on_road_reward\"] == False or episode_len >= 200:\n",
    "                done = True\n",
    "            \n",
    "            agent.remember(state=observation, action=action_index, done=done,\n",
    "                            reward=reward, new_state=new_observation)\n",
    "            agent.train()\n",
    "\n",
    "            observation = new_observation\n",
    "\n",
    "        episode_lens.append(episode_len)\n",
    "\n",
    "        score_history.append(episode_reward)\n",
    "        avg_score = np.mean(score_history)\n",
    "        avg_history.append(avg_score)\n",
    "        std_score = np.std(score_history)\n",
    "        std_history.append(std_score)\n",
    "\n",
    "        avg_score_100 = np.mean(score_history[-100:])\n",
    "        avg_history_100.append(avg_score_100)\n",
    "\n",
    "        if avg_score_100 > best_score:\n",
    "            best_score = avg_score\n",
    "            agent.save_model(episode)\n",
    "\n",
    "        agent.tensorboard.update_stats(episode_rew = episode_reward,\n",
    "                                       average_rew =avg_score,\n",
    "                                       average_100_reward = avg_score_100,\n",
    "                                       std_rew=std_score,\n",
    "                                       epsilon=agent.epsilon,\n",
    "                                       episode_len = episode_len)\n",
    "        \n",
    "\n",
    "        print('episode ', episode, 'score %.1f' % episode_reward, 'ep len', episode_len,\n",
    "              'avg score %.1f' % avg_score, 'avg_score_100 %.1f' %avg_score_100,'std score %.1f' % std_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25798\n"
     ]
    }
   ],
   "source": [
    "n_steps = sum(episode_lens)\n",
    "print(n_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/o/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.configure to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.configure` for environment variables or `env.get_wrapper_attr('configure')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579b1379360944a08907e3097e8f633f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test episodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  0 score 123.7 ep len 150\n",
      "Moviepy - Building video /home/o/Documents/thesis/ddqn/videos/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/o/Documents/thesis/ddqn/videos/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/o/Documents/thesis/ddqn/videos/rl-video-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# env = record_videos(env)\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "data = load_config()\n",
    "env = gym.make('racetrack-v0', render_mode = 'rgb_array')\n",
    "env.configure(data) # type: ignore\n",
    "\n",
    "env = RecordVideo(env, video_folder=\"videos\", episode_trigger=lambda e: True)\n",
    "env.unwrapped.set_record_video_wrapper(env)\n",
    "\n",
    "# main loop\n",
    "for episode in trange(1, desc='Test episodes'):\n",
    "\n",
    "        proc.reset()\n",
    "        (observation, info), done = env.reset(), False\n",
    "        truncated = False\n",
    "        proc.update_input(observation, info)\n",
    "        observation = proc.get_input()\n",
    "\n",
    "        episode_reward = 0\n",
    "        episode_len = 0\n",
    "\n",
    "        while (not done) or truncated:\n",
    "            \n",
    "            action, action_index = agent.get_action(observation, deterministic=True)\n",
    "            new_observation, reward, done, truncated, new_info = env.step(action=[action])\n",
    "            \n",
    "            proc.update_input(new_observation, info)\n",
    "            new_observation = proc.get_input()\n",
    "\n",
    "            episode_reward += reward # type: ignore\n",
    "            episode_len +=1\n",
    "\n",
    "            if new_info[\"rewards\"][\"on_road_reward\"] == False or episode_len >=150:\n",
    "               done = True\n",
    "            \n",
    "            observation = new_observation\n",
    "\n",
    "        print('episode ', episode, 'score %.1f' % episode_reward, 'ep len', episode_len)   \n",
    "\n",
    "env.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
