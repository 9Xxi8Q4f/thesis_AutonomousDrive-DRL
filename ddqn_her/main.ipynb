{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 21:37:28.362669: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-11 21:37:28.387475: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-11 21:37:28.387495: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-11 21:37:28.387509: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-11 21:37:28.392218: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# fundemental modules\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pprint\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from ddqn import DDQNAgent # type: ignore\n",
    "from utils import load_config\n",
    "from obs import observation_shape\n",
    "\n",
    "aggregate_stats_every=100\n",
    "best_score = -1000.0\n",
    "score_history = []\n",
    "episode_lens = []\n",
    "avg_history = []\n",
    "std_history = []\n",
    "avg_history_100 = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/o/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.configure to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.configure` for environment variables or `env.get_wrapper_attr('configure')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "data = load_config()\n",
    "env = gym.make('racetrack-v0', render_mode = 'rgb_array')\n",
    "env.configure(data) # type: ignore\n",
    "# pprint.pprint(env.config) # type: ignore\n",
    "(obs, info), done = env.reset(), False\n",
    "\n",
    "#observation config\n",
    "proc = observation_shape(obs,info,2)\n",
    "proc.reset()\n",
    "input = proc.get_input()\n",
    "print(input.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               3456      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 11)                1419      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21387 (83.54 KB)\n",
      "Trainable params: 21387 (83.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "summary\n",
      "Agent is initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 21:37:31.087373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 21:37:31.109149: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 21:37:31.109258: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 21:37:31.109982: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 21:37:31.110061: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 21:37:31.110122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 21:37:31.488228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 21:37:31.488327: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 21:37:31.488384: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-11 21:37:31.488431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9522 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#* THIS IS THE BEST \n",
    "\n",
    "agent = DDQNAgent(alpha=0.001, gamma=0.9, epsilon=1.0, obs_shape=input.shape,\n",
    "                  batch_size=64, epsilon_dec=0.995, epsilon_end=0.05, mem_size=100000,\n",
    "                  min_mem_size=100, replace_target=100, learning_rate=0.0003)\n",
    "print(\"Agent is initialized.\")\n",
    "# agent = DDQNAgent(alpha=0.001, gamma=0.9, epsilon=1.0, obs_shape=input.shape,\n",
    "#                   batch_size=64, epsilon_dec=0.9995, epsilon_end=0.05, mem_size=100000,\n",
    "#                   min_mem_size=100, replace_target=1000, learning_rate=0.0003)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b321409377f4883a2dc6ab29fc40ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test episodes:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----saving models------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 21:37:47.448823: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  0 score 2.3 ep len 7 avg score 2.3 avg_score_100 2.3 std score 0.0\n",
      "-----saving models------\n",
      "episode  1 score 4.2 ep len 10 avg score 3.3 avg_score_100 3.3 std score 0.9\n",
      "episode  2 score 1.8 ep len 10 avg score 2.8 avg_score_100 2.8 std score 1.0\n",
      "episode  3 score 3.6 ep len 26 avg score 3.0 avg_score_100 3.0 std score 1.0\n",
      "episode  4 score 3.0 ep len 12 avg score 3.0 avg_score_100 3.0 std score 0.9\n",
      "episode  5 score 1.3 ep len 6 avg score 2.7 avg_score_100 2.7 std score 1.0\n",
      "episode  6 score -0.2 ep len 5 avg score 2.3 avg_score_100 2.3 std score 1.4\n",
      "episode  7 score 0.2 ep len 9 avg score 2.0 avg_score_100 2.0 std score 1.5\n",
      "episode  8 score -0.2 ep len 8 avg score 1.8 avg_score_100 1.8 std score 1.6\n",
      "episode  9 score 0.6 ep len 6 avg score 1.7 avg_score_100 1.7 std score 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 21:37:49.326197: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55aee819c3f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-11 21:37:49.326213: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-12-11 21:37:49.329347: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-11 21:37:50.240932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2023-12-11 21:37:50.295491: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Updated\n",
      "episode  10 score 0.3 ep len 6 avg score 1.5 avg_score_100 1.5 std score 1.5\n",
      "episode  11 score 1.0 ep len 8 avg score 1.5 avg_score_100 1.5 std score 1.5\n",
      "episode  12 score 2.7 ep len 9 avg score 1.6 avg_score_100 1.6 std score 1.4\n",
      "episode  13 score 0.8 ep len 8 avg score 1.5 avg_score_100 1.5 std score 1.4\n",
      "episode  14 score -0.1 ep len 6 avg score 1.4 avg_score_100 1.4 std score 1.4\n",
      "episode  15 score 1.8 ep len 6 avg score 1.5 avg_score_100 1.5 std score 1.4\n",
      "episode  16 score 0.7 ep len 10 avg score 1.4 avg_score_100 1.4 std score 1.3\n",
      "episode  17 score 3.5 ep len 21 avg score 1.5 avg_score_100 1.5 std score 1.4\n",
      "episode  18 score 1.5 ep len 12 avg score 1.5 avg_score_100 1.5 std score 1.3\n",
      "episode  19 score -0.1 ep len 5 avg score 1.4 avg_score_100 1.4 std score 1.4\n",
      "Target Updated\n",
      "episode  20 score 0.6 ep len 10 avg score 1.4 avg_score_100 1.4 std score 1.3\n",
      "episode  21 score 1.8 ep len 21 avg score 1.4 avg_score_100 1.4 std score 1.3\n",
      "episode  22 score 1.8 ep len 12 avg score 1.4 avg_score_100 1.4 std score 1.3\n",
      "episode  23 score 3.7 ep len 16 avg score 1.5 avg_score_100 1.5 std score 1.3\n",
      "episode  24 score -0.0 ep len 4 avg score 1.5 avg_score_100 1.5 std score 1.3\n",
      "episode  25 score 1.9 ep len 10 avg score 1.5 avg_score_100 1.5 std score 1.3\n",
      "episode  26 score 1.5 ep len 7 avg score 1.5 avg_score_100 1.5 std score 1.3\n",
      "episode  27 score 2.8 ep len 14 avg score 1.5 avg_score_100 1.5 std score 1.3\n",
      "episode  28 score 3.0 ep len 10 avg score 1.6 avg_score_100 1.6 std score 1.3\n",
      "Target Updated\n",
      "episode  29 score 2.0 ep len 6 avg score 1.6 avg_score_100 1.6 std score 1.3\n",
      "episode  30 score 2.5 ep len 9 avg score 1.6 avg_score_100 1.6 std score 1.3\n",
      "episode  31 score 2.3 ep len 10 avg score 1.7 avg_score_100 1.7 std score 1.3\n",
      "episode  32 score 0.7 ep len 4 avg score 1.6 avg_score_100 1.6 std score 1.2\n",
      "episode  33 score 2.0 ep len 6 avg score 1.6 avg_score_100 1.6 std score 1.2\n",
      "episode  34 score 3.0 ep len 9 avg score 1.7 avg_score_100 1.7 std score 1.2\n",
      "episode  35 score 3.7 ep len 18 avg score 1.7 avg_score_100 1.7 std score 1.3\n",
      "episode  36 score 2.1 ep len 13 avg score 1.7 avg_score_100 1.7 std score 1.2\n",
      "episode  37 score 4.5 ep len 23 avg score 1.8 avg_score_100 1.8 std score 1.3\n",
      "Target Updated\n",
      "episode  38 score 3.4 ep len 8 avg score 1.9 avg_score_100 1.9 std score 1.3\n",
      "episode  39 score -0.5 ep len 9 avg score 1.8 avg_score_100 1.8 std score 1.3\n",
      "episode  40 score 9.3 ep len 22 avg score 2.0 avg_score_100 2.0 std score 1.8\n",
      "episode  41 score 7.8 ep len 24 avg score 2.1 avg_score_100 2.1 std score 1.9\n",
      "episode  42 score 6.1 ep len 18 avg score 2.2 avg_score_100 2.2 std score 2.0\n",
      "episode  43 score 7.9 ep len 22 avg score 2.3 avg_score_100 2.3 std score 2.2\n",
      "episode  44 score 1.4 ep len 4 avg score 2.3 avg_score_100 2.3 std score 2.1\n",
      "Target Updated\n",
      "episode  45 score 5.5 ep len 20 avg score 2.4 avg_score_100 2.4 std score 2.2\n",
      "episode  46 score 4.7 ep len 12 avg score 2.4 avg_score_100 2.4 std score 2.2\n",
      "episode  47 score 12.0 ep len 38 avg score 2.6 avg_score_100 2.6 std score 2.6\n",
      "episode  48 score 4.8 ep len 14 avg score 2.7 avg_score_100 2.7 std score 2.5\n",
      "Target Updated\n",
      "episode  49 score 5.7 ep len 18 avg score 2.7 avg_score_100 2.7 std score 2.6\n",
      "episode  50 score 7.3 ep len 28 avg score 2.8 avg_score_100 2.8 std score 2.6\n",
      "episode  51 score 9.7 ep len 42 avg score 3.0 avg_score_100 3.0 std score 2.7\n",
      "episode  52 score 3.6 ep len 14 avg score 3.0 avg_score_100 3.0 std score 2.7\n",
      "Target Updated\n",
      "episode  53 score 5.1 ep len 25 avg score 3.0 avg_score_100 3.0 std score 2.7\n",
      "episode  54 score 6.0 ep len 16 avg score 3.1 avg_score_100 3.1 std score 2.7\n",
      "episode  55 score 6.8 ep len 39 avg score 3.1 avg_score_100 3.1 std score 2.7\n",
      "Target Updated\n",
      "episode  56 score 7.0 ep len 35 avg score 3.2 avg_score_100 3.2 std score 2.8\n",
      "-----saving models------\n",
      "episode  57 score 9.1 ep len 33 avg score 3.3 avg_score_100 3.3 std score 2.8\n",
      "-----saving models------\n",
      "episode  58 score 4.9 ep len 16 avg score 3.3 avg_score_100 3.3 std score 2.8\n",
      "-----saving models------\n",
      "episode  59 score 6.1 ep len 29 avg score 3.4 avg_score_100 3.4 std score 2.8\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  60 score 6.1 ep len 27 avg score 3.4 avg_score_100 3.4 std score 2.8\n",
      "-----saving models------\n",
      "episode  61 score 4.1 ep len 16 avg score 3.4 avg_score_100 3.4 std score 2.8\n",
      "-----saving models------\n",
      "episode  62 score 7.2 ep len 26 avg score 3.5 avg_score_100 3.5 std score 2.8\n",
      "-----saving models------\n",
      "episode  63 score 6.5 ep len 25 avg score 3.5 avg_score_100 3.5 std score 2.8\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  64 score 12.1 ep len 35 avg score 3.7 avg_score_100 3.7 std score 3.0\n",
      "-----saving models------\n",
      "episode  65 score 7.2 ep len 13 avg score 3.7 avg_score_100 3.7 std score 3.0\n",
      "-----saving models------\n",
      "episode  66 score 6.9 ep len 19 avg score 3.8 avg_score_100 3.8 std score 3.0\n",
      "-----saving models------\n",
      "episode  67 score 3.9 ep len 24 avg score 3.8 avg_score_100 3.8 std score 3.0\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  68 score 9.1 ep len 40 avg score 3.9 avg_score_100 3.9 std score 3.0\n",
      "-----saving models------\n",
      "episode  69 score 4.4 ep len 11 avg score 3.9 avg_score_100 3.9 std score 3.0\n",
      "-----saving models------\n",
      "episode  70 score 8.7 ep len 44 avg score 3.9 avg_score_100 3.9 std score 3.0\n",
      "-----saving models------\n",
      "episode  71 score 8.2 ep len 26 avg score 4.0 avg_score_100 4.0 std score 3.1\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  72 score 10.4 ep len 27 avg score 4.1 avg_score_100 4.1 std score 3.1\n",
      "-----saving models------\n",
      "episode  73 score 10.3 ep len 30 avg score 4.2 avg_score_100 4.2 std score 3.2\n",
      "-----saving models------\n",
      "episode  74 score 8.8 ep len 22 avg score 4.2 avg_score_100 4.2 std score 3.2\n",
      "-----saving models------\n",
      "episode  75 score 9.2 ep len 30 avg score 4.3 avg_score_100 4.3 std score 3.2\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  76 score 18.2 ep len 32 avg score 4.5 avg_score_100 4.5 std score 3.6\n",
      "-----saving models------\n",
      "episode  77 score 9.5 ep len 33 avg score 4.5 avg_score_100 4.5 std score 3.6\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  78 score 7.7 ep len 47 avg score 4.6 avg_score_100 4.6 std score 3.6\n",
      "-----saving models------\n",
      "episode  79 score 14.4 ep len 32 avg score 4.7 avg_score_100 4.7 std score 3.7\n",
      "-----saving models------\n",
      "episode  80 score 17.3 ep len 61 avg score 4.9 avg_score_100 4.9 std score 4.0\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  81 score 19.6 ep len 48 avg score 5.0 avg_score_100 5.0 std score 4.3\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  82 score 17.1 ep len 62 avg score 5.2 avg_score_100 5.2 std score 4.4\n",
      "-----saving models------\n",
      "episode  83 score 18.7 ep len 58 avg score 5.3 avg_score_100 5.3 std score 4.7\n",
      "-----saving models------\n",
      "episode  84 score 9.9 ep len 21 avg score 5.4 avg_score_100 5.4 std score 4.7\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  85 score 17.3 ep len 56 avg score 5.5 avg_score_100 5.5 std score 4.8\n",
      "-----saving models------\n",
      "episode  86 score 14.3 ep len 54 avg score 5.6 avg_score_100 5.6 std score 4.9\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  87 score 17.9 ep len 38 avg score 5.8 avg_score_100 5.8 std score 5.0\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  88 score 19.0 ep len 68 avg score 5.9 avg_score_100 5.9 std score 5.2\n",
      "-----saving models------\n",
      "episode  89 score 18.3 ep len 45 avg score 6.1 avg_score_100 6.1 std score 5.3\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  90 score 14.5 ep len 81 avg score 6.2 avg_score_100 6.2 std score 5.3\n",
      "-----saving models------\n",
      "episode  91 score 16.9 ep len 68 avg score 6.3 avg_score_100 6.3 std score 5.4\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  92 score 21.8 ep len 58 avg score 6.4 avg_score_100 6.4 std score 5.6\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  93 score 17.3 ep len 66 avg score 6.6 avg_score_100 6.6 std score 5.7\n",
      "-----saving models------\n",
      "episode  94 score 19.3 ep len 62 avg score 6.7 avg_score_100 6.7 std score 5.8\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  95 score 29.1 ep len 85 avg score 6.9 avg_score_100 6.9 std score 6.2\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  96 score 20.8 ep len 56 avg score 7.1 avg_score_100 7.1 std score 6.4\n",
      "-----saving models------\n",
      "episode  97 score 30.9 ep len 62 avg score 7.3 avg_score_100 7.3 std score 6.8\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  98 score 27.3 ep len 67 avg score 7.5 avg_score_100 7.5 std score 7.0\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  99 score 25.3 ep len 56 avg score 7.7 avg_score_100 7.7 std score 7.2\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  100 score 40.6 ep len 92 avg score 8.0 avg_score_100 8.1 std score 7.9\n",
      "-----saving models------\n",
      "episode  101 score 34.2 ep len 75 avg score 8.3 avg_score_100 8.4 std score 8.3\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  102 score 43.6 ep len 77 avg score 8.6 avg_score_100 8.8 std score 8.9\n",
      "-----saving models------\n",
      "episode  103 score 16.0 ep len 43 avg score 8.7 avg_score_100 8.9 std score 8.9\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  104 score 41.8 ep len 86 avg score 9.0 avg_score_100 9.3 std score 9.4\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  105 score 40.5 ep len 77 avg score 9.3 avg_score_100 9.7 std score 9.9\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  106 score 32.3 ep len 75 avg score 9.5 avg_score_100 10.0 std score 10.1\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  107 score 44.9 ep len 83 avg score 9.8 avg_score_100 10.5 std score 10.6\n",
      "-----saving models------\n",
      "episode  108 score 45.2 ep len 76 avg score 10.2 avg_score_100 10.9 std score 11.1\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  109 score 38.7 ep len 81 avg score 10.4 avg_score_100 11.3 std score 11.3\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  110 score 43.1 ep len 79 avg score 10.7 avg_score_100 11.7 std score 11.7\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  111 score 44.0 ep len 79 avg score 11.0 avg_score_100 12.2 std score 12.1\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  112 score 43.5 ep len 78 avg score 11.3 avg_score_100 12.6 std score 12.4\n",
      "-----saving models------\n",
      "episode  113 score 42.1 ep len 85 avg score 11.6 avg_score_100 13.0 std score 12.7\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  114 score 48.3 ep len 74 avg score 11.9 avg_score_100 13.5 std score 13.1\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  115 score 48.6 ep len 86 avg score 12.2 avg_score_100 13.9 std score 13.4\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  116 score 42.1 ep len 78 avg score 12.5 avg_score_100 14.3 std score 13.7\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  117 score 52.9 ep len 87 avg score 12.8 avg_score_100 14.8 std score 14.1\n",
      "-----saving models------\n",
      "episode  118 score 44.4 ep len 79 avg score 13.1 avg_score_100 15.3 std score 14.3\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  119 score 53.5 ep len 86 avg score 13.4 avg_score_100 15.8 std score 14.7\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  120 score 51.6 ep len 89 avg score 13.7 avg_score_100 16.3 std score 15.1\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  121 score 40.6 ep len 83 avg score 13.9 avg_score_100 16.7 std score 15.2\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  122 score 50.9 ep len 79 avg score 14.2 avg_score_100 17.2 std score 15.5\n",
      "-----saving models------\n",
      "episode  123 score 36.2 ep len 56 avg score 14.4 avg_score_100 17.5 std score 15.6\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  124 score 45.6 ep len 80 avg score 14.7 avg_score_100 18.0 std score 15.8\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  125 score 51.6 ep len 84 avg score 15.0 avg_score_100 18.5 std score 16.0\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  126 score 42.1 ep len 82 avg score 15.2 avg_score_100 18.9 std score 16.1\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  127 score 49.5 ep len 82 avg score 15.4 avg_score_100 19.3 std score 16.4\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  128 score 48.8 ep len 81 avg score 15.7 avg_score_100 19.8 std score 16.6\n",
      "-----saving models------\n",
      "episode  129 score 51.3 ep len 81 avg score 16.0 avg_score_100 20.3 std score 16.8\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  130 score 63.9 ep len 139 avg score 16.3 avg_score_100 20.9 std score 17.2\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  131 score 50.9 ep len 86 avg score 16.6 avg_score_100 21.4 std score 17.4\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  132 score 80.0 ep len 163 avg score 17.1 avg_score_100 22.2 std score 18.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  133 score 86.9 ep len 145 avg score 17.6 avg_score_100 23.0 std score 19.1\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  134 score 88.2 ep len 140 avg score 18.1 avg_score_100 23.9 std score 20.0\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  135 score 85.5 ep len 200 avg score 18.6 avg_score_100 24.7 std score 20.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  136 score 103.5 ep len 200 avg score 19.2 avg_score_100 25.7 std score 21.9\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  137 score 110.5 ep len 200 avg score 19.9 avg_score_100 26.8 std score 23.1\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  138 score 104.6 ep len 200 avg score 20.5 avg_score_100 27.8 std score 24.1\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  139 score 99.5 ep len 200 avg score 21.1 avg_score_100 28.8 std score 24.9\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  140 score 124.5 ep len 200 avg score 21.8 avg_score_100 29.9 std score 26.3\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  141 score 111.3 ep len 200 avg score 22.4 avg_score_100 31.0 std score 27.3\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  142 score 118.6 ep len 200 avg score 23.1 avg_score_100 32.1 std score 28.3\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  143 score 132.1 ep len 200 avg score 23.9 avg_score_100 33.3 std score 29.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  144 score 123.3 ep len 200 avg score 24.6 avg_score_100 34.6 std score 30.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  145 score 127.5 ep len 200 avg score 25.3 avg_score_100 35.8 std score 31.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  146 score 126.6 ep len 200 avg score 25.9 avg_score_100 37.0 std score 32.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  147 score 126.3 ep len 200 avg score 26.6 avg_score_100 38.1 std score 33.6\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  148 score 139.0 ep len 200 avg score 27.4 avg_score_100 39.5 std score 34.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  149 score 125.9 ep len 200 avg score 28.0 avg_score_100 40.7 std score 35.5\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  150 score 146.6 ep len 200 avg score 28.8 avg_score_100 42.1 std score 36.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  151 score 99.8 ep len 150 avg score 29.3 avg_score_100 43.0 std score 37.0\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  152 score 108.4 ep len 154 avg score 29.8 avg_score_100 44.0 std score 37.4\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  153 score 130.8 ep len 200 avg score 30.5 avg_score_100 45.3 std score 38.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  154 score 132.9 ep len 200 avg score 31.1 avg_score_100 46.6 std score 38.9\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  155 score 89.2 ep len 127 avg score 31.5 avg_score_100 47.4 std score 39.1\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  156 score 154.0 ep len 200 avg score 32.3 avg_score_100 48.8 std score 40.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  157 score 144.3 ep len 200 avg score 33.0 avg_score_100 50.2 std score 41.0\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  158 score 147.3 ep len 200 avg score 33.7 avg_score_100 51.6 std score 41.9\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  159 score 139.5 ep len 200 avg score 34.4 avg_score_100 53.0 std score 42.6\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  160 score 147.7 ep len 200 avg score 35.1 avg_score_100 54.4 std score 43.4\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  161 score 150.5 ep len 200 avg score 35.8 avg_score_100 55.8 std score 44.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  162 score 147.9 ep len 200 avg score 36.5 avg_score_100 57.2 std score 44.9\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  163 score 152.2 ep len 200 avg score 37.2 avg_score_100 58.7 std score 45.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  164 score 151.4 ep len 200 avg score 37.9 avg_score_100 60.1 std score 46.4\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  165 score 151.2 ep len 200 avg score 38.5 avg_score_100 61.5 std score 47.1\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  166 score 147.0 ep len 200 avg score 39.2 avg_score_100 62.9 std score 47.7\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  167 score 155.2 ep len 200 avg score 39.9 avg_score_100 64.4 std score 48.3\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  168 score 95.7 ep len 129 avg score 40.2 avg_score_100 65.3 std score 48.4\n",
      "-----saving models------\n",
      "episode  169 score 47.7 ep len 59 avg score 40.3 avg_score_100 65.7 std score 48.2\n",
      "Target Updated\n",
      "Target Updated\n",
      "-----saving models------\n",
      "episode  170 score 150.0 ep len 200 avg score 40.9 avg_score_100 67.2 std score 48.8\n",
      "Target Updated\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m         truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     agent\u001b[38;5;241m.\u001b[39mremember(state\u001b[38;5;241m=\u001b[39mobservation, action\u001b[38;5;241m=\u001b[39maction_index, done\u001b[38;5;241m=\u001b[39mdone,\n\u001b[1;32m     28\u001b[0m                     reward\u001b[38;5;241m=\u001b[39mreward, new_state\u001b[38;5;241m=\u001b[39mnew_observation)\n\u001b[0;32m---> 29\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     observation \u001b[38;5;241m=\u001b[39m new_observation\n\u001b[1;32m     33\u001b[0m episode_lens\u001b[38;5;241m.\u001b[39mappend(episode_len)\n",
      "File \u001b[0;32m~/Documents/thesis/ddqn_her/ddqn.py:137\u001b[0m, in \u001b[0;36mDDQNAgent.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m q_target[batch_index, action_indices] \u001b[38;5;241m=\u001b[39m reward \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m    134\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma\u001b[38;5;241m*\u001b[39mq_next[batch_index, max_actions\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)]\u001b[38;5;241m*\u001b[39mdone\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m#* now we fit the main model (q_eval)\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_eval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m#* If counter reaches set value, update target network with weights of main network\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m#* it will update it at the very beginning also\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mmem_cntr \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplace_target \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# main loop\n",
    "for episode in trange(500, desc='Test episodes'):\n",
    "\n",
    "        proc.reset()\n",
    "        (observation, info), done = env.reset(), False\n",
    "        truncated = False\n",
    "        proc.update_input(observation, info)\n",
    "        observation = proc.get_input()\n",
    "\n",
    "        episode_reward = 0\n",
    "        episode_len = 0\n",
    "\n",
    "        while (not done) and (not truncated):\n",
    "            \n",
    "            action, action_index = agent.get_action(observation, deterministic=False)\n",
    "            new_observation, reward, done, truncated, new_info = env.step(action=[action])\n",
    "            \n",
    "            proc.update_input(new_observation, info)\n",
    "            new_observation = proc.get_input()\n",
    "\n",
    "            episode_reward += reward # type: ignore\n",
    "            episode_len +=1\n",
    "\n",
    "            if new_info[\"rewards\"][\"on_road_reward\"] == False or episode_len >= 200:\n",
    "                truncated = True\n",
    "            \n",
    "            agent.remember(state=observation, action=action_index, done=done,\n",
    "                            reward=reward, new_state=new_observation)\n",
    "            agent.train()\n",
    "\n",
    "            observation = new_observation\n",
    "\n",
    "        episode_lens.append(episode_len)\n",
    "\n",
    "        score_history.append(episode_reward)\n",
    "        avg_score = np.mean(score_history)\n",
    "        avg_history.append(avg_score)\n",
    "        std_score = np.std(score_history)\n",
    "        std_history.append(std_score)\n",
    "\n",
    "        avg_score_100 = np.mean(score_history[-100:])\n",
    "        avg_history_100.append(avg_score_100)\n",
    "\n",
    "        if avg_score_100 > best_score:\n",
    "            best_score = avg_score\n",
    "            agent.save_model(episode)\n",
    "\n",
    "        agent.tensorboard.update_stats(episode_rew = episode_reward,\n",
    "                                       average_rew =avg_score,\n",
    "                                       average_100_reward = avg_score_100,\n",
    "                                       std_rew=std_score,\n",
    "                                       epsilon=agent.epsilon,\n",
    "                                       episode_len = episode_len)\n",
    "        \n",
    "\n",
    "        print('episode ', episode, 'score %.1f' % episode_reward, 'ep len', episode_len,\n",
    "              'avg score %.1f' % avg_score, 'avg_score_100 %.1f' %avg_score_100,'std score %.1f' % std_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12474\n"
     ]
    }
   ],
   "source": [
    "n_steps = sum(episode_lens)\n",
    "print(n_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/o/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.configure to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.configure` for environment variables or `env.get_wrapper_attr('configure')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92734101045748c3b93572c30bd9b195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test episodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  0 score 124.9 ep len 150\n",
      "Moviepy - Building video /home/o/Documents/thesis/ddqn_her/videos/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/o/Documents/thesis/ddqn_her/videos/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/o/Documents/thesis/ddqn_her/videos/rl-video-episode-0.mp4\n"
     ]
    }
   ],
   "source": [
    "# env = record_videos(env)\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "data = load_config()\n",
    "env = gym.make('racetrack-v0', render_mode = 'rgb_array')\n",
    "env.configure(data) # type: ignore\n",
    "\n",
    "env = RecordVideo(env, video_folder=\"videos\", episode_trigger=lambda e: True)\n",
    "env.unwrapped.set_record_video_wrapper(env)\n",
    "\n",
    "# main loop\n",
    "for episode in trange(1, desc='Test episodes'):\n",
    "\n",
    "        proc.reset()\n",
    "        (observation, info), done = env.reset(), False\n",
    "        truncated = False\n",
    "        proc.update_input(observation, info)\n",
    "        observation = proc.get_input()\n",
    "\n",
    "        episode_reward = 0\n",
    "        episode_len = 0\n",
    "\n",
    "        while (not done) or truncated:\n",
    "            \n",
    "            action, action_index = agent.get_action(observation, deterministic=True)\n",
    "            new_observation, reward, done, truncated, new_info = env.step(action=[action])\n",
    "            \n",
    "            proc.update_input(new_observation, info)\n",
    "            new_observation = proc.get_input()\n",
    "\n",
    "            episode_reward += reward # type: ignore\n",
    "            episode_len +=1\n",
    "\n",
    "            if new_info[\"rewards\"][\"on_road_reward\"] == False or episode_len >=150:\n",
    "               done = True\n",
    "            \n",
    "            observation = new_observation\n",
    "\n",
    "        print('episode ', episode, 'score %.1f' % episode_reward, 'ep len', episode_len)   \n",
    "\n",
    "env.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
