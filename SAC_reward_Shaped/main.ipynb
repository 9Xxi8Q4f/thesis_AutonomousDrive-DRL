{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 00:24:21.426555: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-04 00:24:21.451454: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-04 00:24:21.451481: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-04 00:24:21.451508: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-04 00:24:21.457318: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# fundemental modules\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pprint\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from sac import Agent\n",
    "from obs import observation_shape\n",
    "from utils import record_videos, load_config\n",
    "\n",
    "filename = 'inverted_pendulum.png'\n",
    "\n",
    "best_score = -10000.0\n",
    "best_score = -1000.0\n",
    "score_history = []\n",
    "episode_lens = []\n",
    "avg_history = []\n",
    "std_history = []\n",
    "avg_history_100 = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/o/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.configure to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.configure` for environment variables or `env.get_wrapper_attr('configure')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "data = load_config()\n",
    "env = gym.make('racetrack-v0', render_mode = 'rgb_array')\n",
    "env.configure(data) # type: ignore\n",
    "# pprint.pprint(env.config) # type: ignore\n",
    "(obs, info), done = env.reset(), False\n",
    "\n",
    "#observation config\n",
    "proc = observation_shape(obs,info,2)\n",
    "proc.reset()\n",
    "input = proc.get_input()\n",
    "print(input.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 00:24:29.017028: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 00:24:29.039237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 00:24:29.039348: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 00:24:29.040086: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 00:24:29.040158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 00:24:29.040203: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 00:24:29.395664: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 00:24:29.395757: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 00:24:29.395818: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 00:24:29.395865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9631 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(input_dims=input.shape, env=env,\n",
    "            n_actions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab9ea85cf514a1f8e4000578dce68f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test episodes:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 00:25:23.210604: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... saving models ...\n",
      "episode  0 score -1.4 ep len 200 avg score -1.4 avg_score_100 -1.4 std score 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 00:25:27.810957: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557e6246d020 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-04 00:25:27.810973: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-12-04 00:25:27.813915: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-04 00:25:28.678568: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2023-12-04 00:25:28.732944: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f6174205120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f6174205120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "episode  1 score -1.7 ep len 200 avg score -1.5 avg_score_100 -1.5 std score 0.1\n",
      "... saving models ...\n",
      "episode  2 score 0.9 ep len 200 avg score -0.7 avg_score_100 -0.7 std score 1.2\n",
      "... saving models ...\n",
      "episode  3 score 1.2 ep len 200 avg score -0.2 avg_score_100 -0.2 std score 1.3\n",
      "episode  4 score -0.7 ep len 200 avg score -0.3 avg_score_100 -0.3 std score 1.2\n",
      "episode  5 score -0.4 ep len 200 avg score -0.3 avg_score_100 -0.3 std score 1.1\n",
      "... saving models ...\n",
      "episode  6 score 0.7 ep len 200 avg score -0.2 avg_score_100 -0.2 std score 1.1\n",
      "... saving models ...\n",
      "episode  7 score -0.0 ep len 200 avg score -0.2 avg_score_100 -0.2 std score 1.0\n",
      "episode  8 score -0.4 ep len 200 avg score -0.2 avg_score_100 -0.2 std score 0.9\n",
      "... saving models ...\n",
      "episode  9 score 2.0 ep len 200 avg score 0.0 avg_score_100 0.0 std score 1.1\n",
      "episode  10 score -0.2 ep len 200 avg score 0.0 avg_score_100 0.0 std score 1.1\n",
      "episode  11 score -1.5 ep len 200 avg score -0.1 avg_score_100 -0.1 std score 1.1\n",
      "episode  12 score 0.3 ep len 200 avg score -0.1 avg_score_100 -0.1 std score 1.1\n",
      "... saving models ...\n",
      "episode  13 score 2.3 ep len 200 avg score 0.1 avg_score_100 0.1 std score 1.2\n",
      "... saving models ...\n",
      "episode  14 score 0.2 ep len 200 avg score 0.1 avg_score_100 0.1 std score 1.2\n",
      "... saving models ...\n",
      "episode  15 score 1.6 ep len 200 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  16 score -1.2 ep len 200 avg score 0.1 avg_score_100 0.1 std score 1.2\n",
      "... saving models ...\n",
      "episode  17 score 2.0 ep len 200 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  18 score -0.4 ep len 200 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  19 score -0.9 ep len 200 avg score 0.1 avg_score_100 0.1 std score 1.2\n",
      "episode  20 score -0.6 ep len 200 avg score 0.1 avg_score_100 0.1 std score 1.2\n",
      "episode  21 score 1.5 ep len 200 avg score 0.2 avg_score_100 0.2 std score 1.2\n",
      "episode  22 score -0.9 ep len 200 avg score 0.1 avg_score_100 0.1 std score 1.2\n",
      "episode  23 score -0.5 ep len 200 avg score 0.1 avg_score_100 0.1 std score 1.2\n",
      "episode  24 score 0.3 ep len 200 avg score 0.1 avg_score_100 0.1 std score 1.1\n",
      "episode  25 score -0.8 ep len 200 avg score 0.1 avg_score_100 0.1 std score 1.1\n",
      "episode  26 score -1.0 ep len 200 avg score 0.0 avg_score_100 0.0 std score 1.1\n",
      "episode  27 score -1.8 ep len 200 avg score -0.0 avg_score_100 -0.0 std score 1.2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/o/Documents/thesis/SAC/main.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/SAC/main.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         done \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/SAC/main.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     agent\u001b[39m.\u001b[39mremember(state\u001b[39m=\u001b[39mobservation, action\u001b[39m=\u001b[39maction, done\u001b[39m=\u001b[39mdone,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/SAC/main.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                     reward\u001b[39m=\u001b[39mreward, new_state\u001b[39m=\u001b[39mnew_observation)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/o/Documents/thesis/SAC/main.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     agent\u001b[39m.\u001b[39;49mlearn()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/SAC/main.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     observation \u001b[39m=\u001b[39m new_observation\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/SAC/main.ipynb#W3sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m episode_lens\u001b[39m.\u001b[39mappend(episode_len)\n",
      "File \u001b[0;32m~/Documents/thesis/SAC/sac.py:252\u001b[0m, in \u001b[0;36mAgent.learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic_2\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(\n\u001b[1;32m    248\u001b[0m     critic_2_network_gradient, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic_2\u001b[39m.\u001b[39mtrainable_variables))\n\u001b[1;32m    250\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_network_parameters()\n\u001b[0;32m--> 252\u001b[0m gc\u001b[39m.\u001b[39;49mcollect()\n\u001b[1;32m    253\u001b[0m K\u001b[39m.\u001b[39mclear_session()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# main loop\n",
    "for episode in trange(500, desc='Test episodes'):\n",
    "\n",
    "        proc.reset()        \n",
    "        (observation, info), done = env.reset(), False\n",
    "        truncated = False\n",
    "        \n",
    "        proc.update_input(observation, info)\n",
    "        observation = proc.get_input()\n",
    "\n",
    "        episode_reward = 0\n",
    "        episode_len = 0\n",
    "\n",
    "        while (not done) and (not truncated):\n",
    "            action = agent.choose_action(observation)\n",
    "\n",
    "            new_observation, reward, done, truncated, new_info = env.step(action=[action])\n",
    "            proc.update_input(new_observation, info)\n",
    "            new_observation = proc.get_input()\n",
    "\n",
    "            episode_reward += reward # type: ignore\n",
    "            episode_len +=1\n",
    "\n",
    "            if new_info[\"rewards\"][\"on_road_reward\"] == False or episode_len >= 200:\n",
    "                done = True\n",
    "\n",
    "            agent.remember(state=observation, action=action, done=done,\n",
    "                            reward=reward, new_state=new_observation)\n",
    "            agent.learn()\n",
    "\n",
    "            observation = new_observation\n",
    "\n",
    "        episode_lens.append(episode_len)\n",
    "\n",
    "        score_history.append(episode_reward)\n",
    "        avg_score = np.mean(score_history)\n",
    "        avg_history.append(avg_score)\n",
    "        std_score = np.std(score_history)\n",
    "        std_history.append(std_score)\n",
    "\n",
    "        avg_score_100 = np.mean(score_history[-100:])\n",
    "        avg_history_100.append(avg_score_100)\n",
    "\n",
    "        if avg_score_100 > best_score:\n",
    "            best_score = avg_score\n",
    "            agent.save_models(episode)\n",
    "\n",
    "        agent.tensorboard.update_stats(episode_rew = episode_reward, \n",
    "                                       average_rew =avg_score,\n",
    "                                       average_100_reward = avg_score_100,\n",
    "                                       std_rew=std_score, \n",
    "                                       episode_len = episode_len)\n",
    "\n",
    "        print('episode ', episode, 'score %.1f' % episode_reward, 'ep len', episode_len,\n",
    "              'avg score %.1f' % avg_score, 'avg_score_100 %.1f' %avg_score_100,'std score %.1f' % std_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18635\n"
     ]
    }
   ],
   "source": [
    "n_steps = sum(episode_lens)\n",
    "print(n_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/o/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.configure to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.configure` for environment variables or `env.get_wrapper_attr('configure')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/o/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/o/Documents/thesis/SAC/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e258537b5c6740deaa7b9b8cb6fece45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test episodes:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  0 score 32.8 ep len 95\n",
      "episode  1 score 14.9 ep len 74\n",
      "episode  2 score 17.1 ep len 47\n",
      "Moviepy - Building video /home/o/Documents/thesis/SAC/videos/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/o/Documents/thesis/SAC/videos/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/o/Documents/thesis/SAC/videos/rl-video-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# env = record_videos(env)\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "data = load_config()\n",
    "env = gym.make('racetrack-v0', render_mode = 'rgb_array')\n",
    "env.configure(data) # type: ignore\n",
    "\n",
    "env = RecordVideo(env, video_folder=\"videos\", episode_trigger=lambda e: True)\n",
    "env.unwrapped.set_record_video_wrapper(env)\n",
    "\n",
    "\n",
    "for episode in trange(3, desc='Test episodes'):\n",
    "\n",
    "        proc.reset()        \n",
    "        (observation, info), done = env.reset(), False\n",
    "        truncated = False\n",
    "        \n",
    "        proc.update_input(observation, info)\n",
    "        observation = proc.get_input()\n",
    "\n",
    "        episode_reward = 0\n",
    "        episode_len = 0\n",
    "\n",
    "        while (not done) and (not truncated):\n",
    "            action = agent.choose_action(observation)\n",
    "\n",
    "            new_observation, reward, done, truncated, new_info = env.step(action=[action])\n",
    "            proc.update_input(new_observation, info)\n",
    "            new_observation = proc.get_input()\n",
    "\n",
    "            episode_reward += reward # type: ignore\n",
    "            episode_len +=1\n",
    "\n",
    "            if new_info[\"rewards\"][\"on_road_reward\"] == False or episode_len >= 200:\n",
    "                done = True\n",
    "\n",
    "            observation = new_observation\n",
    "\n",
    "        print('episode ', episode, 'score %.1f' % episode_reward, 'ep len', episode_len)\n",
    "\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
