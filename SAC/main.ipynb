{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 15:54:38.678422: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-10 15:54:38.705573: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-10 15:54:38.705594: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-10 15:54:38.705608: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-10 15:54:38.710254: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# fundemental modules\n",
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pprint\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from sac import Agent\n",
    "from obs import observation_shape\n",
    "from utils import record_videos, load_config\n",
    "\n",
    "filename = 'inverted_pendulum.png'\n",
    "\n",
    "best_score = -10000.0\n",
    "best_score = -1000.0\n",
    "score_history = []\n",
    "episode_lens = []\n",
    "avg_history = []\n",
    "std_history = []\n",
    "avg_history_100 = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/o/Documents/thesis/.venv/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.configure to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.configure` for environment variables or `env.get_wrapper_attr('configure')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "data = load_config()\n",
    "env = gym.make('racetrack-v0', render_mode = 'rgb_array')\n",
    "env.configure(data) # type: ignore\n",
    "# pprint.pprint(env.config) # type: ignore\n",
    "(obs, info), done = env.reset(), False\n",
    "\n",
    "#observation config\n",
    "proc = observation_shape(obs,info,2)\n",
    "proc.reset()\n",
    "input = proc.get_input()\n",
    "print(input.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 15:54:44.816952: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-10 15:54:44.839846: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-10 15:54:44.839944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-10 15:54:44.841221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-10 15:54:44.841296: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-10 15:54:44.841344: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-10 15:54:45.178539: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-10 15:54:45.178637: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-10 15:54:45.178700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-10 15:54:45.178743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9514 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(input_dims=input.shape, env=env,\n",
    "            n_actions=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997c9126bcbb4f21ba0674a7fe58c406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test episodes:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 15:55:13.540137: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... saving models ...\n",
      "episode  0 score -1.9 ep len 6 avg score -0.9 avg_score_100 -0.9 std score 0.9\n",
      "... saving models ...\n",
      "episode  1 score 2.5 ep len 14 avg score 0.2 avg_score_100 0.2 std score 1.8\n",
      "episode  2 score -1.3 ep len 7 avg score -0.2 avg_score_100 -0.2 std score 1.7\n",
      "... saving models ...\n",
      "episode  3 score 2.5 ep len 15 avg score 0.3 avg_score_100 0.3 std score 1.8\n",
      "... saving models ...\n",
      "episode  4 score 2.3 ep len 14 avg score 0.7 avg_score_100 0.7 std score 1.8\n",
      "episode  5 score -1.0 ep len 9 avg score 0.4 avg_score_100 0.4 std score 1.8\n",
      "episode  6 score 0.7 ep len 14 avg score 0.5 avg_score_100 0.5 std score 1.7\n",
      "episode  7 score 0.7 ep len 10 avg score 0.5 avg_score_100 0.5 std score 1.6\n",
      "episode  8 score -0.1 ep len 10 avg score 0.4 avg_score_100 0.4 std score 1.5\n",
      "episode  9 score -1.9 ep len 6 avg score 0.2 avg_score_100 0.2 std score 1.6\n",
      "episode  10 score 0.0 ep len 10 avg score 0.2 avg_score_100 0.2 std score 1.5\n",
      "episode  11 score -1.9 ep len 6 avg score 0.0 avg_score_100 0.0 std score 1.6\n",
      "episode  12 score -0.2 ep len 9 avg score 0.0 avg_score_100 0.0 std score 1.5\n",
      "episode  13 score -1.8 ep len 6 avg score -0.1 avg_score_100 -0.1 std score 1.5\n",
      "episode  14 score 0.6 ep len 12 avg score -0.1 avg_score_100 -0.1 std score 1.5\n",
      "episode  15 score -1.4 ep len 7 avg score -0.1 avg_score_100 -0.1 std score 1.5\n",
      "episode  16 score 1.7 ep len 15 avg score -0.0 avg_score_100 -0.0 std score 1.5\n",
      "episode  17 score -1.3 ep len 7 avg score -0.1 avg_score_100 -0.1 std score 1.5\n",
      "episode  18 score 3.6 ep len 14 avg score 0.1 avg_score_100 0.1 std score 1.7\n",
      "episode  19 score 1.6 ep len 11 avg score 0.2 avg_score_100 0.2 std score 1.7\n",
      "episode  20 score 0.7 ep len 12 avg score 0.2 avg_score_100 0.2 std score 1.6\n",
      "episode  21 score 2.0 ep len 13 avg score 0.3 avg_score_100 0.3 std score 1.6\n",
      "episode  22 score -0.7 ep len 8 avg score 0.2 avg_score_100 0.2 std score 1.6\n",
      "episode  23 score 0.0 ep len 10 avg score 0.2 avg_score_100 0.2 std score 1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 15:55:18.569785: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5599cb0c7010 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-10 15:55:18.569802: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2023-11-10 15:55:18.574734: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-10 15:55:19.820750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2023-11-10 15:55:19.885840: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f1a771c91b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f1a771c91b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "episode  24 score 1.7 ep len 16 avg score 0.3 avg_score_100 0.3 std score 1.6\n",
      "episode  25 score 1.4 ep len 12 avg score 0.3 avg_score_100 0.3 std score 1.6\n",
      "episode  26 score 4.5 ep len 20 avg score 0.5 avg_score_100 0.5 std score 1.7\n",
      "episode  27 score -3.8 ep len 4 avg score 0.3 avg_score_100 0.3 std score 1.9\n",
      "episode  28 score -1.6 ep len 12 avg score 0.3 avg_score_100 0.3 std score 1.9\n",
      "episode  29 score 0.2 ep len 10 avg score 0.2 avg_score_100 0.2 std score 1.8\n",
      "episode  30 score -1.9 ep len 7 avg score 0.2 avg_score_100 0.2 std score 1.8\n",
      "episode  31 score 3.6 ep len 16 avg score 0.3 avg_score_100 0.3 std score 1.9\n",
      "episode  32 score -3.9 ep len 4 avg score 0.2 avg_score_100 0.2 std score 2.0\n",
      "episode  33 score -0.1 ep len 9 avg score 0.2 avg_score_100 0.2 std score 2.0\n",
      "episode  34 score -1.3 ep len 7 avg score 0.1 avg_score_100 0.1 std score 2.0\n",
      "episode  35 score -0.2 ep len 8 avg score 0.1 avg_score_100 0.1 std score 1.9\n",
      "episode  36 score 3.3 ep len 20 avg score 0.2 avg_score_100 0.2 std score 2.0\n",
      "episode  37 score -3.9 ep len 4 avg score 0.1 avg_score_100 0.1 std score 2.1\n",
      "episode  38 score 1.8 ep len 23 avg score 0.1 avg_score_100 0.1 std score 2.1\n",
      "episode  39 score 5.1 ep len 13 avg score 0.2 avg_score_100 0.2 std score 2.2\n",
      "episode  40 score 3.9 ep len 19 avg score 0.3 avg_score_100 0.3 std score 2.2\n",
      "episode  41 score -1.5 ep len 8 avg score 0.3 avg_score_100 0.3 std score 2.2\n",
      "episode  42 score 0.8 ep len 13 avg score 0.3 avg_score_100 0.3 std score 2.2\n",
      "episode  43 score -0.4 ep len 12 avg score 0.3 avg_score_100 0.3 std score 2.2\n",
      "episode  44 score 3.5 ep len 19 avg score 0.4 avg_score_100 0.4 std score 2.2\n",
      "episode  45 score 3.7 ep len 15 avg score 0.4 avg_score_100 0.4 std score 2.2\n",
      "episode  46 score 0.2 ep len 9 avg score 0.4 avg_score_100 0.4 std score 2.2\n",
      "episode  47 score -0.9 ep len 10 avg score 0.4 avg_score_100 0.4 std score 2.2\n",
      "episode  48 score -2.7 ep len 7 avg score 0.3 avg_score_100 0.3 std score 2.2\n",
      "episode  49 score -3.2 ep len 5 avg score 0.3 avg_score_100 0.3 std score 2.2\n",
      "episode  50 score -0.5 ep len 15 avg score 0.2 avg_score_100 0.2 std score 2.2\n",
      "episode  51 score 6.3 ep len 20 avg score 0.4 avg_score_100 0.4 std score 2.3\n",
      "episode  52 score -0.5 ep len 12 avg score 0.3 avg_score_100 0.3 std score 2.3\n",
      "episode  53 score 9.2 ep len 34 avg score 0.5 avg_score_100 0.5 std score 2.6\n",
      "episode  54 score 2.5 ep len 19 avg score 0.5 avg_score_100 0.5 std score 2.6\n",
      "episode  55 score -2.9 ep len 10 avg score 0.5 avg_score_100 0.5 std score 2.6\n",
      "episode  56 score -1.4 ep len 9 avg score 0.5 avg_score_100 0.5 std score 2.6\n",
      "episode  57 score -1.9 ep len 9 avg score 0.4 avg_score_100 0.4 std score 2.6\n",
      "episode  58 score 2.1 ep len 18 avg score 0.4 avg_score_100 0.4 std score 2.6\n",
      "episode  59 score -1.3 ep len 10 avg score 0.4 avg_score_100 0.4 std score 2.6\n",
      "episode  60 score 2.3 ep len 17 avg score 0.4 avg_score_100 0.4 std score 2.5\n",
      "episode  61 score 6.0 ep len 13 avg score 0.5 avg_score_100 0.5 std score 2.6\n",
      "episode  62 score -0.7 ep len 12 avg score 0.5 avg_score_100 0.5 std score 2.6\n",
      "episode  63 score 2.7 ep len 29 avg score 0.5 avg_score_100 0.5 std score 2.6\n",
      "episode  64 score 2.4 ep len 17 avg score 0.6 avg_score_100 0.6 std score 2.6\n",
      "episode  65 score 3.0 ep len 20 avg score 0.6 avg_score_100 0.6 std score 2.6\n",
      "episode  66 score 1.5 ep len 27 avg score 0.6 avg_score_100 0.6 std score 2.6\n",
      "episode  67 score 0.7 ep len 10 avg score 0.6 avg_score_100 0.6 std score 2.5\n",
      "... saving models ...\n",
      "episode  68 score 4.3 ep len 20 avg score 0.7 avg_score_100 0.7 std score 2.6\n",
      "episode  69 score 0.5 ep len 15 avg score 0.7 avg_score_100 0.7 std score 2.5\n",
      "... saving models ...\n",
      "episode  70 score 7.3 ep len 24 avg score 0.8 avg_score_100 0.8 std score 2.6\n",
      "episode  71 score -3.8 ep len 5 avg score 0.7 avg_score_100 0.7 std score 2.7\n",
      "... saving models ...\n",
      "episode  72 score 6.9 ep len 28 avg score 0.8 avg_score_100 0.8 std score 2.8\n",
      "... saving models ...\n",
      "episode  73 score 1.2 ep len 18 avg score 0.8 avg_score_100 0.8 std score 2.7\n",
      "... saving models ...\n",
      "episode  74 score 2.6 ep len 26 avg score 0.8 avg_score_100 0.8 std score 2.7\n",
      "... saving models ...\n",
      "episode  75 score 4.9 ep len 23 avg score 0.9 avg_score_100 0.9 std score 2.8\n",
      "episode  76 score -2.7 ep len 9 avg score 0.8 avg_score_100 0.8 std score 2.8\n",
      "episode  77 score 1.2 ep len 14 avg score 0.8 avg_score_100 0.8 std score 2.7\n",
      "episode  78 score 0.9 ep len 16 avg score 0.8 avg_score_100 0.8 std score 2.7\n",
      "episode  79 score 0.3 ep len 18 avg score 0.8 avg_score_100 0.8 std score 2.7\n",
      "episode  80 score -0.4 ep len 15 avg score 0.8 avg_score_100 0.8 std score 2.7\n",
      "episode  81 score -1.5 ep len 11 avg score 0.8 avg_score_100 0.8 std score 2.7\n",
      "episode  82 score 0.9 ep len 12 avg score 0.8 avg_score_100 0.8 std score 2.7\n",
      "episode  83 score 7.5 ep len 28 avg score 0.9 avg_score_100 0.9 std score 2.8\n",
      "episode  84 score -2.7 ep len 7 avg score 0.8 avg_score_100 0.8 std score 2.8\n",
      "episode  85 score 4.8 ep len 25 avg score 0.9 avg_score_100 0.9 std score 2.8\n",
      "... saving models ...\n",
      "episode  86 score 4.9 ep len 34 avg score 0.9 avg_score_100 0.9 std score 2.8\n",
      "... saving models ...\n",
      "episode  87 score 1.9 ep len 25 avg score 0.9 avg_score_100 0.9 std score 2.8\n",
      "... saving models ...\n",
      "episode  88 score 2.2 ep len 23 avg score 0.9 avg_score_100 0.9 std score 2.8\n",
      "... saving models ...\n",
      "episode  89 score 5.1 ep len 23 avg score 1.0 avg_score_100 1.0 std score 2.8\n",
      "... saving models ...\n",
      "episode  90 score 1.1 ep len 13 avg score 1.0 avg_score_100 1.0 std score 2.8\n",
      "episode  91 score 0.5 ep len 21 avg score 1.0 avg_score_100 1.0 std score 2.8\n",
      "... saving models ...\n",
      "episode  92 score 5.2 ep len 27 avg score 1.0 avg_score_100 1.0 std score 2.8\n",
      "... saving models ...\n",
      "episode  93 score 8.0 ep len 24 avg score 1.1 avg_score_100 1.1 std score 2.9\n",
      "episode  94 score -0.9 ep len 12 avg score 1.1 avg_score_100 1.1 std score 2.9\n",
      "... saving models ...\n",
      "episode  95 score 8.3 ep len 30 avg score 1.2 avg_score_100 1.2 std score 2.9\n",
      "... saving models ...\n",
      "episode  96 score 1.7 ep len 21 avg score 1.2 avg_score_100 1.2 std score 2.9\n",
      "... saving models ...\n",
      "episode  97 score 6.7 ep len 24 avg score 1.2 avg_score_100 1.2 std score 3.0\n",
      "... saving models ...\n",
      "episode  98 score 5.0 ep len 23 avg score 1.3 avg_score_100 1.3 std score 3.0\n",
      "... saving models ...\n",
      "episode  99 score 3.7 ep len 21 avg score 1.3 avg_score_100 1.3 std score 3.0\n",
      "... saving models ...\n",
      "episode  100 score 6.4 ep len 24 avg score 1.3 avg_score_100 1.4 std score 3.0\n",
      "... saving models ...\n",
      "episode  101 score -2.1 ep len 9 avg score 1.3 avg_score_100 1.3 std score 3.0\n",
      "... saving models ...\n",
      "episode  102 score 9.8 ep len 31 avg score 1.4 avg_score_100 1.4 std score 3.1\n",
      "... saving models ...\n",
      "episode  103 score 3.5 ep len 18 avg score 1.4 avg_score_100 1.4 std score 3.1\n",
      "... saving models ...\n",
      "episode  104 score 2.1 ep len 14 avg score 1.4 avg_score_100 1.4 std score 3.1\n",
      "... saving models ...\n",
      "episode  105 score 4.7 ep len 23 avg score 1.4 avg_score_100 1.5 std score 3.1\n",
      "... saving models ...\n",
      "episode  106 score 5.0 ep len 23 avg score 1.5 avg_score_100 1.5 std score 3.1\n",
      "... saving models ...\n",
      "episode  107 score 5.3 ep len 24 avg score 1.5 avg_score_100 1.6 std score 3.1\n",
      "... saving models ...\n",
      "episode  108 score 5.6 ep len 19 avg score 1.5 avg_score_100 1.6 std score 3.1\n",
      "... saving models ...\n",
      "episode  109 score 2.2 ep len 21 avg score 1.5 avg_score_100 1.7 std score 3.1\n",
      "... saving models ...\n",
      "episode  110 score 6.1 ep len 20 avg score 1.6 avg_score_100 1.8 std score 3.1\n",
      "... saving models ...\n",
      "episode  111 score 1.8 ep len 22 avg score 1.6 avg_score_100 1.8 std score 3.1\n",
      "... saving models ...\n",
      "episode  112 score 1.1 ep len 12 avg score 1.6 avg_score_100 1.8 std score 3.1\n",
      "... saving models ...\n",
      "episode  113 score 4.7 ep len 21 avg score 1.6 avg_score_100 1.9 std score 3.1\n",
      "... saving models ...\n",
      "episode  114 score 4.6 ep len 18 avg score 1.6 avg_score_100 1.9 std score 3.1\n",
      "... saving models ...\n",
      "episode  115 score 13.8 ep len 35 avg score 1.7 avg_score_100 2.1 std score 3.3\n",
      "... saving models ...\n",
      "episode  116 score 11.3 ep len 32 avg score 1.8 avg_score_100 2.2 std score 3.4\n",
      "... saving models ...\n",
      "episode  117 score 6.2 ep len 20 avg score 1.9 avg_score_100 2.2 std score 3.4\n",
      "... saving models ...\n",
      "episode  118 score 1.6 ep len 20 avg score 1.9 avg_score_100 2.2 std score 3.4\n",
      "... saving models ...\n",
      "episode  119 score 4.7 ep len 25 avg score 1.9 avg_score_100 2.2 std score 3.3\n",
      "... saving models ...\n",
      "episode  120 score 1.4 ep len 20 avg score 1.9 avg_score_100 2.2 std score 3.3\n",
      "... saving models ...\n",
      "episode  121 score 15.2 ep len 30 avg score 2.0 avg_score_100 2.4 std score 3.5\n",
      "... saving models ...\n",
      "episode  122 score 9.4 ep len 31 avg score 2.0 avg_score_100 2.5 std score 3.6\n",
      "... saving models ...\n",
      "episode  123 score 4.5 ep len 19 avg score 2.1 avg_score_100 2.5 std score 3.6\n",
      "... saving models ...\n",
      "episode  124 score 6.6 ep len 22 avg score 2.1 avg_score_100 2.6 std score 3.6\n",
      "... saving models ...\n",
      "episode  125 score 2.4 ep len 23 avg score 2.1 avg_score_100 2.6 std score 3.6\n",
      "... saving models ...\n",
      "episode  126 score -1.0 ep len 14 avg score 2.1 avg_score_100 2.5 std score 3.6\n",
      "... saving models ...\n",
      "episode  127 score 2.9 ep len 26 avg score 2.1 avg_score_100 2.6 std score 3.5\n",
      "... saving models ...\n",
      "episode  128 score 11.2 ep len 29 avg score 2.2 avg_score_100 2.7 std score 3.6\n",
      "... saving models ...\n",
      "episode  129 score 3.3 ep len 19 avg score 2.2 avg_score_100 2.8 std score 3.6\n",
      "... saving models ...\n",
      "episode  130 score 4.6 ep len 29 avg score 2.2 avg_score_100 2.8 std score 3.6\n",
      "... saving models ...\n",
      "episode  131 score 3.5 ep len 23 avg score 2.2 avg_score_100 2.8 std score 3.6\n",
      "... saving models ...\n",
      "episode  132 score 8.9 ep len 28 avg score 2.2 avg_score_100 2.9 std score 3.6\n",
      "... saving models ...\n",
      "episode  133 score 9.6 ep len 31 avg score 2.3 avg_score_100 3.0 std score 3.7\n",
      "... saving models ...\n",
      "episode  134 score 2.6 ep len 22 avg score 2.3 avg_score_100 3.1 std score 3.6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/o/Documents/thesis/env/SAC/main.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/env/SAC/main.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m           done \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/env/SAC/main.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     agent\u001b[39m.\u001b[39mremember(state\u001b[39m=\u001b[39mobservation, action\u001b[39m=\u001b[39maction, done\u001b[39m=\u001b[39mdone,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/env/SAC/main.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m                     reward\u001b[39m=\u001b[39mreward, new_state\u001b[39m=\u001b[39mnew_observation)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/o/Documents/thesis/env/SAC/main.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     agent\u001b[39m.\u001b[39;49mlearn()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/env/SAC/main.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     observation \u001b[39m=\u001b[39m new_observation\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/o/Documents/thesis/env/SAC/main.ipynb#W3sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m episode_lens\u001b[39m.\u001b[39mappend(episode_len)\n",
      "File \u001b[0;32m~/Documents/thesis/env/SAC/sac.py:227\u001b[0m, in \u001b[0;36mAgent.learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m     actor_loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mreduce_mean(actor_loss)\n\u001b[1;32m    225\u001b[0m actor_network_gradient \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(actor_loss,\n\u001b[1;32m    226\u001b[0m                                     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactor\u001b[39m.\u001b[39mtrainable_variables)\n\u001b[0;32m--> 227\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactor\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mapply_gradients(\u001b[39mzip\u001b[39;49m(\n\u001b[1;32m    228\u001b[0m                 actor_network_gradient, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactor\u001b[39m.\u001b[39;49mtrainable_variables))\n\u001b[1;32m    231\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape(persistent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m    232\u001b[0m     \u001b[39m# I didn't know that these context managers shared values?\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     q_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale\u001b[39m*\u001b[39mreward \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma\u001b[39m*\u001b[39mvalue_\u001b[39m*\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mdone)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:1222\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1218\u001b[0m experimental_aggregate_gradients \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\n\u001b[1;32m   1219\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mexperimental_aggregate_gradients\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m )\n\u001b[1;32m   1221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_gradients_aggregation \u001b[39mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[0;32m-> 1222\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggregate_gradients(grads_and_vars)\n\u001b[1;32m   1223\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:1184\u001b[0m, in \u001b[0;36mOptimizer.aggregate_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1182\u001b[0m     \u001b[39mreturn\u001b[39;00m grads_and_vars\n\u001b[1;32m   1183\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1184\u001b[0m     \u001b[39mreturn\u001b[39;00m optimizer_utils\u001b[39m.\u001b[39;49mall_reduce_sum_gradients(grads_and_vars)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/keras/src/optimizers/utils.py:37\u001b[0m, in \u001b[0;36mall_reduce_sum_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mstrategy_supports_no_merge_call():\n\u001b[1;32m     36\u001b[0m     grads \u001b[39m=\u001b[39m [pair[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m pair \u001b[39min\u001b[39;00m filtered_grads_and_vars]\n\u001b[0;32m---> 37\u001b[0m     reduced \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_replica_context()\u001b[39m.\u001b[39;49mall_reduce(\n\u001b[1;32m     38\u001b[0m         tf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mReduceOp\u001b[39m.\u001b[39;49mSUM, grads\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     40\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[39m# TODO(b/183257003): Remove this branch\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     reduced \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_replica_context()\u001b[39m.\u001b[39mmerge_call(\n\u001b[1;32m     43\u001b[0m         _all_reduce_sum_fn, args\u001b[39m=\u001b[39m(filtered_grads_and_vars,)\n\u001b[1;32m     44\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3625\u001b[0m, in \u001b[0;36mReplicaContextBase.all_reduce\u001b[0;34m(self, reduce_op, value, options)\u001b[0m\n\u001b[1;32m   3623\u001b[0m   reduce_op \u001b[39m=\u001b[39m reduce_util\u001b[39m.\u001b[39mReduceOp(reduce_op\u001b[39m.\u001b[39mupper())\n\u001b[1;32m   3624\u001b[0m \u001b[39mif\u001b[39;00m options \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 3625\u001b[0m   options \u001b[39m=\u001b[39m collective_util\u001b[39m.\u001b[39;49mOptions()\n\u001b[1;32m   3627\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbatch_all_reduce\u001b[39m(strategy, \u001b[39m*\u001b[39mvalue_flat):\n\u001b[1;32m   3628\u001b[0m   \u001b[39mreturn\u001b[39;00m strategy\u001b[39m.\u001b[39mextended\u001b[39m.\u001b[39mbatch_reduce_to(\n\u001b[1;32m   3629\u001b[0m       reduce_op, [(v, _batch_reduce_destination(v)) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m value_flat],\n\u001b[1;32m   3630\u001b[0m       options)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tensorflow/python/distribute/collective_util.py:127\u001b[0m, in \u001b[0;36mOptions.__init__\u001b[0;34m(self, bytes_per_pack, timeout_seconds, implementation)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m bytes_per_pack \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    125\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    126\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mArgument `bytes_per_pack` must be >=0, Received \u001b[39m\u001b[39m{\u001b[39;00mbytes_per_pack\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(implementation, \u001b[39mstr\u001b[39;49m):\n\u001b[1;32m    128\u001b[0m   implementation \u001b[39m=\u001b[39m CommunicationImplementation(implementation\u001b[39m.\u001b[39mupper())\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(implementation, CommunicationImplementation):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# main loop\n",
    "for episode in trange(500, desc='Test episodes'):\n",
    "\n",
    "        proc.reset()        \n",
    "        (observation, info), done = env.reset(), False\n",
    "        truncated = False\n",
    "        \n",
    "        proc.update_input(observation, info)\n",
    "        observation = proc.get_input()\n",
    "\n",
    "        episode_reward = 0\n",
    "        episode_len = 0\n",
    "\n",
    "        while (not done) and (not truncated):\n",
    "            action = agent.choose_action(observation)\n",
    "\n",
    "            new_observation, reward, done, truncated, new_info = env.step(action=[action])\n",
    "            proc.update_input(new_observation, info)\n",
    "            new_observation = proc.get_input()\n",
    "\n",
    "            episode_reward += reward # type: ignore\n",
    "            episode_len +=1\n",
    "\n",
    "            if new_info[\"rewards\"][\"on_road_reward\"] == False or episode_len >= 200:\n",
    "                done = True\n",
    "\n",
    "            agent.remember(state=observation, action=action, done=done,\n",
    "                            reward=reward, new_state=new_observation)\n",
    "            agent.learn()\n",
    "\n",
    "            observation = new_observation\n",
    "\n",
    "        episode_lens.append(episode_len)\n",
    "\n",
    "        score_history.append(episode_reward)\n",
    "        avg_score = np.mean(score_history)\n",
    "        avg_history.append(avg_score)\n",
    "        std_score = np.std(score_history)\n",
    "        std_history.append(std_score)\n",
    "\n",
    "        avg_score_100 = np.mean(score_history[-100:])\n",
    "        avg_history_100.append(avg_score_100)\n",
    "\n",
    "        if avg_score_100 > best_score:\n",
    "            best_score = avg_score\n",
    "            agent.save_models(episode)\n",
    "\n",
    "        agent.tensorboard.update_stats(episode_rew = episode_reward, \n",
    "                                       average_rew =avg_score,\n",
    "                                       average_100_reward = avg_score_100,\n",
    "                                       std_rew=std_score, \n",
    "                                       episode_len = episode_len)\n",
    "\n",
    "        print('episode ', episode, 'score %.1f' % episode_reward, 'ep len', episode_len,\n",
    "              'avg score %.1f' % avg_score, 'avg_score_100 %.1f' %avg_score_100,'std score %.1f' % std_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = sum(episode_lens)\n",
    "print(n_steps)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
